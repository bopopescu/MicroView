{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MicroView Latest News 2018-11-30: We've re-launched MicroView's documentation!","title":"Welcome to MicroView"},{"location":"#welcome-to-microview","text":"","title":"Welcome to MicroView"},{"location":"#latest-news","text":"2018-11-30: We've re-launched MicroView's documentation!","title":"Latest News"},{"location":"bibliography/","text":"Bibliography [1] A Odgaard and HJG Gundersen. \u201cQuantification of Connectivity in Cancellous Bone, with Special Emphasis on 3-D Reconstructions\u201d. Bone. 14. 113-152. 1993. [2] N Otsu. \u201cA threshold selection method from gray-level histograms\u201d. IEEE Trans. Systems, Man, and Cybernetics. 9(1). 62-66. 1979. [3] T Hildebrand and P R\u00fcegsegger. \u201cQuantification of bone microarchitecture with the structure model index\u201d. Comp Meth Biomech Biomed Eng 1. 15-23. 1997. [4] T Hildebrand and P R\u00fcegsegger. \u201cA new method for the model-independent assessment of thickness in three-dimensional images\u201d. J Microsc 185. 67-75. 1997. [5] WJ Whitehouse. \u201cThe quantitative morphology of anisotropic trabecular bone\u201d. J Microsc 101. 153-168. 1974. [6] TP Harrigan and RW Mann. \u201cCharacterization of microstructural anisotropy in orthotropic materials using a second rank tensor\u201d. J Mat Sci 19. 761-767. 1984.","title":"Bibliography"},{"location":"bibliography/#bibliography","text":"[1] A Odgaard and HJG Gundersen. \u201cQuantification of Connectivity in Cancellous Bone, with Special Emphasis on 3-D Reconstructions\u201d. Bone. 14. 113-152. 1993. [2] N Otsu. \u201cA threshold selection method from gray-level histograms\u201d. IEEE Trans. Systems, Man, and Cybernetics. 9(1). 62-66. 1979. [3] T Hildebrand and P R\u00fcegsegger. \u201cQuantification of bone microarchitecture with the structure model index\u201d. Comp Meth Biomech Biomed Eng 1. 15-23. 1997. [4] T Hildebrand and P R\u00fcegsegger. \u201cA new method for the model-independent assessment of thickness in three-dimensional images\u201d. J Microsc 185. 67-75. 1997. [5] WJ Whitehouse. \u201cThe quantitative morphology of anisotropic trabecular bone\u201d. J Microsc 101. 153-168. 1974. [6] TP Harrigan and RW Mann. \u201cCharacterization of microstructural anisotropy in orthotropic materials using a second rank tensor\u201d. J Mat Sci 19. 761-767. 1984.","title":"Bibliography"},{"location":"changelog/","text":"Changelog 2018-11-27: MicroView 2.5.0-rc23 Release (2.5.0-3987) Demo extended until 2019-04-01 Various bug fixes re. DICOM import Various improvements to Orthanc support 2018-09-04: MicroView 2.5.0-rc22 Release (2.5.0-3946) Demo extended until 2018-12-01 Various minor bug fixes \u200b2018-06-01: MicroView 2.5.0-rc21 Release (2.5.0-3943) Demo extended until 2018-09-01 Various minor bug fixes 2018-05-01: MicroView 2.5.0-rc20 Release (2.5.0-3927) Demo extended until 2018-06-01 Various minor bug fixes \u200b2018-02-01: MicroView 2.5.0-rc19 Release (2.5.0-3886) Demo extended until 2018-05-01 DICOM browser compatibility code added for python3 Attempts to load a VTK geometry file through ( File \u2192 Open... ) Provide better feedback better handling of DICOM slope/intercept rescaling \u200b2017-11-29: MicroView 2.5.0-rc18 Release (2.5.0-3842) Demo extended until 2018-02-01 Upgraded to Python 2.7.14 for Windows platform builds DICOMDIR dialog supports selection/loading of multiple series at a time Improvements to adaptive thresholding New shell scripting feature added Shared memory ITK infrastructure added Additional view layouts added \"Reveal in File browser\" context menu entry added Preview of image registration tool added \u200b2017-08-28: MicroView 2.5.0-rc17 Release (2.5.0-3768) Demo extended until 2017-12-01 \u200b- DICOM annotations added Support for pandas added Right-mouse button context menu over 2D viewport added wx Phoenix integration 3mf format reader fixes Add jpeg_ls support to DICOM image reader Add support for Python 3.5 and 3.6 builds \u200b 2017-05-29: MicroView 2.5.0-rc16 Release (2.5.0-3664) Demo extended until 2017-09-01 Slanted edge MTF tool added to CT tools plugin Minor DICOM reader improvements Changes to volume renderer to assist with saving/restoring look-up tables Spreadsheets can now be saved to disk Various improvements to dynamic code loader - MicroView installation size reduced on all platforms Improvements to bone analysis: SMI tool added Standard anatomical labels added to 2D image viewports (use 'o' key to toggle on/off) Bug fixes to Advanced ROI tool (applies to save/restore of slice contours that were recorded on oblique slices or slices other than z-axis) 2017-02-28: MicroView 2.5.0-rc15 Release (2.5.0-3557) Demo extended until 2017-06-01 Experimental build with Python 2.7.13 and VTK 7.0 \u200b 2016-12-01: MicroView 2.5.0-rc14 Release (2.5.0-3448) Better support for dynamic downloading of content Demo extended until 2017-03-01 \u200b \u200b2016-10-06: MicroView 2.5.0-rc13 Release (2.5.0-3380) Bug fixes for stereology Bug fixes related to download/installation of dynamic content Bug fixes to region grow tool wxPhoenix portability changes 2016-09-21: MicroView 2.5.0-rc12 Release (2.5.0-3356) Bug fixes for stereology 2016-09-01: MicroView 2.5.0-rc11 Release (2.5.0-3351) Extend demo date to 2016-12-01 Hotfix of a python27.dll startup error on Win64 CUDA 8.0 support added Bone analysis bug fixes ITK matrix support added Movie maker fixes 2016-05-31: MicroView 2.5.0-rc10 Release (2.5.0-3305) Extend demo date to 2016-09-01 Rewrite of manual thresholding code DICOM browse dialog modifications to support streaming support Rolling ball implemented in line-profiling tool Angle display during image re-orientation added \u200b 2016-03-31: MicroView 2.5.0-rc9 Release (2.5.0-3243) Extend demo date to 2016-06-01 Size reduction: close to 50% reduction in disk and memory footprint VFF reader: Support for non-z-axis 2D image slices added DICOM: reading of multi-slice dicom meta info is faster Improved drag&drop support - plugins now respond to D&D over the plugin window Spreadsheet display: Experimental SQL-query capability added Column rename added Geometry tool: object rename function added Logging cleanup 2016-02-04: MicroView 2.5.0-rc8 Release (2.5.0-3140) Extend demo date to 2016-04-01 VTK-7 updates Python 3 portability updates DICOM speed improvements Application loading speed improvements Image transfer plugin improvements: DICOM push, Orthanc REST interface push added 2015-12-01: MicroView 2.5.0-rc7 Release (2.5.0-3089) Extend demo date to 2016-02-01 \u200b- Fixes to Advanced ROI tool: interactions on slices other than z-slice were broken Support for Fedora 23 added DICOM: patient orientation labelling should be correct for all images now (switch internally to using the new vtkDICOM library) Volume Renderer: opacity-based picker re-enabled Geometry Manager: added ability to apply transforms to geometries Parallel display option added Drag-and-drop a folder of DICOM images now generates DICOMDIR and launches series picker \u200b2015-09-30: MicroView 2.5.0-rc6 Release (2.5.0-3040) L3D image reader bug fixes VTK 6.2 compatibility bug fixes Bug fixes to basic bone analysis tool Widget scrolling enabled to improve display on small screens Camera plugin now displays in mm or pixels Demo for plugins extended to Dec 1, 2015 \u200b2015-07-31: MicroView 2.5.0-rc5 Release (2.5.0-2999) OpenSSL upgraded (this means 32-bit Windows build now requires SP3) VTK 6.2 compatibility bug fixes Point-picker speed-up Demo for plugins extended to Oct 1, 2015 Internal work to support image registration/image fusion \u200b### 2015-06-01: MicroView 2.5.0-rc4 Release (2.5.0-2920) Support for Orthanc image servers added Layout fixes - improved look on smaller screens Improvements to support DICOM image orientation (origin upper left) vs. VTK orientation (origin lower left) 2015-04-09: MicroView 2.5.0-rc3 Release (2.5.0-2799) Fixes to licensing code Improved integration between point picker and ROI tools Image Info: search filters added to display output Volume Renderer: LUT table selection persistence 2015-04-01: MicroView 2.5.0-rc2 Release (2.5.0-2772) Plugin demos extended until June 1, 2015 Installer script improvements: old plugins now deleted during installation DICOM header info now maintained on a slice-by-slice basis Serial ROI tool: save to dicom tag now supported Limited formatting options added for Excel 2007 format spreadsheets Online documentation added ZODB retired - multiple intances of MicroView now supported again 2015-03-09: MicroView 2.5.0-rc1 Release (2.5.0-2703) Release candidate 1 - first release without a main application demo timeout Plugin demos extended until April 1, 2015 File-based logging added DICOM anonymizer added to image info plugin DICOMDIR boostrap mechanism added NRRD image support added (read-only) Improved inter-plugin connectivity Preliminary Ultrasonix image format reader added Fixes: 't' key over 2D viewport fix histogram fixes","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#2018-11-27-microview-250-rc23-release-250-3987","text":"Demo extended until 2019-04-01 Various bug fixes re. DICOM import Various improvements to Orthanc support","title":"2018-11-27: MicroView 2.5.0-rc23 Release (2.5.0-3987)"},{"location":"changelog/#2018-09-04-microview-250-rc22-release-250-3946","text":"Demo extended until 2018-12-01 Various minor bug fixes","title":"2018-09-04: MicroView 2.5.0-rc22 Release (2.5.0-3946)"},{"location":"changelog/#2018-06-01-microview-250-rc21-release-250-3943","text":"Demo extended until 2018-09-01 Various minor bug fixes","title":"\u200b2018-06-01: MicroView 2.5.0-rc21 Release (2.5.0-3943)"},{"location":"changelog/#2018-05-01-microview-250-rc20-release-250-3927","text":"Demo extended until 2018-06-01 Various minor bug fixes","title":"2018-05-01: MicroView 2.5.0-rc20 Release (2.5.0-3927)"},{"location":"changelog/#2018-02-01-microview-250-rc19-release-250-3886","text":"Demo extended until 2018-05-01 DICOM browser compatibility code added for python3 Attempts to load a VTK geometry file through ( File \u2192 Open... ) Provide better feedback better handling of DICOM slope/intercept rescaling","title":"\u200b2018-02-01: MicroView 2.5.0-rc19 Release (2.5.0-3886)"},{"location":"changelog/#2017-11-29-microview-250-rc18-release-250-3842","text":"Demo extended until 2018-02-01 Upgraded to Python 2.7.14 for Windows platform builds DICOMDIR dialog supports selection/loading of multiple series at a time Improvements to adaptive thresholding New shell scripting feature added Shared memory ITK infrastructure added Additional view layouts added \"Reveal in File browser\" context menu entry added Preview of image registration tool added","title":"\u200b2017-11-29: MicroView 2.5.0-rc18 Release (2.5.0-3842)"},{"location":"changelog/#2017-08-28-microview-250-rc17-release-250-3768","text":"Demo extended until 2017-12-01 \u200b- DICOM annotations added Support for pandas added Right-mouse button context menu over 2D viewport added wx Phoenix integration 3mf format reader fixes Add jpeg_ls support to DICOM image reader Add support for Python 3.5 and 3.6 builds \u200b","title":"\u200b2017-08-28: MicroView 2.5.0-rc17 Release (2.5.0-3768)"},{"location":"changelog/#2017-05-29-microview-250-rc16-release-250-3664","text":"Demo extended until 2017-09-01 Slanted edge MTF tool added to CT tools plugin Minor DICOM reader improvements Changes to volume renderer to assist with saving/restoring look-up tables Spreadsheets can now be saved to disk Various improvements to dynamic code loader - MicroView installation size reduced on all platforms Improvements to bone analysis: SMI tool added Standard anatomical labels added to 2D image viewports (use 'o' key to toggle on/off) Bug fixes to Advanced ROI tool (applies to save/restore of slice contours that were recorded on oblique slices or slices other than z-axis)","title":"2017-05-29: MicroView 2.5.0-rc16 Release (2.5.0-3664)"},{"location":"changelog/#2017-02-28-microview-250-rc15-release-250-3557","text":"Demo extended until 2017-06-01 Experimental build with Python 2.7.13 and VTK 7.0 \u200b","title":"2017-02-28: MicroView 2.5.0-rc15 Release (2.5.0-3557)"},{"location":"changelog/#2016-12-01-microview-250-rc14-release-250-3448","text":"Better support for dynamic downloading of content Demo extended until 2017-03-01 \u200b","title":"2016-12-01: MicroView 2.5.0-rc14 Release (2.5.0-3448)"},{"location":"changelog/#2016-10-06-microview-250-rc13-release-250-3380","text":"Bug fixes for stereology Bug fixes related to download/installation of dynamic content Bug fixes to region grow tool wxPhoenix portability changes","title":"\u200b2016-10-06: MicroView 2.5.0-rc13 Release (2.5.0-3380)"},{"location":"changelog/#2016-09-21-microview-250-rc12-release-250-3356","text":"Bug fixes for stereology","title":"2016-09-21: MicroView 2.5.0-rc12 Release (2.5.0-3356)"},{"location":"changelog/#2016-09-01-microview-250-rc11-release-250-3351","text":"Extend demo date to 2016-12-01 Hotfix of a python27.dll startup error on Win64 CUDA 8.0 support added Bone analysis bug fixes ITK matrix support added Movie maker fixes","title":"2016-09-01: MicroView 2.5.0-rc11 Release (2.5.0-3351)"},{"location":"changelog/#2016-05-31-microview-250-rc10-release-250-3305","text":"Extend demo date to 2016-09-01 Rewrite of manual thresholding code DICOM browse dialog modifications to support streaming support Rolling ball implemented in line-profiling tool Angle display during image re-orientation added \u200b","title":"2016-05-31: MicroView 2.5.0-rc10 Release (2.5.0-3305)"},{"location":"changelog/#2016-03-31-microview-250-rc9-release-250-3243","text":"Extend demo date to 2016-06-01 Size reduction: close to 50% reduction in disk and memory footprint VFF reader: Support for non-z-axis 2D image slices added DICOM: reading of multi-slice dicom meta info is faster Improved drag&drop support - plugins now respond to D&D over the plugin window Spreadsheet display: Experimental SQL-query capability added Column rename added Geometry tool: object rename function added Logging cleanup","title":"2016-03-31: MicroView 2.5.0-rc9 Release (2.5.0-3243)"},{"location":"changelog/#2016-02-04-microview-250-rc8-release-250-3140","text":"Extend demo date to 2016-04-01 VTK-7 updates Python 3 portability updates DICOM speed improvements Application loading speed improvements Image transfer plugin improvements: DICOM push, Orthanc REST interface push added","title":"2016-02-04: MicroView 2.5.0-rc8 Release (2.5.0-3140)"},{"location":"changelog/#2015-12-01-microview-250-rc7-release-250-3089","text":"Extend demo date to 2016-02-01 \u200b- Fixes to Advanced ROI tool: interactions on slices other than z-slice were broken Support for Fedora 23 added DICOM: patient orientation labelling should be correct for all images now (switch internally to using the new vtkDICOM library) Volume Renderer: opacity-based picker re-enabled Geometry Manager: added ability to apply transforms to geometries Parallel display option added Drag-and-drop a folder of DICOM images now generates DICOMDIR and launches series picker","title":"2015-12-01: MicroView 2.5.0-rc7 Release (2.5.0-3089)"},{"location":"changelog/#2015-09-30-microview-250-rc6-release-250-3040","text":"L3D image reader bug fixes VTK 6.2 compatibility bug fixes Bug fixes to basic bone analysis tool Widget scrolling enabled to improve display on small screens Camera plugin now displays in mm or pixels Demo for plugins extended to Dec 1, 2015","title":"\u200b2015-09-30: MicroView 2.5.0-rc6 Release (2.5.0-3040)"},{"location":"changelog/#2015-07-31-microview-250-rc5-release-250-2999","text":"OpenSSL upgraded (this means 32-bit Windows build now requires SP3) VTK 6.2 compatibility bug fixes Point-picker speed-up Demo for plugins extended to Oct 1, 2015 Internal work to support image registration/image fusion \u200b### 2015-06-01: MicroView 2.5.0-rc4 Release (2.5.0-2920) Support for Orthanc image servers added Layout fixes - improved look on smaller screens Improvements to support DICOM image orientation (origin upper left) vs. VTK orientation (origin lower left)","title":"\u200b2015-07-31: MicroView 2.5.0-rc5 Release (2.5.0-2999)"},{"location":"changelog/#2015-04-09-microview-250-rc3-release-250-2799","text":"Fixes to licensing code Improved integration between point picker and ROI tools Image Info: search filters added to display output Volume Renderer: LUT table selection persistence","title":"2015-04-09: MicroView 2.5.0-rc3 Release (2.5.0-2799)"},{"location":"changelog/#2015-04-01-microview-250-rc2-release-250-2772","text":"Plugin demos extended until June 1, 2015 Installer script improvements: old plugins now deleted during installation DICOM header info now maintained on a slice-by-slice basis Serial ROI tool: save to dicom tag now supported Limited formatting options added for Excel 2007 format spreadsheets Online documentation added ZODB retired - multiple intances of MicroView now supported again","title":"2015-04-01: MicroView 2.5.0-rc2 Release (2.5.0-2772)"},{"location":"changelog/#2015-03-09-microview-250-rc1-release-250-2703","text":"Release candidate 1 - first release without a main application demo timeout Plugin demos extended until April 1, 2015 File-based logging added DICOM anonymizer added to image info plugin DICOMDIR boostrap mechanism added NRRD image support added (read-only) Improved inter-plugin connectivity Preliminary Ultrasonix image format reader added Fixes: 't' key over 2D viewport fix histogram fixes","title":"2015-03-09: MicroView 2.5.0-rc1 Release (2.5.0-2703)"},{"location":"copyright/","text":"Copyright Notice MicroView is based on a number of Open Source software packages. Individual copyright and license statements from their respective owners follow. GE Healthcare Copyright Copyright (c) 2000-2008 GE Healthcare. Use, modification and redistribution of the software, in source or binary forms, are permitted provided that the following terms and conditions are met: 1) Redistribution of the source code, in verbatim or modified form, must retain the above copyright notice, this license, the following disclaimer, and any notices that refer to this license and/or the following disclaimer. 1) Redistribution in binary form must include the above copyright notice, a copy of this license and the following disclaimer in the documentation or with other materials provided with the distribution. 1) Modified copies of the source code must be clearly marked as such, and must not be misrepresented as verbatim copies of the source code. EXCEPT WHEN OTHERWISE STATED IN WRITING BY THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES, THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE SOFTWARE \"AS IS\" WITHOUT EXPRESSED OR IMPLIED WARRANTY INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. IN NO EVENT UNLESS AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER OR OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE SOFTWARE UNDER THE TERMS OF THIS LICENSE BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, LOSS OF DATA OR DATA BECOMING INACCURATE OR LOSS OF PROFIT OR BUSINESS INTERRUPTION) ARISING IN ANY WAY OUT OF THE USE OR INABILITY TO USE THE SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Atamai Inc. License Portions of MicroView are based on code provided by Atamai Inc. The code represented in MicroView has been modified from it's original version. The Copyright and license statement follows: Copyright (c) 2000 Atamai, Inc. Use, modification and redistribution of the software, in source or binary forms, are permitted provided that the following terms and conditions are met: 1) Redistribution of the source code, in verbatim or modified form, must retain the above copyright notice, this license, the following disclaimer, and any notices that refer to this license and/or the following disclaimer. 1) Redistribution in binary form must include the above copyright notice, a copy of this license and the following disclaimer in the documentation or with other materials provided with the distribution. 1) Modified copies of the source code must be clearly marked as such, and must not be misrepresented as verbatim copies of the source code. THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE SOFTWARE \"AS IS\" WITHOUT EXPRESSED OR IMPLIED WARRANTY INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. IN NO EVENT SHALL ANY COPYRIGHT HOLDER OR OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE SOFTWARE UNDER THE TERMS OF THIS LICENSE BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, LOSS OF DATA OR DATA BECOMING INACCURATE OR LOSS OF PROFIT OR BUSINESS INTERRUPTION) ARISING IN ANY WAY OUT OF THE USE OR INABILITY TO USE THE SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. VTK Copyright MicroView makes use of the Visualization Toolkit ( VTK ) for most viewing and rendering functions. The Copyright and license statement follows: Copyright (c) 1993-2008 Ken Martin, Will Schroeder, Bill Lorensen All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither name of Ken Martin, Will Schroeder, or Bill Lorensen nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHORS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. ITK Copyright MicroView makes use of the National Library of Medicine Insight Segmentation and Registration Toolkit ( ITK ) for some segmentation and image filtering algorithms. The Copyright and license statement follows: TERMS AND CONDITIONS FOR USE , REPRODUCTION , AND DISTRIBUTION 1 . Definitions : \"License\" shall mean the terms and conditions for use , reproduction , and distribution as defined by Sections 1 through 9 of this document . \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License . \"Legal Entity\" shall mean the union of the acting entity and all other entities that control , are controlled by , or are under common control with that entity . For the purposes of this definition , \"control\" means ( i ) the power , direct or indirect , to cause the direction or management of such entity , whether by contract or otherwise , or ( ii ) ownership of fifty percent ( 50 %) or more of the outstanding shares , or ( iii ) beneficial ownership of such entity . \"You\" ( or \"Your\" ) shall mean an individual or Legal Entity exercising permissions granted by this License . \"Source\" form shall mean the preferred form for making modifications , including but not limited to software source code , documentation source , and configuration files . \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form , including but not limited to compiled object code , generated documentation , and conversions to other media types . \"Work\" shall mean the work of authorship , whether in Source or Object form , made available under the License , as indicated by a copyright notice that is included in or attached to the work ( an example is provided in the Appendix below ). \"Derivative Works\" shall mean any work , whether in Source or Object form , that is based on ( or derived from ) the Work and for which the editorial revisions , annotations , elaborations , or other modifications represent , as a whole , an original work of authorship . For the purposes of this License , Derivative Works shall not include works that remain separable from , or merely link ( or bind by name ) to the interfaces of , the Work and Derivative Works thereof . \"Contribution\" shall mean any work of authorship , including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof , that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner . For the purposes of this definition , \"submitted\" means any form of electronic , verbal , or written communication sent to the Licensor or its representatives , including but not limited to communication on electronic mailing lists , source code control systems , and issue tracking systems that are managed by , or on behalf of , the Licensor for the purpose of discussing and improving the Work , but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work . 1 . Grant of Copyright License : Subject to the terms and conditions of this License , each Contributor hereby grants to You a perpetual , worldwide , non-exclusive , no-charge , royalty-free , irrevocable copyright license to reproduce , prepare Derivative Works of , publicly display , publicly perform , sublicense , and distribute the Work and such Derivative Works in Source or Object form . 2 . Grant of Patent License : Subject to the terms and conditions of this License , each Contributor hereby grants to You a perpetual , worldwide , non-exclusive , no-charge , royalty-free , irrevocable ( except as stated in this section ) patent license to make , have made , use , offer to sell , sell , import , and otherwise transfer the Work , where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution ( s ) alone or by combination of their Contribution ( s ) with the Work to which such Contribution ( s ) was submitted . If You institute patent litigation against any entity ( including a cross-claim or counterclaim in a lawsuit ) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement , then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed . 3 . Redistribution : You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium , with or without modifications , and in Source or Object form , provided that You meet the following conditions : You must give any other recipients of the Work or Derivative Works a copy of this License ; and You must cause any modified files to carry prominent notices stating that You changed the files ; and You must retain , in the Source form of any Derivative Works that You distribute , all copyright , patent , trademark , and attribution notices from the Source form of the Work , excluding those notices that do not pertain to any part of the Derivative Works ; and If the Work includes a \"NOTICE\" text file as part of its distribution , then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file , excluding those notices that do not pertain to any part of the Derivative Works , in at least one of the following places : within a NOTICE text file distributed as part of the Derivative Works ; within the Source form or documentation , if provided along with the Derivative Works ; or , within a display generated by the Derivative Works , if and wherever such third-party notices normally appear . The contents of the NOTICE file are for informational purposes only and do not modify the License . You may add Your own attribution notices within Derivative Works that You distribute , alongside or as an addendum to the NOTICE text from the Work , provided that such additional attribution notices cannot be construed as modifying the License . You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use , reproduction , or distribution of Your modifications , or for any such Derivative Works as a whole , provided Your use , reproduction , and distribution of the Work otherwise complies with the conditions stated in this License . 1 . Submission of Contributions : Unless You explicitly state otherwise , any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License , without any additional terms or conditions . Notwithstanding the above , nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions . 2 . Trademarks : This License does not grant permission to use the trade names , trademarks , service marks , or product names of the Licensor , except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file . 3 . Disclaimer of Warranty : Unless required by applicable law or agreed to in writing , Licensor provides the Work ( and each Contributor provides its Contributions ) on an \"AS IS\" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied , including , without limitation , any warranties or conditions of TITLE , NON-INFRINGEMENT , MERCHANTABILITY , or FITNESS FOR A PARTICULAR PURPOSE . You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License . 4 . Limitation of Liability : In no event and under no legal theory , whether in tort ( including negligence ), contract , or otherwise , unless required by applicable law ( such as deliberate and grossly negligent acts ) or agreed to in writing , shall any Contributor be liable to You for damages , including any direct , indirect , special , incidental , or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work ( including but not limited to damages for loss of goodwill , work stoppage , computer failure or malfunction , or any and all other commercial damages or losses ), even if such Contributor has been advised of the possibility of such damages . 5 . Accepting Warranty or Additional Liability : While redistributing the Work or Derivative Works thereof , You may choose to offer , and charge a fee for , acceptance of support , warranty , indemnity , or other liability obligations and / or rights consistent with this License . However , in accepting such obligations , You may act only on Your own behalf and on Your sole responsibility , not on behalf of any other Contributor , and only if You agree to indemnify , defend , and hold each Contributor harmless for any liability incurred by , or claims asserted against , such Contributor by reason of your accepting any such warranty or additional liability . PIL Copyright The Python Imaging Library (PIL) is Copyright \u00a9 1997-2011 by Secret Labs AB Copyright \u00a9 1995-2011 by Fredrik Lundh By obtaining, using, and/or copying this software and/or its associated documentation, you agree that you have read, understood, and will comply with the following terms and conditions: Permission to use, copy, modify, and distribute this software and its associated documentation for any purpose and without fee is hereby granted, provided that the above copyright notice appears in all copies, and that both that copyright notice and this permission notice appear in supporting documentation, and that the name of Secret Labs AB or the author not be used in advertising or publicity pertaining to distribution of the software without specific, written prior permission. SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. Numpy Copyright Copyright (c) 2005, NumPy Developers All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of the NumPy Developers nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"Copyright Notices"},{"location":"copyright/#copyright-notice","text":"MicroView is based on a number of Open Source software packages. Individual copyright and license statements from their respective owners follow.","title":"Copyright Notice"},{"location":"copyright/#ge-healthcare-copyright","text":"Copyright (c) 2000-2008 GE Healthcare. Use, modification and redistribution of the software, in source or binary forms, are permitted provided that the following terms and conditions are met: 1) Redistribution of the source code, in verbatim or modified form, must retain the above copyright notice, this license, the following disclaimer, and any notices that refer to this license and/or the following disclaimer. 1) Redistribution in binary form must include the above copyright notice, a copy of this license and the following disclaimer in the documentation or with other materials provided with the distribution. 1) Modified copies of the source code must be clearly marked as such, and must not be misrepresented as verbatim copies of the source code. EXCEPT WHEN OTHERWISE STATED IN WRITING BY THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES, THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE SOFTWARE \"AS IS\" WITHOUT EXPRESSED OR IMPLIED WARRANTY INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. IN NO EVENT UNLESS AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER OR OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE SOFTWARE UNDER THE TERMS OF THIS LICENSE BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, LOSS OF DATA OR DATA BECOMING INACCURATE OR LOSS OF PROFIT OR BUSINESS INTERRUPTION) ARISING IN ANY WAY OUT OF THE USE OR INABILITY TO USE THE SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.","title":"GE Healthcare Copyright"},{"location":"copyright/#atamai-inc-license","text":"Portions of MicroView are based on code provided by Atamai Inc. The code represented in MicroView has been modified from it's original version. The Copyright and license statement follows: Copyright (c) 2000 Atamai, Inc. Use, modification and redistribution of the software, in source or binary forms, are permitted provided that the following terms and conditions are met: 1) Redistribution of the source code, in verbatim or modified form, must retain the above copyright notice, this license, the following disclaimer, and any notices that refer to this license and/or the following disclaimer. 1) Redistribution in binary form must include the above copyright notice, a copy of this license and the following disclaimer in the documentation or with other materials provided with the distribution. 1) Modified copies of the source code must be clearly marked as such, and must not be misrepresented as verbatim copies of the source code. THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE SOFTWARE \"AS IS\" WITHOUT EXPRESSED OR IMPLIED WARRANTY INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. IN NO EVENT SHALL ANY COPYRIGHT HOLDER OR OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE SOFTWARE UNDER THE TERMS OF THIS LICENSE BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, LOSS OF DATA OR DATA BECOMING INACCURATE OR LOSS OF PROFIT OR BUSINESS INTERRUPTION) ARISING IN ANY WAY OUT OF THE USE OR INABILITY TO USE THE SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.","title":"Atamai Inc. License"},{"location":"copyright/#vtk-copyright","text":"MicroView makes use of the Visualization Toolkit ( VTK ) for most viewing and rendering functions. The Copyright and license statement follows: Copyright (c) 1993-2008 Ken Martin, Will Schroeder, Bill Lorensen All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither name of Ken Martin, Will Schroeder, or Bill Lorensen nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHORS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"VTK Copyright"},{"location":"copyright/#itk-copyright","text":"MicroView makes use of the National Library of Medicine Insight Segmentation and Registration Toolkit ( ITK ) for some segmentation and image filtering algorithms. The Copyright and license statement follows: TERMS AND CONDITIONS FOR USE , REPRODUCTION , AND DISTRIBUTION 1 . Definitions : \"License\" shall mean the terms and conditions for use , reproduction , and distribution as defined by Sections 1 through 9 of this document . \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License . \"Legal Entity\" shall mean the union of the acting entity and all other entities that control , are controlled by , or are under common control with that entity . For the purposes of this definition , \"control\" means ( i ) the power , direct or indirect , to cause the direction or management of such entity , whether by contract or otherwise , or ( ii ) ownership of fifty percent ( 50 %) or more of the outstanding shares , or ( iii ) beneficial ownership of such entity . \"You\" ( or \"Your\" ) shall mean an individual or Legal Entity exercising permissions granted by this License . \"Source\" form shall mean the preferred form for making modifications , including but not limited to software source code , documentation source , and configuration files . \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form , including but not limited to compiled object code , generated documentation , and conversions to other media types . \"Work\" shall mean the work of authorship , whether in Source or Object form , made available under the License , as indicated by a copyright notice that is included in or attached to the work ( an example is provided in the Appendix below ). \"Derivative Works\" shall mean any work , whether in Source or Object form , that is based on ( or derived from ) the Work and for which the editorial revisions , annotations , elaborations , or other modifications represent , as a whole , an original work of authorship . For the purposes of this License , Derivative Works shall not include works that remain separable from , or merely link ( or bind by name ) to the interfaces of , the Work and Derivative Works thereof . \"Contribution\" shall mean any work of authorship , including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof , that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner . For the purposes of this definition , \"submitted\" means any form of electronic , verbal , or written communication sent to the Licensor or its representatives , including but not limited to communication on electronic mailing lists , source code control systems , and issue tracking systems that are managed by , or on behalf of , the Licensor for the purpose of discussing and improving the Work , but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work . 1 . Grant of Copyright License : Subject to the terms and conditions of this License , each Contributor hereby grants to You a perpetual , worldwide , non-exclusive , no-charge , royalty-free , irrevocable copyright license to reproduce , prepare Derivative Works of , publicly display , publicly perform , sublicense , and distribute the Work and such Derivative Works in Source or Object form . 2 . Grant of Patent License : Subject to the terms and conditions of this License , each Contributor hereby grants to You a perpetual , worldwide , non-exclusive , no-charge , royalty-free , irrevocable ( except as stated in this section ) patent license to make , have made , use , offer to sell , sell , import , and otherwise transfer the Work , where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution ( s ) alone or by combination of their Contribution ( s ) with the Work to which such Contribution ( s ) was submitted . If You institute patent litigation against any entity ( including a cross-claim or counterclaim in a lawsuit ) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement , then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed . 3 . Redistribution : You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium , with or without modifications , and in Source or Object form , provided that You meet the following conditions : You must give any other recipients of the Work or Derivative Works a copy of this License ; and You must cause any modified files to carry prominent notices stating that You changed the files ; and You must retain , in the Source form of any Derivative Works that You distribute , all copyright , patent , trademark , and attribution notices from the Source form of the Work , excluding those notices that do not pertain to any part of the Derivative Works ; and If the Work includes a \"NOTICE\" text file as part of its distribution , then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file , excluding those notices that do not pertain to any part of the Derivative Works , in at least one of the following places : within a NOTICE text file distributed as part of the Derivative Works ; within the Source form or documentation , if provided along with the Derivative Works ; or , within a display generated by the Derivative Works , if and wherever such third-party notices normally appear . The contents of the NOTICE file are for informational purposes only and do not modify the License . You may add Your own attribution notices within Derivative Works that You distribute , alongside or as an addendum to the NOTICE text from the Work , provided that such additional attribution notices cannot be construed as modifying the License . You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use , reproduction , or distribution of Your modifications , or for any such Derivative Works as a whole , provided Your use , reproduction , and distribution of the Work otherwise complies with the conditions stated in this License . 1 . Submission of Contributions : Unless You explicitly state otherwise , any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License , without any additional terms or conditions . Notwithstanding the above , nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions . 2 . Trademarks : This License does not grant permission to use the trade names , trademarks , service marks , or product names of the Licensor , except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file . 3 . Disclaimer of Warranty : Unless required by applicable law or agreed to in writing , Licensor provides the Work ( and each Contributor provides its Contributions ) on an \"AS IS\" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied , including , without limitation , any warranties or conditions of TITLE , NON-INFRINGEMENT , MERCHANTABILITY , or FITNESS FOR A PARTICULAR PURPOSE . You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License . 4 . Limitation of Liability : In no event and under no legal theory , whether in tort ( including negligence ), contract , or otherwise , unless required by applicable law ( such as deliberate and grossly negligent acts ) or agreed to in writing , shall any Contributor be liable to You for damages , including any direct , indirect , special , incidental , or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work ( including but not limited to damages for loss of goodwill , work stoppage , computer failure or malfunction , or any and all other commercial damages or losses ), even if such Contributor has been advised of the possibility of such damages . 5 . Accepting Warranty or Additional Liability : While redistributing the Work or Derivative Works thereof , You may choose to offer , and charge a fee for , acceptance of support , warranty , indemnity , or other liability obligations and / or rights consistent with this License . However , in accepting such obligations , You may act only on Your own behalf and on Your sole responsibility , not on behalf of any other Contributor , and only if You agree to indemnify , defend , and hold each Contributor harmless for any liability incurred by , or claims asserted against , such Contributor by reason of your accepting any such warranty or additional liability .","title":"ITK Copyright"},{"location":"copyright/#pil-copyright","text":"The Python Imaging Library (PIL) is Copyright \u00a9 1997-2011 by Secret Labs AB Copyright \u00a9 1995-2011 by Fredrik Lundh By obtaining, using, and/or copying this software and/or its associated documentation, you agree that you have read, understood, and will comply with the following terms and conditions: Permission to use, copy, modify, and distribute this software and its associated documentation for any purpose and without fee is hereby granted, provided that the above copyright notice appears in all copies, and that both that copyright notice and this permission notice appear in supporting documentation, and that the name of Secret Labs AB or the author not be used in advertising or publicity pertaining to distribution of the software without specific, written prior permission. SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.","title":"PIL Copyright"},{"location":"copyright/#numpy-copyright","text":"Copyright (c) 2005, NumPy Developers All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of the NumPy Developers nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"Numpy Copyright"},{"location":"downloads/","text":"Downloads Latest binaries (2.5.0-rc23 released 2018-11-29): Windows: 64 bit , 32 bit OS X: macOS 10.8+ Linux: Ubuntu: 16.04 Fedora FC18 , FC10","title":"Downloads"},{"location":"downloads/#downloads","text":"Latest binaries (2.5.0-rc23 released 2018-11-29): Windows: 64 bit , 32 bit OS X: macOS 10.8+ Linux: Ubuntu: 16.04 Fedora FC18 , FC10","title":"Downloads"},{"location":"faq/","text":"Frequently Asked Questions Q. Where can I download the latest version of MicroView? The latest version of MicroView can be downloaded here . Q. Where can I get source code for MicroView and instructions on how to build it? The original source code for MicroView was maintained in cvs, then later, in git on sourceforge . As of 2015, the sourceforge code was archived and development of Microview was moved to github . Q. Is MicroView available for Mac OS X? Yes. MicroView is supported on recent version of OS X for both 32-bit and 64-bit architectures. Previous generations of MicroView ran on PPC hardware but with the release of 2.5.0+ PPC platforms are no longer supported. Q. How can I automatically threshold a loaded image in MicroView? MicroView can automatically select an optimal threshold value by examining a histogram of pixel values in a user defined region of interest. This value is useful as input to the isosurface, stereology, and volume rendering plugins. To automatically threshold an image, first select a region of interest, using either the ROI plugin or the 7/8 keys. Next, generate a histogram of the pixel values within this region of interest by hitting the g key. Finally, click on the Auto Threshold button on the histogram plot window to automatically determine an optimal threshold. MicroView's automatic thresholding is based upon the \"Otsu\" method. Q. Why can't I export to DICOM format? The image export feature gives a list of appropriate file formats, depending on the image depth of the image you've loaded. If, for instance, you have a 16-bit image, only DICOM format will be available. For 8-bit images, different formats will be available, including jpeg, png, gif, etc. To handle the export of 16-bit images to formats such as jpeg, you need to first rescale the images to 8-bit. Under the Process menu, select Image Downsample in order to convert your image from 16-bit to 8-bit, then select Image Export from the File menu. Q. How do I make movies in MicroView? MicroView has a rudimentary movie making facility , which permits generation of movies. For more complex movie making, there are numerous screen capture applications that can export to e.g. AVI movies. One such utility is CamStudio . Q. Where's the \"Advanced ROI\" tool? This release of MicroView stems from the open-source origins posted on http://microview.sourceforge.net . The so-called \"Advanced ROI\" plugin was a customization provided by GE Healthcare. A replacement plugin with similar functionality is in the works (2014 Q3). As of Q3 2014, MicroView has a replacement plugin, called Advanced ROI Tool with much of the original functionality of the \"Advanced ROI\" tool. advanced_bone_app ... What is the format of the ABA xml database format? The Advanced Bone Application xml database format specification is maintained as an xml Document Type Definition file (DTD). The database format specification can be found here .","title":"Frequently Asked Questions"},{"location":"faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"faq/#q-where-can-i-download-the-latest-version-of-microview","text":"The latest version of MicroView can be downloaded here .","title":"Q. Where can I download the latest version of MicroView?"},{"location":"faq/#q-where-can-i-get-source-code-for-microview-and-instructions-on-how-to-build-it","text":"The original source code for MicroView was maintained in cvs, then later, in git on sourceforge . As of 2015, the sourceforge code was archived and development of Microview was moved to github .","title":"Q. Where can I get source code for MicroView and instructions on how to build it?"},{"location":"faq/#q-is-microview-available-for-mac-os-x","text":"Yes. MicroView is supported on recent version of OS X for both 32-bit and 64-bit architectures. Previous generations of MicroView ran on PPC hardware but with the release of 2.5.0+ PPC platforms are no longer supported.","title":"Q. Is MicroView available for Mac OS X?"},{"location":"faq/#q-how-can-i-automatically-threshold-a-loaded-image-in-microview","text":"MicroView can automatically select an optimal threshold value by examining a histogram of pixel values in a user defined region of interest. This value is useful as input to the isosurface, stereology, and volume rendering plugins. To automatically threshold an image, first select a region of interest, using either the ROI plugin or the 7/8 keys. Next, generate a histogram of the pixel values within this region of interest by hitting the g key. Finally, click on the Auto Threshold button on the histogram plot window to automatically determine an optimal threshold. MicroView's automatic thresholding is based upon the \"Otsu\" method.","title":"Q. How can I automatically threshold a loaded image in MicroView?"},{"location":"faq/#q-why-cant-i-export-to-dicom-format","text":"The image export feature gives a list of appropriate file formats, depending on the image depth of the image you've loaded. If, for instance, you have a 16-bit image, only DICOM format will be available. For 8-bit images, different formats will be available, including jpeg, png, gif, etc. To handle the export of 16-bit images to formats such as jpeg, you need to first rescale the images to 8-bit. Under the Process menu, select Image Downsample in order to convert your image from 16-bit to 8-bit, then select Image Export from the File menu.","title":"Q. Why can't I export to DICOM format?"},{"location":"faq/#q-how-do-i-make-movies-in-microview","text":"MicroView has a rudimentary movie making facility , which permits generation of movies. For more complex movie making, there are numerous screen capture applications that can export to e.g. AVI movies. One such utility is CamStudio .","title":"Q. How do I make movies in MicroView?"},{"location":"faq/#q-wheres-the-advanced-roi-tool","text":"This release of MicroView stems from the open-source origins posted on http://microview.sourceforge.net . The so-called \"Advanced ROI\" plugin was a customization provided by GE Healthcare. A replacement plugin with similar functionality is in the works (2014 Q3). As of Q3 2014, MicroView has a replacement plugin, called Advanced ROI Tool with much of the original functionality of the \"Advanced ROI\" tool. advanced_bone_app ... What is the format of the ABA xml database format? The Advanced Bone Application xml database format specification is maintained as an xml Document Type Definition file (DTD). The database format specification can be found here .","title":"Q. Where's the \"Advanced ROI\" tool?"},{"location":"features/","text":"MicroView Features Visualization and quantification of both 2D and 3D image data Generate, view and save isosurfaces Multi-platform environment: Windows (XP SP3/Vista/Win7/Win8/Win10, x86 and x86_64) Linux (x86 and x86_64) Mac OSX (universal binaries; 10.6.6+) GPU-accelerated opacity based volume rendering Surface rendering Multiple-slice viewing, single plane viewing Arbitrary oblique slicing Window / level control of display Multiple file format import and export: Including DICOM, Raw, Analyze, VTK, HFH, MINC, JPEG, TIFF, BMP, PNG formats Reads 8, 16, or 32 bit image files Image Statistics: Mean Standard deviation Quantitative Bone Measurements Bone Mineral Density (BMD) Bone Volume Fraction (BVF) Stereological parameters: Trabecular number, spacing, thickness Connectivity by Euler's number Isotropy Histogram Plotting Profile Line Plotting Line measurement Measurement data export into formatted text for use with spreadsheets and data analysis software Fixed and variable slice increment Volume reorientation / re-alignment Control of data viewing including: Zoom Pan Rotate Sub-volume viewing Registration tools to merge two volumes On-line documentation Open source for easy customization using VTK and ITK","title":"Features"},{"location":"features/#microview-features","text":"Visualization and quantification of both 2D and 3D image data Generate, view and save isosurfaces Multi-platform environment: Windows (XP SP3/Vista/Win7/Win8/Win10, x86 and x86_64) Linux (x86 and x86_64) Mac OSX (universal binaries; 10.6.6+) GPU-accelerated opacity based volume rendering Surface rendering Multiple-slice viewing, single plane viewing Arbitrary oblique slicing Window / level control of display Multiple file format import and export: Including DICOM, Raw, Analyze, VTK, HFH, MINC, JPEG, TIFF, BMP, PNG formats Reads 8, 16, or 32 bit image files Image Statistics: Mean Standard deviation Quantitative Bone Measurements Bone Mineral Density (BMD) Bone Volume Fraction (BVF) Stereological parameters: Trabecular number, spacing, thickness Connectivity by Euler's number Isotropy Histogram Plotting Profile Line Plotting Line measurement Measurement data export into formatted text for use with spreadsheets and data analysis software Fixed and variable slice increment Volume reorientation / re-alignment Control of data viewing including: Zoom Pan Rotate Sub-volume viewing Registration tools to merge two volumes On-line documentation Open source for easy customization using VTK and ITK","title":"MicroView Features"},{"location":"getting-started/","text":"Getting Started This section describes how to download, install, and run MicroView. It will also show you where and how to get help. Download See the Downloads section. Install Launching MicroView Windows Start MicroView by performing one of the following steps: Double-click the icon of any supported image file (such as a vff file), which was associated with MicroView during the installation process, file from within Window's Explorer or any file browser. MicroView will be launched, and the selected image file will be automatically loaded. Run MicroView by selecting it from the system Start menu. Select Start \u2192 Programs \u2192 Parallax Innovations \u2192 MicroView \u2192 MicroView . OS X The MicroView installation process will place a MicroView launcher in the Applications folder of the Finder application. Double-click on the Parallax Innovations icon ( Finder \u2192 Applications \u2192 MicroView ) to start MicroView. Linux When using MicroView under Linux, ensure X11 is installed, and an X session (e.g. KDE, Gnome, LXDE, etc.) has been started. Start MicroView by: Running /opt/PI/MicroView/MicroView from an xterm, or similar console; Selecting Graphics \u2192 MicroView from the system menu (applies to Gnome desktops; KDE menu entries may differ slightly). Getting Help MicroView has context-sensitive help attached to most dialogs and windows, including the main MicroView window. Press F1 , or h at any time to view the MicroView quick-reference guide. Additional MicroView support can be obtained through the MicroView forum , or by email: info@parallax-innovations.com . Bug reports should be directed to MicroView's github site.","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"This section describes how to download, install, and run MicroView. It will also show you where and how to get help.","title":"Getting Started"},{"location":"getting-started/#download","text":"See the Downloads section.","title":"Download"},{"location":"getting-started/#install","text":"","title":"Install"},{"location":"getting-started/#launching-microview","text":"","title":"Launching MicroView"},{"location":"getting-started/#windows","text":"Start MicroView by performing one of the following steps: Double-click the icon of any supported image file (such as a vff file), which was associated with MicroView during the installation process, file from within Window's Explorer or any file browser. MicroView will be launched, and the selected image file will be automatically loaded. Run MicroView by selecting it from the system Start menu. Select Start \u2192 Programs \u2192 Parallax Innovations \u2192 MicroView \u2192 MicroView .","title":"Windows"},{"location":"getting-started/#os-x","text":"The MicroView installation process will place a MicroView launcher in the Applications folder of the Finder application. Double-click on the Parallax Innovations icon ( Finder \u2192 Applications \u2192 MicroView ) to start MicroView.","title":"OS X"},{"location":"getting-started/#linux","text":"When using MicroView under Linux, ensure X11 is installed, and an X session (e.g. KDE, Gnome, LXDE, etc.) has been started. Start MicroView by: Running /opt/PI/MicroView/MicroView from an xterm, or similar console; Selecting Graphics \u2192 MicroView from the system menu (applies to Gnome desktops; KDE menu entries may differ slightly).","title":"Linux"},{"location":"getting-started/#getting-help","text":"MicroView has context-sensitive help attached to most dialogs and windows, including the main MicroView window. Press F1 , or h at any time to view the MicroView quick-reference guide. Additional MicroView support can be obtained through the MicroView forum , or by email: info@parallax-innovations.com . Bug reports should be directed to MicroView's github site.","title":"Getting Help"},{"location":"glossary/","text":"Glossary CSV (Comma-separated value file) : A commonly used text-based spreadsheet format. Many spreadsheets can read and write this file format. CT (Computed Tomography) : The science of generating tomographic x-ray images of an object or subject. DICOM : An acronym for The Digital Imaging and Communications in Medicine standard. The standard was created by the National Electrical Manufacturers Association (NEMA) to aid the distribution and viewing of medical images. HU : Hounsfield Unit. An X-ray attenuation scale commonly used for interpreting CT images. Hydroxylapatite : A crystalline form of calcium found in bone. LUT : Look-up Table. A table that defines the mapping between the gray scale values found in a CT image and the coloration to be displayed for each gray scale value. ROI : Region of Interest. A 2D or 3D region, within an image, used to define the extent of an analysis or computation. Voxel : The 3D analog of a pixel, or picture element. The smallest, box-shaped element in any 3D image.","title":"Glossary"},{"location":"glossary/#glossary","text":"CSV (Comma-separated value file) : A commonly used text-based spreadsheet format. Many spreadsheets can read and write this file format. CT (Computed Tomography) : The science of generating tomographic x-ray images of an object or subject. DICOM : An acronym for The Digital Imaging and Communications in Medicine standard. The standard was created by the National Electrical Manufacturers Association (NEMA) to aid the distribution and viewing of medical images. HU : Hounsfield Unit. An X-ray attenuation scale commonly used for interpreting CT images. Hydroxylapatite : A crystalline form of calcium found in bone. LUT : Look-up Table. A table that defines the mapping between the gray scale values found in a CT image and the coloration to be displayed for each gray scale value. ROI : Region of Interest. A 2D or 3D region, within an image, used to define the extent of an analysis or computation. Voxel : The 3D analog of a pixel, or picture element. The smallest, box-shaped element in any 3D image.","title":"Glossary"},{"location":"interacting-with-microview/","text":"Interacting with MicroView This section describes the elements of how to interact with image display in MicroView. Function Description Window and Level Adjust Window and Level values to control image contrast and brightness. Window and Level values can be modified by using the scrollbars at the bottom of the MicroView window, or by selecting the window/level button on the [interaction palette](screen-layout.md#interaction-palette), then click-and-dragging the left mouse button in any of MicroView's viewports. The behavior and values of the window/level scrollbars can be adjusted by clicking on the Window/Level value display, in the bottom right corner of MicroView's main window. Note Image contrast and brightness can also be controlled by selection of image minimum and maximum values. From MicroView's Application Settings... menu entry <Options> , select the Misc tab, then select Use Min/Max for W/L control. Once selected, Window and Level scrollbars will be replaced by Min and Max scrollbars. Image Rotate (3D) Move the mouse in the 3D viewport while clicking the left mouse button to rotate the image. By default, the image will rotate about its center, while the mouse is dragged. However, clicking and dragging the left mouse button in the bottom portion of the 3D viewport will cause the image to rotate about an axis parallel to the viewing direction. Image Pan Click and drag the left mouse button, while pressing one of the Shift keys to pan the image up, down, left or right. Image Slice (3D) Move the mouse over the center region of a slice plane. Drag the mouse, while pressing the middle mouse button to interactively slice through the image. Press the Up or Down Arrow key while the mouse is positioned over the center region of a slice plane in order to move the slice forwards or backwards in the image by one slice. Press the PgUp or PgDn key while the mouse is positioned over the center region of a slice plane in order to move the slice forwards or backwards in the image by ten slices. Press the Home and End keys to select the first and last image slice, respectively. Image Slice Orientation (3D) Position the mouse within the 3D viewport, on the edge, or corner of an image slice. Press the middle mouse button and drag the mouse up and down or left and right to rotate the orientation of the three slice planes within the image. When a corner is picked, the plane border color will change to red and the plane will rotate around the plane normal. When an edge is picked, the plane border color will change to cyan and the plane will rotate around the plane center line that parallels to the picked edge. Image Zoom Click and drag the right mousebutton up or down, to zoom in or out, respectively, on the image. Maximize Viewport Double-click the left mouse button while the mouse is positioned within any of MicroView's four viewports to view only the selected viewport. MicroView will expand the selected viewport to occupy the entire working space of the MicroView window. Double-click on the viewport again to restore the original screen layout. Reset all Viewports Press the r key to restore slice selection and view orientation to their original settings. Center Slice Intersection Click the left mouse button, while pressing the Ctrl key over the image, in any viewport. The intersection of the three image slices will move to the current location selected by the mouse position.","title":"Interacting with MicroView"},{"location":"interacting-with-microview/#interacting-with-microview","text":"This section describes the elements of how to interact with image display in MicroView. Function Description Window and Level Adjust Window and Level values to control image contrast and brightness. Window and Level values can be modified by using the scrollbars at the bottom of the MicroView window, or by selecting the window/level button on the [interaction palette](screen-layout.md#interaction-palette), then click-and-dragging the left mouse button in any of MicroView's viewports. The behavior and values of the window/level scrollbars can be adjusted by clicking on the Window/Level value display, in the bottom right corner of MicroView's main window. Note Image contrast and brightness can also be controlled by selection of image minimum and maximum values. From MicroView's Application Settings... menu entry <Options> , select the Misc tab, then select Use Min/Max for W/L control. Once selected, Window and Level scrollbars will be replaced by Min and Max scrollbars. Image Rotate (3D) Move the mouse in the 3D viewport while clicking the left mouse button to rotate the image. By default, the image will rotate about its center, while the mouse is dragged. However, clicking and dragging the left mouse button in the bottom portion of the 3D viewport will cause the image to rotate about an axis parallel to the viewing direction. Image Pan Click and drag the left mouse button, while pressing one of the Shift keys to pan the image up, down, left or right. Image Slice (3D) Move the mouse over the center region of a slice plane. Drag the mouse, while pressing the middle mouse button to interactively slice through the image. Press the Up or Down Arrow key while the mouse is positioned over the center region of a slice plane in order to move the slice forwards or backwards in the image by one slice. Press the PgUp or PgDn key while the mouse is positioned over the center region of a slice plane in order to move the slice forwards or backwards in the image by ten slices. Press the Home and End keys to select the first and last image slice, respectively. Image Slice Orientation (3D) Position the mouse within the 3D viewport, on the edge, or corner of an image slice. Press the middle mouse button and drag the mouse up and down or left and right to rotate the orientation of the three slice planes within the image. When a corner is picked, the plane border color will change to red and the plane will rotate around the plane normal. When an edge is picked, the plane border color will change to cyan and the plane will rotate around the plane center line that parallels to the picked edge. Image Zoom Click and drag the right mousebutton up or down, to zoom in or out, respectively, on the image. Maximize Viewport Double-click the left mouse button while the mouse is positioned within any of MicroView's four viewports to view only the selected viewport. MicroView will expand the selected viewport to occupy the entire working space of the MicroView window. Double-click on the viewport again to restore the original screen layout. Reset all Viewports Press the r key to restore slice selection and view orientation to their original settings. Center Slice Intersection Click the left mouse button, while pressing the Ctrl key over the image, in any viewport. The intersection of the three image slices will move to the current location selected by the mouse position.","title":"Interacting with MicroView"},{"location":"microview-options/","text":"MicroView Application Settings This section describes application settings in MicroView. Overview Select Edit \u2192 Application Settings... from MicroView's menu, to change most of MicroView's display options. Pop-up help is available for all options, simply by holding the mouse still over an option for a few seconds. Many of the options have corresponding keyboard shortcuts, which are displayed in square brackets to the right of the option. A description of each option is listed below, along with a table of corresponding keyboard shortcuts, where available. Option Descriptions Display Show Intersection Lines [e] - Toggles the visibility of axes lines. X, Y and Z axes are displayed in red, green and blue, respectively. Show Plane Borders [f] - Toggles the visibility of the border around each image plane in both 3D and 2D viewports. Set Gray Background [l] - Toggles the display background color between black and medium gray. Show Axes Labels [o] - Toggles the display of the '+X', '-X', '+Y', '-Y', '+Z' and '-Z' axes labels in the 3D viewport. Show Axial Plane [k] - Toggles the display of the z-plane image. Show Coronal Plane [j] - Toggles the display of the y-plane image. Show Sagittal Plane [i] - Toggles the display of the x-plane image. Show Volume Outline - Toggles the display of the yellow border surrounding the full extent of the image in the 3D viewport. Highlight Label [x] - Toggles highlighting of all annotations visible on the 3D viewports. For some images turning on label highlighting will make annotations easier to read. Use Image Interpolation - If enabled, MicroView uses bilinear interpolation when displaying image data. When disabled, nearest neighbor interpolation is used instead. Misc. Show measurements in mm - When enabled, line and position measurements are made in millimeters. If disabled, or if not available for a particular image, measurements are made in pixels. Enable Integer Stepping - If enabled, MicroView will prevent the display of bilinearly interpolated slices between actual data slices. Use Min/Max for W/L control - If enabled, image contrast and brightness are controlled by selecting minimum and maximum image values to view. Values below the minimum will be set to black, values above the maximum will be set to white. If disabled, window and level settings are used instead. Update W/L Immediately - For slow displays, toggle this option off to have brightness and contrast adjustments take affect only when the mouse button is released, after dragging the window or level scrollbars. If enabled, window/level values will be updated immediately. Display Splash at Startup - If disabled, MicroView will avoid displaying a splash screen at program start up. Enable balloon help - If enabled, MicroView will display pop-up help text over all dialog controls and pop-up boxes when the mouse is stationary for a few seconds.","title":"MicroView Application Settings"},{"location":"microview-options/#microview-application-settings","text":"This section describes application settings in MicroView.","title":"MicroView Application Settings"},{"location":"microview-options/#overview","text":"Select Edit \u2192 Application Settings... from MicroView's menu, to change most of MicroView's display options. Pop-up help is available for all options, simply by holding the mouse still over an option for a few seconds. Many of the options have corresponding keyboard shortcuts, which are displayed in square brackets to the right of the option. A description of each option is listed below, along with a table of corresponding keyboard shortcuts, where available.","title":"Overview"},{"location":"microview-options/#option-descriptions","text":"","title":"Option Descriptions"},{"location":"microview-options/#display","text":"Show Intersection Lines [e] - Toggles the visibility of axes lines. X, Y and Z axes are displayed in red, green and blue, respectively. Show Plane Borders [f] - Toggles the visibility of the border around each image plane in both 3D and 2D viewports. Set Gray Background [l] - Toggles the display background color between black and medium gray. Show Axes Labels [o] - Toggles the display of the '+X', '-X', '+Y', '-Y', '+Z' and '-Z' axes labels in the 3D viewport. Show Axial Plane [k] - Toggles the display of the z-plane image. Show Coronal Plane [j] - Toggles the display of the y-plane image. Show Sagittal Plane [i] - Toggles the display of the x-plane image. Show Volume Outline - Toggles the display of the yellow border surrounding the full extent of the image in the 3D viewport. Highlight Label [x] - Toggles highlighting of all annotations visible on the 3D viewports. For some images turning on label highlighting will make annotations easier to read. Use Image Interpolation - If enabled, MicroView uses bilinear interpolation when displaying image data. When disabled, nearest neighbor interpolation is used instead.","title":"Display"},{"location":"microview-options/#misc","text":"Show measurements in mm - When enabled, line and position measurements are made in millimeters. If disabled, or if not available for a particular image, measurements are made in pixels. Enable Integer Stepping - If enabled, MicroView will prevent the display of bilinearly interpolated slices between actual data slices. Use Min/Max for W/L control - If enabled, image contrast and brightness are controlled by selecting minimum and maximum image values to view. Values below the minimum will be set to black, values above the maximum will be set to white. If disabled, window and level settings are used instead. Update W/L Immediately - For slow displays, toggle this option off to have brightness and contrast adjustments take affect only when the mouse button is released, after dragging the window or level scrollbars. If enabled, window/level values will be updated immediately. Display Splash at Startup - If disabled, MicroView will avoid displaying a splash screen at program start up. Enable balloon help - If enabled, MicroView will display pop-up help text over all dialog controls and pop-up boxes when the mouse is stationary for a few seconds.","title":"Misc."},{"location":"overview/","text":"Overview MicroView is an advanced 3D image viewer and analysis platform capable of reading and writing a wide variety of 2D and 3D image formats . It is often used for biomedical imaging tasks and has a specific focus on microCT image analysis. Quick Links Downloads Changelog Release Notes","title":"Overview"},{"location":"overview/#overview","text":"MicroView is an advanced 3D image viewer and analysis platform capable of reading and writing a wide variety of 2D and 3D image formats . It is often used for biomedical imaging tasks and has a specific focus on microCT image analysis.","title":"Overview"},{"location":"overview/#quick-links","text":"Downloads Changelog Release Notes","title":"Quick Links"},{"location":"playground/","text":"Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. import tensorflow as tf \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \\frac{n!}{k!(n-k)!} = \\binom{n}{k} Ctrl + Alt + Del .demo-card-event.mdl-card { width: 256px; height: 256px; background: #3E4EB8; } .demo-card-event > .mdl-card__actions { border-color: rgba(255, 255, 255, 0.2); } .demo-card-event > .mdl-card__title { align-items: flex-start; } .demo-card-event > .mdl-card__title > h4 { margin-top: 0; } .demo-card-event > .mdl-card__actions { display: flex; box-sizing:border-box; align-items: center; } .demo-card-event > .mdl-card__actions > .material-icons { padding-right: 10px; } .demo-card-event > .mdl-card__title, .demo-card-event > .mdl-card__actions, .demo-card-event > .mdl-card__actions > .mdl-button { color: #fff; } Featured event: May 24, 2016 7-11pm Add to Calendar event","title":"Playground"},{"location":"reading-and-writing-files/","text":"Reading and Writing Image Files This section describes basic reading and writing methods in MicroView. Overview MicroView supports a number of 2D and 3D file formats, both for image data, as well as surface geometry formats. A distinction is made between reading/writing image data and importing/exporting image data. This distinction is reflected in the entries listed in MicroView's File menu. File reading and writing reads and writes precisely one file per operation (for instance, one might read a vff image, then save it to a different filename in a different format). File import and export operations are used to read and write, respectively, a sequence of 2D images. Image import is useful for loading a sequence of 2D images into a stacked 3D image. Image export is useful for splitting a 3D image up into a sequence of 2D slices. Not all image formats supported in MicroView are available for all tasks: For instance, while exporting a 3D VFF image to a sequence of TIFF images is available, saving a 3D VFF image to TIFF format is not, since there is no 3D TIFF image format defined. MicroView supports images in various bit depths, ranging from 8-bit to 32-bit formats. Not all file formats are available for image writing and image exporting, depending on the limitations of the individual format. Often, it is convenient to downsample image data to 8-bit, in order to maximize the number of file formats available. MicroView supports images with varying numbers of channels in them. Both single channel (e.g. grayscale images) as well as multichannel (e.g. RGBA images) are supported. Currently, multichannel images are exclusively interpreted as RGB images. The complete list of supported file formats is available in Appendix A of this document. Loading an Image Select File \u2192 Open... from MicroView's menu. Enter a filename, or locate a file in the file selector that appears on the screen. Saving an Image Select File \u2192 Save As... from MicroView's menu to save an image. Select the desired output image type in the drop down selector at the bottom of file selector dialog and enter a filename for the new image. Saving a Screen Snapshot Position the mouse over any 2D viewport, or the main 3D viewport, and press the t key to save a snapshot of the viewport to an image file. Select a filename and filetype, then hit OK to save the file. Importing 2D image slices MicroView is capable of importing a sequence of 2D images, in a variety of common image formats , and assembling them into a 3D image. In order to accomplish this, each 2D image file must be named with a monotonically increasing ordinal. Select File \u2192 Image Import... from MicroView's menu. Enter a filename template, in the format import-####.png , where \"#\" denotes characters that will be automatically replaced by index numbers. The Browse button to the right of the template filename box can be used to select a file from a file browser. Hit the Examine button to permit MicroView to examine metadata for all images found in the selected folder. Enter the first index number and last index number in the appropriate entry boxes (e.g. if the template is chosen to be \"import-##.gif\" and first and last numbers are set to be 3 and 7, respectively, MicroView will attempt to load import-03.gif , import-04.gif ... import-07.gif ). Enter the spacing between image slices, in millimeters. Finally, press the OK button to import the sequence of images. Importing Raw Images MicroView can also import raw data in a variety of forms. Start by clicking the Raw Image button to display additional image import options. Specify the offset from the beginning of each file to the raw image data (in case an image header is present), the data type, byte ordering (for 16-bit image data) and the dimensions of the raw image data. Note MicroView can also import a single 3D raw image, if the 3D Image checkbox is checked. Instead of entering a sequence of file names, specify the entire filename, and enter x, y and z axis dimensions. Exporting 2D image slices Select File \u2192 Image Export... from MicroView's menu. Choose an image format from the list provided. The list will vary depending on the image depth of the image you are saving. Next, select an output directory to write the image slice sequence into. MicroView will automatically write image slices to filenames with an extension that depends on the file format that you select, and a prefix of \"export-\" (e.g. export-0001.gif , ...).","title":"Reading and Writing Image Files"},{"location":"reading-and-writing-files/#reading-and-writing-image-files","text":"This section describes basic reading and writing methods in MicroView.","title":"Reading and Writing Image Files"},{"location":"reading-and-writing-files/#overview","text":"MicroView supports a number of 2D and 3D file formats, both for image data, as well as surface geometry formats. A distinction is made between reading/writing image data and importing/exporting image data. This distinction is reflected in the entries listed in MicroView's File menu. File reading and writing reads and writes precisely one file per operation (for instance, one might read a vff image, then save it to a different filename in a different format). File import and export operations are used to read and write, respectively, a sequence of 2D images. Image import is useful for loading a sequence of 2D images into a stacked 3D image. Image export is useful for splitting a 3D image up into a sequence of 2D slices. Not all image formats supported in MicroView are available for all tasks: For instance, while exporting a 3D VFF image to a sequence of TIFF images is available, saving a 3D VFF image to TIFF format is not, since there is no 3D TIFF image format defined. MicroView supports images in various bit depths, ranging from 8-bit to 32-bit formats. Not all file formats are available for image writing and image exporting, depending on the limitations of the individual format. Often, it is convenient to downsample image data to 8-bit, in order to maximize the number of file formats available. MicroView supports images with varying numbers of channels in them. Both single channel (e.g. grayscale images) as well as multichannel (e.g. RGBA images) are supported. Currently, multichannel images are exclusively interpreted as RGB images. The complete list of supported file formats is available in Appendix A of this document.","title":"Overview"},{"location":"reading-and-writing-files/#loading-an-image","text":"Select File \u2192 Open... from MicroView's menu. Enter a filename, or locate a file in the file selector that appears on the screen.","title":"Loading an Image"},{"location":"reading-and-writing-files/#saving-an-image","text":"Select File \u2192 Save As... from MicroView's menu to save an image. Select the desired output image type in the drop down selector at the bottom of file selector dialog and enter a filename for the new image.","title":"Saving an Image"},{"location":"reading-and-writing-files/#saving-a-screen-snapshot","text":"Position the mouse over any 2D viewport, or the main 3D viewport, and press the t key to save a snapshot of the viewport to an image file. Select a filename and filetype, then hit OK to save the file.","title":"Saving a Screen Snapshot"},{"location":"reading-and-writing-files/#importing-2d-image-slices","text":"MicroView is capable of importing a sequence of 2D images, in a variety of common image formats , and assembling them into a 3D image. In order to accomplish this, each 2D image file must be named with a monotonically increasing ordinal. Select File \u2192 Image Import... from MicroView's menu. Enter a filename template, in the format import-####.png , where \"#\" denotes characters that will be automatically replaced by index numbers. The Browse button to the right of the template filename box can be used to select a file from a file browser. Hit the Examine button to permit MicroView to examine metadata for all images found in the selected folder. Enter the first index number and last index number in the appropriate entry boxes (e.g. if the template is chosen to be \"import-##.gif\" and first and last numbers are set to be 3 and 7, respectively, MicroView will attempt to load import-03.gif , import-04.gif ... import-07.gif ). Enter the spacing between image slices, in millimeters. Finally, press the OK button to import the sequence of images.","title":"Importing 2D image slices"},{"location":"reading-and-writing-files/#importing-raw-images","text":"MicroView can also import raw data in a variety of forms. Start by clicking the Raw Image button to display additional image import options. Specify the offset from the beginning of each file to the raw image data (in case an image header is present), the data type, byte ordering (for 16-bit image data) and the dimensions of the raw image data. Note MicroView can also import a single 3D raw image, if the 3D Image checkbox is checked. Instead of entering a sequence of file names, specify the entire filename, and enter x, y and z axis dimensions.","title":"Importing Raw Images"},{"location":"reading-and-writing-files/#exporting-2d-image-slices","text":"Select File \u2192 Image Export... from MicroView's menu. Choose an image format from the list provided. The list will vary depending on the image depth of the image you are saving. Next, select an output directory to write the image slice sequence into. MicroView will automatically write image slices to filenames with an extension that depends on the file format that you select, and a prefix of \"export-\" (e.g. export-0001.gif , ...).","title":"Exporting 2D image slices"},{"location":"release-notes-2.5/","text":"MicroView 2.5.0 Release Notes General Notes MicroView 2.5.0 represents a major release unlike any in the history of the software: the underlying platform has been modernized and all software dependencies have been ported to recent releases. MicroView has been ported from VTK 4.4 to 5.10, which provides it with a more stable and capable visualization framework. A completely new user interface, based on wxWidgets , has been written which permits the software to be ported to a wide variety of platforms and uses native widgets in place of the custom Motif-style Tkinter widgets used in previous releases. Under the hood, all images are treated as DICOM objects, which facilitates maintaining image meta data between different image formats in a much better fashion. With compatible hardware, MicroView will begin to leverage GPU-acceleration in a variety of places, most visible with volume rendering. New Features Multi-image support : Multiple images can be loaded into separate viewer tabs in MicroView, simultaneously. Tabs can be arranged on the screen side-by-side to facilitate image comparison and image registration. Tabs can be cloned, to permit side-by-side comparison and analysis of the same image without incurring additional memory overhead. New image formats : MicroView 2.5.0 adds support for Jpeg2000, FITS, Nifti, ISQ, VTK Metafile, BioRad, Drishti, VG Studio Max export format, VOX, WEBP and more. It also radically improves support for DICOM (including DICOMDIR), as well as Analyze, and MINC. A full list of supported file formats can be found in File formats . New filters : MicroView 2.5.0 supports a wider collection of common filters, including: minium, maximum, and median filters. It also includes a variety of static and adaptive thresholding and morphological operators. A simplified scripting interface : Third-party scripts can be writte in python to perform simple tasks. Each script is passed a numpy array linking to the currently selected image and some simple meta data - scripts simply make changes to the image array and return results. New plugins : MicroView 2.5.0 adds a variety of new plugins including: CT Toolbox: A replacement plugin for the original GE CT Calibration tool. This plugin contains a variety of useful tools for CT image analysis Reconstruct: A basic front-end to the Parallax Innovations GPU reconstruction tools. This plugin allows you to monitor reconstruction progress on reconstruction compute engines Point-picker: A new plugin that mimics a similar tool in GE's Analysis+ version of MicroView. Useful for recording, measuring and manipulating fiducial markers on an image. Serial-ROI: A replacement plugin for the original GE 'Advanced ROI' tool. This plugin closely mimics the look-and-feel of it's predecessor but lacks some of the more advanced features of the original plugin. Flood-fill Region Grow: A new plugin that mimics GE's original region growing plugin, but with a number of additional features. Camera Info: Shows camera transform info as well as cut plane information. Can load and save both camera and image slice orientation information. Shell: Perhaps the most powerful tool in MicroView: MicroView 2.5.0 now has an interactive shell, which allows access to loaded images as 3D image arrays. A variety of open-source packages can be directly used on images including Numpy and Scipy . Plugin Improvements : The standard ROI plugin gains spherical ROI support as well as the ability to rotate ROI primitives The image information plugin now displays DICOM tags for all image types The DICOM transfer plugin has been rewritten to natively support DICOM network transfers, rather than relying on 3 rd party tools. It will automatically detect Osirix workstations as well as the Parallax Image Bank . The Render volume plugin has been rewritten from the ground up, and now supports GPU-accelerated rendering The Geometry manager has been rewritten to support a larger variety of datatypes. Unstructured grids, vector fields and surfaces can now be viewed, with a wider range of viewing options. The movie maker plugin has been rewritten to use OpenCV on all platforms. It has been extended to support combining multiple basic sequences together, thus enabling more complicated movie generation. Supported Platforms Windows MicroView is now supported on 32-bit and 64-bit Windows (XP/Vista/Win7/Win8) platforms. Versions of Windows prior to Windows XP are no longer supported. Linux MicroView is now supported on Centos, Fedora and Ubuntu platforms. Binary installers are available that target each platform's long-term support releases for a minimum of one support cycle. For example, MicroView Ubuntu binaries are currently available for Ubuntu 18.04 LTS (Bionic Beaver) and Ubuntu 16.04 LTS (Xenial Xerus). Mac OS X MicroView is now supported on 64-bit Intel Mac platforms, starting with OS X 10.8. PPC platforms will no longer be supported.","title":"MicroView 2.5.0 Release Notes"},{"location":"release-notes-2.5/#microview-250-release-notes","text":"","title":"MicroView 2.5.0 Release Notes"},{"location":"release-notes-2.5/#general-notes","text":"MicroView 2.5.0 represents a major release unlike any in the history of the software: the underlying platform has been modernized and all software dependencies have been ported to recent releases. MicroView has been ported from VTK 4.4 to 5.10, which provides it with a more stable and capable visualization framework. A completely new user interface, based on wxWidgets , has been written which permits the software to be ported to a wide variety of platforms and uses native widgets in place of the custom Motif-style Tkinter widgets used in previous releases. Under the hood, all images are treated as DICOM objects, which facilitates maintaining image meta data between different image formats in a much better fashion. With compatible hardware, MicroView will begin to leverage GPU-acceleration in a variety of places, most visible with volume rendering.","title":"General Notes"},{"location":"release-notes-2.5/#new-features","text":"Multi-image support : Multiple images can be loaded into separate viewer tabs in MicroView, simultaneously. Tabs can be arranged on the screen side-by-side to facilitate image comparison and image registration. Tabs can be cloned, to permit side-by-side comparison and analysis of the same image without incurring additional memory overhead. New image formats : MicroView 2.5.0 adds support for Jpeg2000, FITS, Nifti, ISQ, VTK Metafile, BioRad, Drishti, VG Studio Max export format, VOX, WEBP and more. It also radically improves support for DICOM (including DICOMDIR), as well as Analyze, and MINC. A full list of supported file formats can be found in File formats . New filters : MicroView 2.5.0 supports a wider collection of common filters, including: minium, maximum, and median filters. It also includes a variety of static and adaptive thresholding and morphological operators. A simplified scripting interface : Third-party scripts can be writte in python to perform simple tasks. Each script is passed a numpy array linking to the currently selected image and some simple meta data - scripts simply make changes to the image array and return results. New plugins : MicroView 2.5.0 adds a variety of new plugins including: CT Toolbox: A replacement plugin for the original GE CT Calibration tool. This plugin contains a variety of useful tools for CT image analysis Reconstruct: A basic front-end to the Parallax Innovations GPU reconstruction tools. This plugin allows you to monitor reconstruction progress on reconstruction compute engines Point-picker: A new plugin that mimics a similar tool in GE's Analysis+ version of MicroView. Useful for recording, measuring and manipulating fiducial markers on an image. Serial-ROI: A replacement plugin for the original GE 'Advanced ROI' tool. This plugin closely mimics the look-and-feel of it's predecessor but lacks some of the more advanced features of the original plugin. Flood-fill Region Grow: A new plugin that mimics GE's original region growing plugin, but with a number of additional features. Camera Info: Shows camera transform info as well as cut plane information. Can load and save both camera and image slice orientation information. Shell: Perhaps the most powerful tool in MicroView: MicroView 2.5.0 now has an interactive shell, which allows access to loaded images as 3D image arrays. A variety of open-source packages can be directly used on images including Numpy and Scipy . Plugin Improvements : The standard ROI plugin gains spherical ROI support as well as the ability to rotate ROI primitives The image information plugin now displays DICOM tags for all image types The DICOM transfer plugin has been rewritten to natively support DICOM network transfers, rather than relying on 3 rd party tools. It will automatically detect Osirix workstations as well as the Parallax Image Bank . The Render volume plugin has been rewritten from the ground up, and now supports GPU-accelerated rendering The Geometry manager has been rewritten to support a larger variety of datatypes. Unstructured grids, vector fields and surfaces can now be viewed, with a wider range of viewing options. The movie maker plugin has been rewritten to use OpenCV on all platforms. It has been extended to support combining multiple basic sequences together, thus enabling more complicated movie generation.","title":"New Features"},{"location":"release-notes-2.5/#supported-platforms","text":"","title":"Supported Platforms"},{"location":"release-notes-2.5/#windows","text":"MicroView is now supported on 32-bit and 64-bit Windows (XP/Vista/Win7/Win8) platforms. Versions of Windows prior to Windows XP are no longer supported.","title":"Windows"},{"location":"release-notes-2.5/#linux","text":"MicroView is now supported on Centos, Fedora and Ubuntu platforms. Binary installers are available that target each platform's long-term support releases for a minimum of one support cycle. For example, MicroView Ubuntu binaries are currently available for Ubuntu 18.04 LTS (Bionic Beaver) and Ubuntu 16.04 LTS (Xenial Xerus).","title":"Linux"},{"location":"release-notes-2.5/#mac-os-x","text":"MicroView is now supported on 64-bit Intel Mac platforms, starting with OS X 10.8. PPC platforms will no longer be supported.","title":"Mac OS X"},{"location":"report-generation/","text":"","title":"Report Generation"},{"location":"requirements/","text":"System Requirements MicroView is compatible with most common desktop environments including OS X, Windows and Linux. The sections below describe computer requirements necessary to run MicroView on each supported platform. Windows For Windows computers, the suggested minimum requirement is: an Intel i5 processor or equivalent 1 GB RAM (4 GB recommended) Windows 7 or newer (Windows XP no longer supported) a 3D-accelerated video card with 512 MB of texture memory (1 GB recommended) 550 MB of available hard disk space SVGA monitor and graphics capabilities (1280x1024 resolution, or higher, recommended) The actual memory requirements will depend on the size of image loaded into MicroView, and the operations performed on the image once it is loaded. Some operations require up to 5X the memory of the original file size, so plan accordingly. Under 32-bit Windows (XP/Vista/Win7), the maximum file size that can be loaded is 854 MB, so roughly 1-2 GB of RAM is recommended for normal use. See this note for additional information on how to improve MicroView memory performance under Windows XP. For 64-bit version of MicroView, maximum image size is limited by the amount of system RAM and graphics texture memory. OS X For Macintosh computers, MicroView requires a minimum of: a 64-bit Intel-based Mac computer (PPC support has been discontinued with this release) 1 GB RAM (2 GB recommended) OS X 10.6.6 or newer a 3D-accelerated video card with 512 MB of texture memory (1 GB recommended) 550 MB of available hard disk space SVGA monitor and graphics capabilities (1280x1024 resolution, or higher, recommended) Linux For Linux computers, MicroView's computer and memory requirements are identical to the Windows requirements, listed above.","title":"System Requirements"},{"location":"requirements/#system-requirements","text":"MicroView is compatible with most common desktop environments including OS X, Windows and Linux. The sections below describe computer requirements necessary to run MicroView on each supported platform.","title":"System Requirements"},{"location":"requirements/#windows","text":"For Windows computers, the suggested minimum requirement is: an Intel i5 processor or equivalent 1 GB RAM (4 GB recommended) Windows 7 or newer (Windows XP no longer supported) a 3D-accelerated video card with 512 MB of texture memory (1 GB recommended) 550 MB of available hard disk space SVGA monitor and graphics capabilities (1280x1024 resolution, or higher, recommended) The actual memory requirements will depend on the size of image loaded into MicroView, and the operations performed on the image once it is loaded. Some operations require up to 5X the memory of the original file size, so plan accordingly. Under 32-bit Windows (XP/Vista/Win7), the maximum file size that can be loaded is 854 MB, so roughly 1-2 GB of RAM is recommended for normal use. See this note for additional information on how to improve MicroView memory performance under Windows XP. For 64-bit version of MicroView, maximum image size is limited by the amount of system RAM and graphics texture memory.","title":"Windows"},{"location":"requirements/#os-x","text":"For Macintosh computers, MicroView requires a minimum of: a 64-bit Intel-based Mac computer (PPC support has been discontinued with this release) 1 GB RAM (2 GB recommended) OS X 10.6.6 or newer a 3D-accelerated video card with 512 MB of texture memory (1 GB recommended) 550 MB of available hard disk space SVGA monitor and graphics capabilities (1280x1024 resolution, or higher, recommended)","title":"OS X"},{"location":"requirements/#linux","text":"For Linux computers, MicroView's computer and memory requirements are identical to the Windows requirements, listed above.","title":"Linux"},{"location":"roi-management/","text":"Managing 2D and 3D Regions of Interest (ROI) This sections describes how to use ROIs to limit visualization and analysis to specific portions of an image. Overview For many operations in MicroView, the starting point is the selection of a 2D or 3D region of interest (ROI). ROIs define the portion of the volume to be analyzed. For instance, an ROI can be created around a feature in an image in order to compute the mean and standard deviation of just that feature. The active ROI in MicroView is typically displayed in yellow to differentiate it from other surfaces and voxel highlight tools. The ROI may appear as a transparent yellow surface, or as a grouping of yellow voxels in the displayed image plane, depending on the tool used to generate the ROI. Currently, there are six tools that can be used to generate an ROI: The Standard ROI Tool - The 7 and 8 , or alternatively Alt + 7 and Alt + 8 keys can be used to quickly define a rectangular ROI. You can use the \"Standard ROI\" menu button for greater control over the size and location of the ROI. The Histogram Plot Tool - This tool is used to plot histogram values of voxels contained within the active ROI, but can itself be used to select a range of voxels, by graylevel value, to serve as an ROI. The Advanced ROI Tool - This tool is used to define more generic regions of interest. For instance, spline-fitted surfaces can be defined using this tool. This tool also provides a deformable-model based shrink-wrapping application. The Region Grow Tool - Use this tool to define an ROI based on connected voxels with similar gray-level values. Connected voxels can be grouped together using one of three rules: all voxels with gray-level values greater than a user-defined threshold, all voxels with gray level values lower than a user-defined threshold, or all voxels with gray level values within a range of values centered on a user-defined threshold. While used to select an ROI, the tool can itself operate within the confines of a pre-existing ROI, or can be applied to the whole image. The Advanced Region Grow Tool - Use this tool to define an ROI based on connected voxels with similar gray-level values. Connected voxels can be grouped together using one of three rules: all voxels with gray-level values greater than a user-defined threshold, all voxels with gray level values lower than a user-defined threshold, or all voxels with gray level values within a range of values centered on a user-defined threshold. While used to select an ROI, the tool can itself operate within the confines of a pre-existing ROI, or can be applied to the whole image. This tool provides more control for the user over the growth of the selected region. This includes controling the number of iterations of growth, along with the smoothness of the surface of the ROI selected. The Cortical Bone ROI Tool - When applied to a CT image of a bone, this tool can be used to select an ROI corresponding either to the cortical shell or the internal trabecular space of the bone. The tool uses a series of morphological operators to semi-automatically select cortical bone components. A gray-level threshold value, and two scaling size parameters may be tuned in order to improve the accuracy of this ROI tool. The ROI Manager Tool - This tool replaces and enhances the functionality of the Overlay Geometry tool by enabling MicroView to store and manipulate more than one ROI in memory. File operations, combinations of multiple ROI and manipulation of the display characteristics are possible. Once an ROI has been defined, a number of operations may be performed, including: Image Blanking - Use the Del and Shift + Del to cut voxels inside, or outside of the given ROI, respectively. Select the value to fill in the appropriate region by selecting Process \u2192 ROI Blanking \u2192 Set Background Value from MicroView's menu. Simple and Advanced Analysis","title":"Managing 2D and 3D Regions of Interest (ROI)"},{"location":"roi-management/#managing-2d-and-3d-regions-of-interest-roi","text":"This sections describes how to use ROIs to limit visualization and analysis to specific portions of an image.","title":"Managing 2D and 3D Regions of Interest (ROI)"},{"location":"roi-management/#overview","text":"For many operations in MicroView, the starting point is the selection of a 2D or 3D region of interest (ROI). ROIs define the portion of the volume to be analyzed. For instance, an ROI can be created around a feature in an image in order to compute the mean and standard deviation of just that feature. The active ROI in MicroView is typically displayed in yellow to differentiate it from other surfaces and voxel highlight tools. The ROI may appear as a transparent yellow surface, or as a grouping of yellow voxels in the displayed image plane, depending on the tool used to generate the ROI. Currently, there are six tools that can be used to generate an ROI: The Standard ROI Tool - The 7 and 8 , or alternatively Alt + 7 and Alt + 8 keys can be used to quickly define a rectangular ROI. You can use the \"Standard ROI\" menu button for greater control over the size and location of the ROI. The Histogram Plot Tool - This tool is used to plot histogram values of voxels contained within the active ROI, but can itself be used to select a range of voxels, by graylevel value, to serve as an ROI. The Advanced ROI Tool - This tool is used to define more generic regions of interest. For instance, spline-fitted surfaces can be defined using this tool. This tool also provides a deformable-model based shrink-wrapping application. The Region Grow Tool - Use this tool to define an ROI based on connected voxels with similar gray-level values. Connected voxels can be grouped together using one of three rules: all voxels with gray-level values greater than a user-defined threshold, all voxels with gray level values lower than a user-defined threshold, or all voxels with gray level values within a range of values centered on a user-defined threshold. While used to select an ROI, the tool can itself operate within the confines of a pre-existing ROI, or can be applied to the whole image. The Advanced Region Grow Tool - Use this tool to define an ROI based on connected voxels with similar gray-level values. Connected voxels can be grouped together using one of three rules: all voxels with gray-level values greater than a user-defined threshold, all voxels with gray level values lower than a user-defined threshold, or all voxels with gray level values within a range of values centered on a user-defined threshold. While used to select an ROI, the tool can itself operate within the confines of a pre-existing ROI, or can be applied to the whole image. This tool provides more control for the user over the growth of the selected region. This includes controling the number of iterations of growth, along with the smoothness of the surface of the ROI selected. The Cortical Bone ROI Tool - When applied to a CT image of a bone, this tool can be used to select an ROI corresponding either to the cortical shell or the internal trabecular space of the bone. The tool uses a series of morphological operators to semi-automatically select cortical bone components. A gray-level threshold value, and two scaling size parameters may be tuned in order to improve the accuracy of this ROI tool. The ROI Manager Tool - This tool replaces and enhances the functionality of the Overlay Geometry tool by enabling MicroView to store and manipulate more than one ROI in memory. File operations, combinations of multiple ROI and manipulation of the display characteristics are possible. Once an ROI has been defined, a number of operations may be performed, including: Image Blanking - Use the Del and Shift + Del to cut voxels inside, or outside of the given ROI, respectively. Select the value to fill in the appropriate region by selecting Process \u2192 ROI Blanking \u2192 Set Background Value from MicroView's menu. Simple and Advanced Analysis","title":"Overview"},{"location":"screen-layout/","text":"Screen Layout This section describes the basic screen layout of the MicroView application and some of it's visual cues. Overview By default, the MicroView display consists of an application toolbar on the far left side of the screen, and one or more viewer windows contained within a notebook on the right side of the screen. Each viewer window contains a 3D image viewport in the center-left of the window, and a column of three 2D viewports on the right side of each window. MicroView also contains a menu at the top of the application window, Window and Level adjustment scrollbars at the bottom and status and progress indicators at the extreme bottom of the window. It contains image-specific tools in the upper right corner of each notebook page and context-sensitive menus in a variety of locations. Finally, it contains an interaction palette just above the status bar, that contains buttons to toggle the behavior of mouse clicks and mouse motion in MicroView. Modifying the Layout Viewports Each viewport in MicroView can be individually maximized by double-clicking the left mouse button over the viewport. When in the maximized state, the display can be restored by double-clicking the left mouse button while continuing to position the mouse over the viewport. The display of individual viewports can be managed by selecting the appropriate entries under the Window menu as well ( Window \u2192 Layout ). The basic layout of MicroView can also be changed: Select Window \u2192 Layout \u2192 Set Layout to 2-by-2 to display MicroView as a 2-by-2 grid of viewports. Select Window \u2192 Layout \u2192 Set Layout to 1-by-3 to switch back to the default arrangement. Tabs and Notebooks Generally speaking, a majority of the layout features of MicroView are customizable by click-and-dragging them from one place on the screen to another. Toolbar All of MicroView's analysis tools are available through pull down menus. The most commonly used tools and applications are also available in the toolbar on the tab named \"Tools & Apps\", at the left hand side of the main window. Whenever a tool is launched, a new tabbed window will appear in the toolbar. Interaction Palette MicroView's Interaction Palette contains convenient buttons that change the default mode of mouse interaction with the application. By default, left (or primary) mouse clicks and drags within the 3D and 2D viewports changes the orientation of the image on the screen. By clicking on the appropriate button in the palette, this behavior can be changed to one of a number of other modes. Each mode can be additionally accessed by either a different mouse button, or combining Shift and/or Ctrl with a mouse button, as described below . Using the Interaction Palette is particularly convenient in one or two mouse button environments. Window and Level Controls A common task, when viewing images with greater dynamic range than the capabilities of the viewing workstation, is the adjustment of image brightness and contrast. MicroView allows adjustment of grayscale image brightness by defining either an image's window and level setting, or by defining the minimum and maximum grayscale values to display. Window and Level scrollbars are positioned at the bottom right side of MicroView's main window, and can be interactively adjusted. The actual window and level values will be displayed in the statusbar at the very bottom right corner of MicroView. To switch to the min/max approach to adjusting image brightness and contrast, or to explicitly set image window and level values manually, right-click over the window/level text in the statusbar. A popup menu will appear, which contains a number of predefined window/level settings, which are useful when viewing DICOM CT data, and an option to edit window and level values directly. Context-Sensitive Menu By default, right-clicking over the 3D image viewport will produce a context-sensitive menu. A variety of menu options exist, but generally, they focus on adjusting the viewport orientation. Note that clicking the right mouse button and dragging the mouse will activate, by default, the zoom feature in MicroView, so the mouse must be stationary when right-clicking to produce the context-sensitive menu. Image-specific Tools Palette Clicking on the palette icon in the right hand corner of each notebook window will produce a dialog from which different color palettes may be selected. Synchronization Clicking on the synchronization icon in the right hand corner of each notebook window will produce a dialog from which image synchronization can be adjusted. This tool is useful for synchronizing and comparing registered image sets. Each image loaded can be synchronized with zero, one or more other loaded images. If synchronization is enabled, Image orientation will be linked between images. Visual Cues MicroView provides a number of optional visual cues to assist with navigation within a 3D image. Most of the cues can be toggled on or off using MicroView's Application Settings... menu entry . Volume border - a yellow border drawn around the entire extent of a 3D image. It assists with ROI selection and delineating the entire image. Axis labels - Axis labels that move with the 3D image as it is rotated, zoomed or sliced. These may be the conventional medical imaging labels ('A'nterior, 'P'osterior, 'L'eft, 'R'ight, 'I'nferior, 'S'uperior) if the image orientation information is known to MicroView, or the coordinate axes labels ('+X', '-X', '+Y', '-Y', '+Z' and '-Z'), otherwise. Plane intersection lines and triangular markers - red, green and blue lines/markers that indicate the intersection between planes. The display of the intersection lines can be toggled on/off; the triangular markers appear in each of the 2D views to highlight the location of the other two intersecting planes, and remain visible always. Plane borders - red, green and blue borders around each image plane, visible in both 2D and 3D viewports. 2D viewport border highlight - the x, y and z plane viewports are highlighted in red, green and blue, respectively.","title":"Screen Layout"},{"location":"screen-layout/#screen-layout","text":"This section describes the basic screen layout of the MicroView application and some of it's visual cues.","title":"Screen Layout"},{"location":"screen-layout/#overview","text":"By default, the MicroView display consists of an application toolbar on the far left side of the screen, and one or more viewer windows contained within a notebook on the right side of the screen. Each viewer window contains a 3D image viewport in the center-left of the window, and a column of three 2D viewports on the right side of each window. MicroView also contains a menu at the top of the application window, Window and Level adjustment scrollbars at the bottom and status and progress indicators at the extreme bottom of the window. It contains image-specific tools in the upper right corner of each notebook page and context-sensitive menus in a variety of locations. Finally, it contains an interaction palette just above the status bar, that contains buttons to toggle the behavior of mouse clicks and mouse motion in MicroView.","title":"Overview"},{"location":"screen-layout/#modifying-the-layout","text":"","title":"Modifying the Layout"},{"location":"screen-layout/#viewports","text":"Each viewport in MicroView can be individually maximized by double-clicking the left mouse button over the viewport. When in the maximized state, the display can be restored by double-clicking the left mouse button while continuing to position the mouse over the viewport. The display of individual viewports can be managed by selecting the appropriate entries under the Window menu as well ( Window \u2192 Layout ). The basic layout of MicroView can also be changed: Select Window \u2192 Layout \u2192 Set Layout to 2-by-2 to display MicroView as a 2-by-2 grid of viewports. Select Window \u2192 Layout \u2192 Set Layout to 1-by-3 to switch back to the default arrangement.","title":"Viewports"},{"location":"screen-layout/#tabs-and-notebooks","text":"Generally speaking, a majority of the layout features of MicroView are customizable by click-and-dragging them from one place on the screen to another.","title":"Tabs and Notebooks"},{"location":"screen-layout/#toolbar","text":"All of MicroView's analysis tools are available through pull down menus. The most commonly used tools and applications are also available in the toolbar on the tab named \"Tools & Apps\", at the left hand side of the main window. Whenever a tool is launched, a new tabbed window will appear in the toolbar.","title":"Toolbar"},{"location":"screen-layout/#interaction-palette","text":"MicroView's Interaction Palette contains convenient buttons that change the default mode of mouse interaction with the application. By default, left (or primary) mouse clicks and drags within the 3D and 2D viewports changes the orientation of the image on the screen. By clicking on the appropriate button in the palette, this behavior can be changed to one of a number of other modes. Each mode can be additionally accessed by either a different mouse button, or combining Shift and/or Ctrl with a mouse button, as described below . Using the Interaction Palette is particularly convenient in one or two mouse button environments.","title":"Interaction Palette"},{"location":"screen-layout/#window-and-level-controls","text":"A common task, when viewing images with greater dynamic range than the capabilities of the viewing workstation, is the adjustment of image brightness and contrast. MicroView allows adjustment of grayscale image brightness by defining either an image's window and level setting, or by defining the minimum and maximum grayscale values to display. Window and Level scrollbars are positioned at the bottom right side of MicroView's main window, and can be interactively adjusted. The actual window and level values will be displayed in the statusbar at the very bottom right corner of MicroView. To switch to the min/max approach to adjusting image brightness and contrast, or to explicitly set image window and level values manually, right-click over the window/level text in the statusbar. A popup menu will appear, which contains a number of predefined window/level settings, which are useful when viewing DICOM CT data, and an option to edit window and level values directly.","title":"Window and Level Controls"},{"location":"screen-layout/#context-sensitive-menu","text":"By default, right-clicking over the 3D image viewport will produce a context-sensitive menu. A variety of menu options exist, but generally, they focus on adjusting the viewport orientation. Note that clicking the right mouse button and dragging the mouse will activate, by default, the zoom feature in MicroView, so the mouse must be stationary when right-clicking to produce the context-sensitive menu.","title":"Context-Sensitive Menu"},{"location":"screen-layout/#image-specific-tools","text":"","title":"Image-specific Tools"},{"location":"screen-layout/#palette","text":"Clicking on the palette icon in the right hand corner of each notebook window will produce a dialog from which different color palettes may be selected.","title":" Palette"},{"location":"screen-layout/#synchronization","text":"Clicking on the synchronization icon in the right hand corner of each notebook window will produce a dialog from which image synchronization can be adjusted. This tool is useful for synchronizing and comparing registered image sets. Each image loaded can be synchronized with zero, one or more other loaded images. If synchronization is enabled, Image orientation will be linked between images.","title":" Synchronization"},{"location":"screen-layout/#visual-cues","text":"MicroView provides a number of optional visual cues to assist with navigation within a 3D image. Most of the cues can be toggled on or off using MicroView's Application Settings... menu entry . Volume border - a yellow border drawn around the entire extent of a 3D image. It assists with ROI selection and delineating the entire image. Axis labels - Axis labels that move with the 3D image as it is rotated, zoomed or sliced. These may be the conventional medical imaging labels ('A'nterior, 'P'osterior, 'L'eft, 'R'ight, 'I'nferior, 'S'uperior) if the image orientation information is known to MicroView, or the coordinate axes labels ('+X', '-X', '+Y', '-Y', '+Z' and '-Z'), otherwise. Plane intersection lines and triangular markers - red, green and blue lines/markers that indicate the intersection between planes. The display of the intersection lines can be toggled on/off; the triangular markers appear in each of the 2D views to highlight the location of the other two intersecting planes, and remain visible always. Plane borders - red, green and blue borders around each image plane, visible in both 2D and 3D viewports. 2D viewport border highlight - the x, y and z plane viewports are highlighted in red, green and blue, respectively.","title":"Visual Cues"},{"location":"tools-and-plugins/","text":"Tools and Plugins This section describes the various extension plugins which are available for MicroView. ROI Manager This tool facilitates the use of multiple regions of interest ( ROI ) within MicroView. ROI are unmanaged until added to the ROI Manager. Once added to the ROI Manager, the originating plugin that created the ROI can move on to generate a new ROI, or in fact, can be closed without losing a reference to the ROI object. The ROI Manager can remember, display, activate, and apply Boolean operations to regions of interest. Adding ROI To have the ROI Manager remember the active ROI, click Add Current ROI and provide a name. The name you provided now appears in the ROI Objects list. The active ROI is now managed. To save a ROI to disk, select a ROI from the ROI Objects list and click Save. The ROI Manager uses the VTK Image or vti format to store ROI on disk. The ROI Manager supports loading of VTK Image files that are created using the save functionality above, as well as the file formats previously supported with the Geometry Manager tool, such as VTK . To load a ROI from disk, click Load and locate the appropriate file. To delete a managed ROI, select the ROI from the ROI Objects list and click Delete. Click Delete All to remove all ROI from the list. Displaying ROI Displaying a ROI does not make a ROI active. That is, displayed ROI do not affect any of MicroView's plugins or the calculations that they perform. To activate a ROI, see the next section \"Activating ROI\". To display a managed ROI, select a ROI in the ROI Objects list. Now click Show. You can display multiple ROI simultaneously. To remove the ROI from the display, click Hide. You have several options to control the visual presentation of the ROI. To view all displayed ROI as binary masks, choose the Mask option. To view the displayed ROI as 3D objects, choose the \"Geometry\" option. The Display Characteristics tab contains options that control the presentation of individual ROI. If you are using the \"Geometry\" display option, then select \"Display Wireframe\" to view a wireframe mesh of the ROI or de-select to view the ROI as a solid object. The \"Surface color\" and \"Surface Opacity\" fields control the colour and translucency of the ROI respectively. When viewing ROI using the \"Geometry\" option, the colour and opacity of each ROI can be controlled independently. When viewing ROI using the \"Mask\" option, the colour of each ROI may be controlled independently, but the opacity affects all of the ROI currently viewed simultaneously. Activating ROI The active ROI affects MicroView's plugins. To activate a ROI, select its name in the ROI Objects list and click Activate. Only one ROI can be active. The \"Active ROI\" field at the top of the ROI manager displays the name of the active ROI. Creating a new ROI supplants the active ROI. Applying Boolean Operations to ROI You can apply Boolean operations to existing ROI to create new ROI. The figure illustrates the effects of the different Boolean operations: NOT inverts the ROI; OR combines two ROI; AND intersects two ROI; and XOR gives the ROIs' respective unique points. To apply a Boolean operation, open the Combine ROIs tab. Select the ROI and the operation you desire to perform. Note that NOT operates on a single ROI. Click Do Operation to execute the operation. The resulting ROI is added to the ROI Objects list. Visualizing 3D Data The ROI Manager's 3D display capabilities can be used to create impressive graphical presentations of data. As an alternative to MicroView's Volume Rendering plugin, you can display several ROI simultaneously using the Geometry option. This is particularly advantageous when using the Movie Maker plugin: rendering the ROI is faster than the volume rendering. Simple Analysis Tools Point (1D) At any time while the mouse cursor is over the volume, the coordinates and gray-scale value will appear in the bottom left-hand corner of the 3D viewport. You can change between displaying coordinates in mm or pixels, in MicroView's application settings dialog ( Edit \u2192 Application Settings... ). Line (2D) A line segment can be selected for analysis by performing the following steps: Position the mouse cursor over an image in any of the viewports. Press the 1 key to mark the beginning of the line. Press the 2 key to mark the end of the line. or - Select Edit \u2192 Show Line to display a line in the center of the image immediately Green and blue markers will be drawn in the 3D viewport, indicating the beginning and ending of the line, respectively. The marks can be dragged interactively about each viewport by selecting the marker using the middle button. Re-select the endpoints at any time by pressing either of the 1 and 2 keys. Clear the line by pressing the y key. Once a line segmented has been selected, use any of the following hotkeys to perform a 2D analysis: 2D Keyboard Hotkeys HotKey Result a Saves the end-points of the line tool, and gray-scale values measured along the selected line to a text file. p Plots the gray-scale values along the selected line. y Removes the line from the viewport. Volume (3D) Select a 2D or 3D region of interest (ROI) using any of MicroView's ROI tools . Once a ROI is selected, use any of the following hotkeys to perform 2D/3D analysis: 3D Keyboard Hotkeys Hot Key Result c Removes the active ROI from the screen. g Plots the histogram of the gray-scale values within the ROI. m Calculates the mean and standard deviation of the gray-scale values within the ROI. s Saves the boundary coordinates of the standard ROI to a file. v Saves the ROI to an image file. d Saves the gray-scale values to a text file. Selection region must be two dimensional. u Saves the area to an image file (2D ROI selection only). Del Sets voxel values, within the currently defined ROI to a user-defined value (defaults to zero). Use this key to mask out regions of an image. Shift + Del Sets voxel values, outside the currently defined ROI to a user-defined value (defaults to zero). Use this key combination to mask out everything outside a ROI. Line Profile Window Overview MicroView can plot a profile of pixel data along a user-defined line . First, select the start and end points of the line, then press the p key to plot the data profile. Interacting with the Plot Window Use the left mouse button to interactively click and drag a region of interest in order to zoom in on the plotted data. Multiple levels of zooming can be achieved by repeating the click-and-drag method. Zoom out by clicking with the right mouse button. Reset the plot window by clicking the Reset button at the bottom of the plot window, selecting View \u2192 Reset , or by pressing the r key. Optionally display symbols over each data point, by selecting View \u2192 Symbols . Measurements along the 2D pixel profile may be made by positioning the mouse cursor over a feature within the plot window and pressing the 1 key, then selecting a second feature and pressing the 2 key. A horizontal red line will be drawn between the two features. Once drawn, the endpoints can be moved, either by using the 1 / 2 key combination, or by adjusting the endpoint values in the editable text fields below the plot area. Mouse cursor position and selected line length are displayed in the bottom center of the plot window. This feature is particularly useful for measuring full-width half-max (FWHM) distances on peaks in a unbiased, systematic fashion. Saving data The plot window data can be exported to disk in one of two ways: Select File \u2192 Save Data... to save the line profile to disk in a simple text format Select File \u2192 Save Snapshot... to save a screen capture of the plot window to one of a number of common image file formats Histogram Window MicroView can plot a histogram of pixel values within a 2D or 3D ROI. To plot a histogram of data, first select a ROI , then press the g key to activate the histogram window. The control of the histogram window is similar to the control of the 2D profile plot window . The histogram window has the following additional features: The Auto Threshold button can be used to automatically determine an optimal threshold value for use in the isosurface tool or Advanced Bone Analysis application . The value will be selected using the method of Otsu. A red arrow will be displayed on the x-axis of the plot after hitting this button, indicating the threshold value. In addition, the window/level settings in MicroView will be adjusted to reflect this threshold value, as a convenience. The user can selectively interrogate a range of data within the histogram. For this selected range of values, the total number of voxels in the selected range and corresponding volume fraction are reported. To select a range of voxel values, place the cursor on the graph in the plot window and press the middle mouse button. Drag the mouse and release the button once the desired range of voxel values have been highlighted, in red. Check the Highlight selected region checkbox to adjust the image display in the 3D and all 2D viewports of the main window, so that voxels corresponding to the selected value range will be highlighted. Selected ranges can be converted to an active ROI by first highlighting a region, as described above, then clicking the Highlight \u2192 ROI button . The highlighted red region will become yellow, indicating that the selected values are now the active ROI. The user can select different bin sizes for the histogram. Select from one of the menu entries under Options \u2192 Bin Size to adjust the bin size. Advanced Bone Analysis Application Overview MicroView's Advanced Bone Analysis Application performs a variety of analysis and visualization tasks upon a selected region of interest within an image. The application is designed specifically for analysis of CT images of bone. The choice of which functions to perform on a given ROI , what type of visualization output to use, and how the current project or study should be structured can be selected prior to any calculation. It is possible to export the results to any or all of the following formats: plain text, CSV, Excel, or PDF. The Advanced Bone Analysis Application contains the following analysis tools: BMD , which reports the bone mineral density (BMD), bone volume fraction (BVF), bone mineral content, and various other statistics; SMI , which reports the structure model index (SMI). SMI gives information about the curvature of the surface, and estimates how \"plate-like\" or \"rod-like\" a trabecular structure is; Anisotropy , which determines the degree of symmetry and orientation of a trabecular structure; Stereology , which reports Euler index, bone volume fraction, bone surface to bone volume ratio, trabecular plate thickness, trabecular plate number, trabecular plate separation and various other measures. The Euler index is a measure of the connectivity of a trabecular structure; Topology , which categorizes each voxel in a trabecular structure as being a member of either a surface, curve, or junction and provides a visual representation of this classification; Direct Measures , which determines the local trabecular thickness of a bone, and provides a visual representation of this local thickness, and; Cortical Bone Analysis , which determines slice-by-slice thickness, area, moment of inertia, and BMD values for cortical bone. It is to be used in conjunction with the Cortical ROI tool to perform analysis on the cortical shell of a bone. Using the Advanced Bone Analysis Application Activate the Advanced Bone Analysis Application by selecting Analyze \u2192 Bone Analysis... from MicroView's menu, or by clicking on the Bone Analysis button in the Applications group of MicroView's toolbar . If an ROI has not already been selected, first activate an ROI plugin and select a ROI. As a convenience, the list of available ROI plugins is displayed in the choice-box in the upper left of the plugin: Choose an ROI tool in the available drop-down list, then hit the Activate ROI button to launch the tool. Once a ROI has been selected, enter a gray-level threshold value, that will be used to discriminate bone from non-bone voxels in the image. Either type in a threshold value in the entry field in the Threshold section or click the Auto Threshold button, to determine a best-guess threshold value automatically. If you would like to verify that the automatically selected value is appropriate, generate a histogram of the image contained within the ROI, then hit the Auto Threshold button on the histogram plot window. In the Bone Parameters section select the type of analysis desired. Click the Advanced Options... button to modify the default settings. The Advanced options will be discussed in more detail later in this section. In the Output Options section select the name of the file where the results will be stored. The results are written to an XML database file. These results are presented for review in a custom spreadsheet view. This spreadsheet view allows the results to be exported to one of the supported file formats (text, CSV, Excel, PDF). If no project file name is provided, the analysis cannot be performed. It is also possible to select an existing database file using the Load Project button. The new results can then be added to this database. More information regarding the project database can be found here . In the Visualization Options select RAW, Topology, Anisotropy, or Direct Measures. The options Topology, Anisotropy and Direct Measures will only be available for selection if they have been selected in the Cancellous Bone Parameters section. If one of these three options is selected, MicroView will shift focus from the Advanced Analysis dialog to the appropriate dialog for visualization when the Run button is clicked. Click the Run button. Advanced Options The Advanced Options allows the user to modify the default settings. To display the Advanced Options dialog click the Advanced Options button. In the Advanced Options dialog there are several tabs: The BMD tab has several variables that can be edited manually. By default the values for Bone ADU (arbitrary density unit) and Water ADU are set to the calibration constants found in the header of image file. The Lower Exclusion ADU is a gray scale value below which voxels are not included in the bone equivalent mass calculation. Similarly the Upper Exclusion ADU is a Gray scale value above which voxels are not included in the bone equivalent mass calculation. The upper and lower exclusion ADU should be set to exclude air and metal, respectively, in the bone mass calculation. The SMI tab has options to smooth the image prior to the generation of an isosurface and to smooth the isosurface prior to the calculation of SMI. In the Anisotropy tab, the Grid Spacing determines how finely the ROI is to be resampled prior to any calculations, the Number of Tests determines the number of lines to use when calculating mean intercept length (MIL), and Random Testing Angles determines whether the direction of the lines used when calculating MIL are randomly chosen. In the Direct Measures tab, the user has an option of what measures to compute \u0096 direct trabecular thickness, direct trabecular spacing, or both. The Minimum Feature Size in pixels can also be specified. Structures less than this size will not be used in calculating direct trabecular thickness and direct trabecular spacing. The Stereology tab, has an option to enable verbose output to display additional measures, and an option to enable the purify algorithm. To obtain meaningful results from Stereology, the image should be passed through this purification filter first. The purify algorithm removes spurious unconnected region. After all the modifications to the Advanced Options have been made, click the OK button to close the dialog. Specific Tool Information Bone Composition Measurement Tool This tool performs a virtual biopsy and \"ashing\" to determine bone mineral content non-destructively. Image data derived from the Locus family of CT scanners may be calibrated to standard CT number, measured in Hounsfield Units (HU), and furthermore calibrated to permit determination of equivalent mass of hydroxyappetite. Results are reported as bone mineral fraction (BVF) or bone mineral density (BMD) in units of mg (HyAp)/cm 3 . To use this tool, launch the Advanced Bone Analysis application, define a 3D ROI, then select a threshold that discriminates bone from soft tissue. Prior to hitting the Run button, if required, click the Advanced Options... button to modify the BMD tool settings: Enter a value for Bone ADU Enter a value for Water ADU Enter a value for Lower Exclusion ADU Enter a value for Upper Exclusion ADU SMI Tool Structure model index (SMI) is a parameter used to measure how \"rod-like\" or \"plate-like\" trabecular architecture is. With aging and disease, cancellous bone architecture in some sites deteriorates from plate-like to rod-like. SMI for ideal plates and rods is 0 and 3, respectively. SMI calculated for specimens with high bone volume fraction (BV/TV) can be negative. Outputs SMI (unitless) - the SMI parameter Volume - the volume within the isosurface S.A. - the surface area of the isosurface Delta_R - distance along the normal direction each vertex is translated to estimate SA_Prime SA_Prime - surface area derivative Algorithm The SMI parameter is discussed in detail in Hillebrand97a. SMI is calculated as \\frac{6(S'V)}{S^2} \\frac{6(S'V)}{S^2} where S' S' is the surface area derivative, V V is the trabecular bone volume, and S S is the surface area. The factor of 6 is used to obtain integer values for ideal plate, cylinder, and sphere models (plate = 0, cylinder = 3, sphere = 4). The first step in calculating SMI is to create an isosurface of the trabecular bone within the ROI. The surface area and volume are directly calculated from this isosurface. The surface area derivative is estimated by calculating the change in surface area of the isosurface when the vertices are translated a small amount along their normal directions and normalizing by the magnitude of the displacement. Note SMI was initially used to describe structures with very few intersections between the structure elements (i.e., rods and plates) while the BV/TV is low. SMI parameter is always positive for these structures. However, if SMI analysis is applied on a dense structure with lots of intersections between the structure elements, it may give negative SMI values. This results from the surface area decreasing when dilating the surface vertices along the normals and consequently a negative S' in the equation for SMI. For example, take a plate with a hole in the center. The hole becomes smaller after the vertices are translated in the normal direction and the corresponding change in surface area is negative. Note For a ROI with more than 27 000 000 (300x300x300) voxels, the ROI image is resampled by shrinking factors 2 by 2 by 2 to reduce memory consumption and speed up the calculation. Advanced Options Smooth Isosurface (default value: ON) - uses a windowed sinc function as interpolation kernel to 'relax' the mesh, making the cells better shaped and the vertices more evenly distributed. The windowed sinc function is a low-pass filter that eliminates the high frequency noise and keeps the low frequency features of bone surfaces. Smooth Raw Image (default value: OFF) - passes data through a Gaussian filter prior to creating isosurface. The default kernel size is 3x3x3 and default standard deviation is 1. The user can set these parameters in the advanced options. Anisotropy Tool Anisotropy measures the orientation of the trabecular architecture. This orientation affects the mechanical behavior of trabecular tissue and is affected by age and disease. MicroView uses the mean intercept length (MIL) method to calculate the structural anisotropy. This method measures the intersections of a test grid with the trabecular structure and calculates the fabric ellipsoid (3D ellipse). Trabecular structures with no preferred orientation have a spherical ellipsoid, while structures with more alignment in one direction have the major axis of the ellipse aligned in that direction. Output Ellipsoid Coefficient Eigenvector, value and principle MILs Ratios: a1/a3, a1/a2, a2/a3 Algorithm A grid of parallel test lines is passed though the ROI and the number of intersections of the test lines with the bone/marrow interface is calculated. This procedure is performed for the number of test rotations listed in the advanced options. Each rotation of the test grid is described by two angles (theta, phi) in spherical coordinates. For each rotation, MIL is calculated as 2* BV/TV / (number of intersections / test line length). The MIL data are then fit to the equation of an ellipse using least squares. The least squares analysis provides the 6 coefficients for the best fit ellipse. An eigen analysis of the second rank tensor formed by these coefficients provides the length of the axes of the ellipsoid and their corresponding directions. The degree of anisotropy is then defined as the ratio of the lengths of the maximum and minimum axes. Advanced Options Random Test Angles (default: ON) - when checked, the test grid is rotated through pseudo-random angles; otherwise the test grid is rotated step by step in theta and phi with a constant stride. Number of Rotations (default: 200) - number of rotations of the test grid Grid Spacing (default: 3) - spacing (in voxels) between test lines Stereology Tool MicroView can perform a simple stereology analysis of a 3D bone image. The stereology tool measures trabecular structure using similar techniques to those implemented in classical histomorphometry . 2D techniques determine estimates of trabecular thickness, spacing and density. At the same time, trabecular connectivity is quantified by calculating the Euler number for the trabecular structure. Finally, the bone surface area to volume ratio is also calculated. To perform a stereology analysis on a CT image of a bone, launch the Advanced Bone Analysis application, define a 3D ROI, then select a threshold that discriminates bone from soft tissue. Prior to hitting the Run, if required, click the Advanced button to modify the Stereology tool settings: Advanced Options Turning on Enable verbose output will generate additional output measures. Turn on the Enable purify algorithm for Euler No. calculation option to pass the selected image through a purification algorithm, first, before computing the Euler number. The purify algorithm removes isolated bony spicules and fills encapsulated marrow spaces. !!! Note When the purify algorithm is enabled, select a ROI where at least one of the voxels at the boundary of the ROI is equal to or above the threshold (ie. the trabecular bone must intersect the boundaries of the ROI). Passing a clipped image, through the purify filter, which has no boundary voxels equal to or above the threshold will produce a blank image from the filter. Turn on the Enable purify algorithm for all other calculations option to pass the selected image through a purification algorithm, first, before performing the other calculations. Topology Plugin Topology Warning This plugin may not be available in all versions of MicroView. This plugin can be used to determine a 3D topology of each voxel in a trabecular bone structure. Define a 3D ROI by using either the 7 / 8 keys,or by selecting a ROI using the ROI plugin ( Plugins \u2192 ROI Selection Tool... on the MicroView menu). Once a ROI has been defined, activate the Topology plugin by selecting Topology... from the Plugins menu. Enter the desired file name in the Output File text window. Click the Calculate button to generate a topological image within the selected ROI and create a report (see Output File ). Click the Show Overlay or Hide Overlay button to show or hide the topological image. Once the topological image is overlaid on the original image, the transparency of topological image can be adjusted by the checkboxes and sliders. The voxels of the topological image are classified as follows: DENS - topological skeleton CE - curve edge SE - surface edge C - curve interior S - surface interior CC - curve-curve junction SC - surface-curve SS - surface-surface PE - profile-edge PI - profile interior Direct Measures Tool Direct Measures Direct Measures calculates the trabecular thickness ( Tb.Th Tb.Th ) and separation ( Tb.Sp Tb.Sp ) by fitting maximal spheres to the trabecular structure. The diameters of the spheres within the bone and marrow regions provide estimates of Tb.Th Tb.Th and Tb.Sp Tb.Sp , respectively. Output Tb.Th Tb.Th - mean trabecular thickness Tb.Sp Tb.Sp - mean trabecular separation Histogram of voxels within spheres of incremental sizes determined in the Advanced Options Algorithm The algorithm is discussed in detail in. The first step is to binarize the data based on the selected threshold. For trabecular thickness, the Euclidean Distance Transform of the bone region is calculated. This results in each bone voxel being assigned a value corresponding to the distance to the nearest non-bone voxel. Next, for each bone voxel the largest sphere that fits within the bone structure is determined. Tb.Th Tb.Th and Tb.Sp Tb.Sp are then calculated as the mean value assigned to all bone and marrow voxels, respectively. Advanced Options Min Feature Size - determines the minimum diameter sphere used when calculating the mean value for Tb.Th Tb.Th and Tb.Sp Tb.Sp . Histogram Bin Size - sets the bin width for the Tb.Th Tb.Th and Tb.Sp Tb.Sp histograms What to measure? - sets which parameters are measured Direct Trabecular Thickness Direct Trabecular Separation Direct Tb.Th Tb.Th and Tb.Sp Tb.Sp Note There is a limitation for ROI dimensions, which is 650x650x650. The accuracy of the Tb.Th Tb.Th and Tb.Sp Tb.Sp calculation is 0.01 voxel. Cortical Analysis Tool Cortical Analysis Cortical analysis is designed to be applied to the cortical shell of a bone such as a femur or humerus. The algorithm measures a wide number of different parameters of utility. Note The cortical analysis tool assumes that the bone is aligned with the long axis parallel to the z-axis defined in MicroView. If your sample is not oriented in this way, it must be reoriented for the results to be meaningful. Output By default, the output values are reported for the entire ROI. Using an advanced option, it is possible to have the values reported on a slice-by-slice basis. Angle X - the angle between the x-axis of the ROI and the original x-axis (not available in slice-by-slice data) Angle Y - the angle between the y-axis of the ROI and the original y-axis (not available in slice-by-slice data) Angle Z - the angle between the z-axis of the ROI and the original z-axis (not available in slice-by-slice data) Number of Slices - number of slices in the ROI (not available in slice-by-slice data) Mean Thickness - the average thickness of the cortical bone Std Dev Thickness - the standard deviation of the thickness of the cortical bone Ixx - the moment about the x-axis of the cortical bone Iyy - the moment about the y-axis of the cortical bone Izz - the moment about the z-axis of the cortical bone Ixy - the bending xy moment of the cortical bone Inner Perimeter - the inner perimeter of the cortical bone Outer Perimeter - the outer perimeter of the cortical bone Marrow Area - the area contained inside the cortical bone Cortical Area - the area of the cortical bone only Total Area - the total cross-sectional area of the bone BMD - Bone mineral density BMC - Bone mineral content Centroid - the position of the centroid of the volume Algorithm The first parameters computed are the moments and the centroid location. Once the centroid location has been determined, rays are projected from this location towards the edge of the ROI. When the ray first intersects the edge of the cortical bone, this point is noted as an interior point. When the ray intersects the second edge of the cortical bone, this is noted as an exterior point. The lists of interior and exterior points are then used for thickness, perimeter and area computations. Advanced Options Report individual slice data - turns on reporting of all output measures listed above but on a slice-by-slice basis rather than for the entire volume Report radial thickness data - turns on reporting of cortical thickness measurements at ten degree intervals around the circumference of each slice Perform mass normalization of moments - normalizes all of the moment measures by the total mass of cortical bone Basic Bone Analysis Application Overview MicroView's Basic Bone Analysis Application performs a variety of analysis upon a selected region of interest within an image. The application is designed specifically for analysis of CT images of bone. The choice of which functions to perform on a given ROI , can be selected prior to any calculation. The results could be stored or appended in user specified plain text files. The Basic Bone Analysis Application contains the following analysis tools: BMD , which reports the bone mineral density (BMD), bone volume fraction (BVF), bone mineral content, and various other statistics; Stereology , which reports Euler index, bone volume fraction, bone surface to bone volume ratio, trabecular plate thickness, trabecular plate number, trabecular plate separation and various other measures. The Euler index is a measure of the connectivity of a trabecular structure. Tip The commercial package Advanced Bone Analysis Application contains analysis tools for SMI, Anisotropy, and Stereology. It also offers project and study management tools and support PDF and Excel outputs. Using the Basic Bone Analysis Application Activate the Basic Bone Analysis Application by selecting Analyze \u2192 Bone Analysis... from MicroView's menu, or by clicking on the Bone Analysis button in the Applications group of MicroView's toolbar . If an ROI has not already been selected, first activate an ROI plugin and select a ROI. As a convenience, the list of available ROI plugins is displayed in the choice-box in the upper left of the plugin: Choose an ROI tool in the available drop-down list, then hit the Activate button to launch the tool. Once a ROI has been selected, enter a gray-level threshold value, that will be used to discriminate bone from none-bone voxels in the image. Either type in a threshold value in the entry field in the Threshold section or click the Auto Threshold button, to determine a best-guess threshold value automatically. If you would like to verify that the automatically selected value is appropriate, generate a histogram of the image contained within the ROI, then hit the Auto Threshold button on the histogram plot window. In the Bone Parameters section select the type of analysis desired. Click the Advanced Options... button to modify the default settings. The Advanced options will be discussed in more detail later in this section. In the Output File section select the name of the file where the results will be stored. The results are written to a plain text file. These results are presented for review after each successful execution. It is also possible to append the results to an existing text file by checking the Append checkbox button. Click the Run button to perform the analysis. Advanced Options The Advanced Options allows the user to modify the default settings. To display the Advanced Options dialog click the Advanced Options... button. In the Advanced Options dialog there are several tabs: The BMD tab has several variables that can be edited manually. By default the values for Bone ADU (arbitrary density unit) and Water ADU are set to the calibration constants found in the header of the currently loaded image file (not all file types support this). The Lower Exclusion ADU is a gray scale value below which voxels are not included in the bone equivalent mass calculation. Similarly the Upper Exclusion ADU is a Gray scale value above which voxels are not included in the bone equivalent mass calculation. The upper and lower exclusion ADU should be set to exclude air and metal, respectively, in the bone mass calculation. The Stereology tab, has an option to enable verbose output to display additional measures, and an option to enable the purify algorithm. To obtain meaningful results from Stereology, the image should be passed through this purification filter first. The purify algorithm removes spurious unconnected region. After all the modifications to the Advanced Options have been made, click the OK button to close the dialog. Specific Tool Information Bone Composition Measurement Tool Bone Composition This tool performs a virtual biopsy and \"ashing\" to determine bone mineral content non-destructively. Image data derived from the Locus family of CT scanners may be calibrated to standard CT number, measured in Hounsfield Units (HU), and furthermore calibrated to permit determination of equivalent mass of hydroxyappetite. Results are reported as bone mineral fraction (BVF) or bone mineral density (BMD) in units of mg (HyAp)/cm 3 . To use this tool, launch the Advanced Bone Analysis application, define a 3D ROI, then select a threshold that discriminates bone from soft tissue. Prior to hitting the Run button, if required, click the Advanced Options... button to modify the BMD tool settings: Enter a value for Bone ADU Enter a value for Water ADU Enter a value for Lower Exclusion ADU Enter a value for Upper Exclusion ADU Stereology Tool Stereology MicroView can perform a simple stereology analysis of a 3D bone image. The stereology tool measures trabecular structure using similar techniques to those implemented in classical histomorphometry . 2D techniques determine estimates of trabecular thickness, spacing and density. At the same time, trabecular connectivity is quantified by calculating the Euler number for the trabecular structure. Finally, the bone surface area to volume ratio is also calculated. To perform a stereology analysis on a CT image of a bone, launch the Advanced Bone Analysis application, define a 3D ROI, then select a threshold that discriminates bone from soft tissue. Prior to hitting the Run, if required, click the Advanced button to modify the Stereology tool settings: Optionally click on the Enable Purify option to pass the selected image through a purification algorithm, first, before performing the stereology analysis. The purify algorithm removes isolated bony spicules and fills encapsulated marrow spaces. Note: When the purify algorithm is enabled, select a ROI where at least one of the voxels at the boundary of the ROI is equal to or above the threshold (ie. the trabecular bone must intersect the boundaries of the ROI). Passing a clipped image, through the purify filter, which has no boundary voxels equal to or above the threshold will produce a blank image by the filter. Optionally uncheck the Enable verbose output to disable the verbose output. Image Registration and Fusion Application Image Registration Overview Image registration is the process of finding a spatial transform that co-aligns two images, such that homologous features in both images (i.e. identical landmarks in the two distinct images) are given the same spatial coordinate. This is commonly performed so that the two images may be displayed superimposed together (i.e. fused) in a fashion that makes corresponding features easily viewed and identified. MicroView's register tool is designed for manual landmark registration. Manual landmark registration involves picking two sets of homologous landmarks from so-called \"fixed\" and \"moving\" images. A simple sum of least squares fitting algorithm is then used to determine the transformation to map the moving image to the coordinate system of the fixed image based on the landmarks selected. There is an option in this registration tool that allows the user to select the type of transform to be performed. The options are rigid body, similarity, and full affine transformations. Once images are registered they can be visualized through synchronization and/or fusion. For example, an image gathered from a positron emission tomography (PET) scanner provides functional information whereas an image obtained from a computed tomography (CT) scanner provides information regarding the structure and anatomy of the specimen. Synchronization and fusion will correlate the structural and functional information. Using the Register Tool Activate the Register Tool by selecting Plugins \u2192 Register... from MicroView's menu or by clicking on the Register button in the Applications group of MicroView's toolbar. The registration process is divided into the following 3 main steps: Loading Images and Layout Setup Landmark Registration Visualization Notice that a toggle button appears beside the window/level slides when the Register Tool is activated. Click on the button to toggle the control of the window/level slides to the left and right images. Loading Images and Layout Setup Click the Images and Layout tab to activate this page. Click the Fixed Image (Left) button and select the fixed image when the Open dialog appears. The fixed image is also called the target image. It is displayed on the left side. Click the Moving Image (Right) button and select the moving image when the Open dialog appears. The moving image is also called the source image. It is displayed on the right side. Select the views desired in the Layouts section and click the Set button. The view settings can be changed at any time during the registration process. Landmark Registration Landmarks Click on the Register tab to activate this page. Following are the typical steps to do landmark registrations: To select landmarks on images, position the cursor over a landmark in either image and then press the Space on the keyboard. Do the same to the other image to find the corresponding landmark. The selected pair of landmarks are shown as orange marks. At the same time, the coordinates of the landmarks are displayed in a row in the table on the left panel, which is highlighted in orange color and begins with a ? mark. These two landmarks can be moved around by moving the mouse to new positions and then pressing the Space . Zoom in on the images if required to fine-tune the locations of the landmarks. Sometimes, it may be easier to locate the corresponding landmarks in a oblique view. Use the 3D view to manipulate the image and get oblique views. To record the pair of landmarks that are selected in previous step, click the Accept button, or press the Enter key. This pair of landmarks will be displayed as red marks to indicate that they are accepted and recorded. The recorded landmarks may not be moved around. However, they can be deleted and replaced by a new pair. Repeat the above two steps to find more pairs of landmarks. There is no upper limit for the number of landmarks that may be selected. However, a minimum of 3 pairs of landmarks must be selected for 2D images and at least 4 pairs of landmarks must be selected for 3D images. Once enough landmarks have been selected a transformation matrix is automatically calculated to register the moving image on left to the fixed image on the right. The initially disabled Transformed View check box becomes enabled. Check the Transformed View check box to switch the moving image to the transformed view. At this stage, it may be sufficient to skip to the visualization section and examine the registration result. If the result is not satisfactory, continue on to the following steps. Select more landmarks to improve the registration. The additional landmarks on the moving image could be picked either in its original view or the transformed view. Switch back and forth between original and transformed views by checking and unchecking the Transformed View check box. Notice the contents of the second (landmark coordinates on the right) and third (distance) columns also change when the view is changed. Examining the distance column in the transformed view could help one to find the pair of landmarks that contribute the largest RMS error for the registration. The RMS value is the root mean square of the distances between each landmark pairs. This value is displayed under the Landmarks table. Landmarks can be reviewed and/or deleted by selecting the corresponding row in the Landmarks table. Click the left mouse button on a row to highlight it. Click the Delete button to delete the highlighted row and the corresponding landmarks on the images. All of the landmarks can be deleted at once by clicking the Delete All button. By default, the rigid-body transform is used for the registration. If the rigid-body transform is not sufficient for the registration, switch to another type of transform by changing the drop-down selection from the Transformation Matrix section: Rigid Body (6 Parameters) is a type of transformation with 6 degrees of freedom (ie. 3 for rotation and 3 for translation). Similarity (7 Parameters) is a type of transformation with 7 degrees of freedom (ie. 3 for rotation, 3 for translation, and 1 for uniform scale). Full Affine (12 Parameters) is a transformation with 12 degrees of freedom (ie. 3 for rotation, 3 for translation, 3 for scale, and 3 for shear). Note that the more parameters the transformation matrix uses, the more landmarks are needed to get a good result. Landmarks may be added or removed after switching the transformation type. Once done, go to the Visualization page to review the registration result. When satisfied, the results can be saved in one, two or all of the following three ways: Landmark tags: save the landmark coordinates by clicking the Save... button in the Landmarks section of the dialog. The landmarks can be loaded at a later time by clicking the Load... button in the Landmarks section. Resampled image: save the transformed (i.e., registered) moving image on the right pane to a file by clicking the Save... button in the Transformed View section. Tri-cubic interpolation is used to resample the transformed image. Transformation matrix: save the transformation matrix by clicking the Save... button in the Transformation Matrix section. This saved transformation can be applied at a later time to the moving image by clicking the Load... button in the Transformation Matrix section. Visualization Click on the Visual tab to activate this page. The visualization tools in this application serve two purposes. One is to visually evaluate the registration result and the other is to help user to correlate the information from the two images, e.g., the structural and functional information. Synchronized View Checking the Synchronized View check box synchronizes the two displayed images. The synchronized interactions on the images include: Gray scale values for both images are displayed when moving the cursor. Synchronized viewing angle. Synchronized zooming and panning. Synchronized slicing through the images (including Page-Up and Page-Down). Synchronized landmarks. Moving the cursor over a point of interest in either the fixed or moving images and then pressing the Space on the keyboard will activate the pair of orange colored landmarks. This feature can be used to do point-by-point comparison for the two registered images. Tip Remember to uncheck the Synchronized View check box before going back to the landmark page and selecting additional landmarks. Fusion Fusion The moving image can be fused on to the fixed image by checking the Fusion View check box. Once the Fusion View check box is checked, additional controls will appear in the dialog. The Min Level and Max Level sliders determine the range of gray scale values that get mapped to colors. The moving image will be transparent outside this range. If the Ramp Opacity option is checked then the opacity of the moving image is ramped exponentially. Otherwise the opacity is constant and is determined by the Opacity slider. There are several different color tables to select from. A color table is a mapping of gray scale values to RGB color values. Tip Synchronized view and fused views are designed to be used for two registered images, or at least two spatially overlapped images in the world-coordinates (the patient space). Trying to synchronize or fuse two spatially unrelated images will result in unexpected behaviors. Volume Rendering Tool Volume Rendering Overview Note MicroView 2.5.0 features GPU-acceleration and improved level of detail rendering for most volume rendering functions. MicroView's volume rendering tool can be used to produce stunning photo-realistic 2D semi-transparent representations of 3D image data by one of three raycast techniques. Raycast volume rendering is especially common in the medical imaging community where three dimensional volume data is easily available. To understand raycasting, think of voxels within a 3D image as possessing a density which corresponds to the graylevel value of the voxel. Imagine that for each pixel in the rendered image scene, a ray is drawn from the observer's eye, through the image pixel, then through the entire 3D image data set. Each ray will intersect a number of voxels before leaving the 3D image data. For each image pixel in the rendered scene, a color is determined by accumulating information derived from the intersecting voxels along the corresponding raycast ray. In particular, for each voxel in the 3D image data, the \"density\" or graylevel value of the voxel will be transformed into a corresponding voxel color and transparency. This color and transparency information will be combined, according to a raycast function to determine the final pixel color in the image scene. MicroView currently supports three styles of raycast volume rendering: Isosurface Rendering - a raycast method where surfaces of similar density objects are rendered, and the remaining materials are hidden. For this rendering mode, a density threshold value must be selected that defines the surface, and the color of the surface selected. Maximum Intensity Rendering - a method where the color of the densest object along each raycast path is used to determine the final color of each pixel. This method is particularly useful to extract, e.g. contrast-enhanced vessels, or bone from images. Composite Rendering - a general raycast method, which gives the greatest level of control over the raycast scene. MicroView's Rendering Interface MicroView's volume rendering interface allows the user to control the type of rendering to generate and the parameters that will be used to generate the rendering. The interface consists of the following elements. A graphical view that presents the image histogram, the opacity and color ramp and a representation of the LUT. The view can be controlled in the same fashion as the histogram or 2D profile plot windows. Additionally, this view contains a number of control points connected by a line. These control points are represented by either a blue (inactive) or red (active) dot and can be manipulated as outlined below. Control Point Settings group. These controls allow the user to fine tune the specific values that are used for each control point in the opacity and color ramp. A drop down box that contains a number of rendering presets. These presets have been designed to produce a good quality rendering in specific circumstances. There are two presents currently. Bone - sets the threshold at the Bone HU value specified in the volume. Soft tissue/Bone - uses the composite rendering method to generate an image that will accurately represent both soft tissues and bones. The preset values have been chosen using the calibrated HU values for bone and soft tissues. A pair of drop down boxes that are used to select the rendering mode to use, and the quality of the rendering to generate. The low quality rendering can be used to rapidly evaluate whether the chosen parameters will generate the desired image or not as the rendering is produced much more rapidly. Once the parameters have been roughly determined, the high quality rendering can be used to fine tune the results. A group of buttons that provide the following functionality: Save - saves all of the parameter settings to file for use at a later time or on another system. Load - loads the parameter settings from a file generated using the Save function above. Reset - Resets the histogram view and all of the associated parameters to the default values for the selected rendering function. Isosurface - the threshold value is set in the middle of the grayscale range of the volume. Maximum Intensity Projection - three regions equally spaced in the grayscale range of the volume. The first region covers the smallest values and has an opacity of 0. The second region covers the middle third of the values and is a ramp from an opacity of 0 to an opacity of 1. The final region covers the highest values and has an opacity of 1. Composite - a ramp starting from the smallest grayscale value in the volume and an opacity of 0 to the largest grayscale value in the volume and an opacity of 1. There is a third control point at the middle grayscale value. The interface is reset whenever a new image is loaded into MicroView. Update: generate the volume rendering using the current settings. Manipulating the volume (rotation, slicing, magnification) has the same effect. Using the Volume Renderer Tool Select Visualize \u2192 Render Volume... from the MicroView menu to open the volume rendering tool window. Select the style of volume rendering desired. Composite rendering offers the greatest control over the display, but is the slowest form of rendering. MIP rendering displays a maximum intensity projection of the currently loaded image data. Isosurface rendering displays only the surface of objects, and is most useful for rendering bone images. Change the location of the controls points if desired, to achieve the appropriate rendering result. The control points are chosen using the left mouse button and will change from blue to red to indicate that they are active. Isosurface - there are two control points that are vertically connected. These control points represent a threshold. All of the values above the threshold will be rendered. The two control points are always at the same graylevel. Maximum Intensity Projection - there are four control points, of which two can be manipulated by changing the graylevel value where they are located. The opacity values are fixed for all of the control points. The two end points are fixed. The first end point is at the lowest graylevel value in the volume and has an opacity of 0. The second end point is at the highest graylevel value in the volume and has an opacity of 1. The two control points in the middle of the histogram can be moved back and forth to change their graylevel position, and thus the location and slope of the ramp function. Composite - the composite rendering function is the most complicated and begins with three control points (two end points and the mid-point) and a ramp function from an opacity of 0 to an opacity of 1 as outlined above. The end points are fixed at the appropriate graylevel positions, but can have their opacity changed. There are a number of different manipulations that can be performed on the control points. Adding a control point - move the mouse pointer over the line that does not have an existing control point and click the left mouse button. A new point will appear at that location and will be active as indicated by the red coloration. Deleting a control point - select any existing control point by clicking on it with the left mouse button. The point will be marked active using the red coloration. Delete the point by pressing the \"Del\" key on your keyboard. Changing the opacity - select any existing control point by clicking on it with the left mouse button. By holding the left mouse button, it is possible to drag the control point up and down in the graphical view to change its opacity value. It is also possible to change the opacity of the currently selected control point by typing a value into the Opacity text entry box. Changing the graylevel position - select any existing control point by clicking on it with the left mouse button. By holding the left mouse button, it is possible to drag the control point left and right in the graphical view to changes is graylevel position. It is also possible to change the graylevel position of the currently selected control point by typing a value into the Position text entry box. Change the color that each surface will appear by using the color editor. Begin by selecting any control point by clicking on it with the left mouse button and noting that its color changes from blue to red. The color can then be edited using either the sliders on the color bars or by entering a value in the appropriate text entry box. How the color change is applied depends on the type of rendering that is being generated. Isosurface - all pixels above the specified threshold will be colored using the selected color. Maximum Intensity Projection - the pixels above the active control point will be colored using the selected color and the ramp function that joins the active control point to the next larger graylevel control point. Composite - same color treatment as the Maximum Intensity Project noted above. Select quality of rendering. Choose \"low\" quality to render rapid, lower quality images. These low quality renderings can be used to quickly evaluate the results of any changes that are made to the parameters before generating the more time consuming high quality renderings. Choose \"high\" quality once opacity, and color tables have been correctly set, in order to render at the highest quality. Click the Update button to update the output display whenever the rendering parameters have been adjusted. Manipulating the image by rotation, slicing or magnification will cause the output display to be updated. Click the Reset button to restore the opacity and color transfer functions to their original default values. Use the Save and Load buttons to save and load the parameter settings. Use the \"Enable volume picking\" checkbox to enable or disable volume picking: When enabled, the middle mouse button can be used to interactively adjust cropping dimensions that will be applied to the rendered image. When disabled, picking is disabled and MicroView will not allow the rendered volume to intercept mouse clicks and drags. Additional MicroView Tools MicroView has a number of additional features bundled into application plugins. Some of the core plugins are described below. Reorient Image As discussed in earlier sections of this help guide, MicroView can perform arbitrary axis multiplanar reformatting of 3-D image data. Reorienting the displayed image planes is performed on-the-fly without actually adjusting the underlying image. To actually save the image reformatted along new axes, a specific image reorient tool in MicroView is used. To save a reoriented image, first center and orient the cut planes in the 3-D view pane to represent the axes of the desired output image. Once satisfied with the displayed axes, select File \u2192 Save Reoriented Image... to save the reoriented image to a file. Standard ROI Tool Note MicroView 2.5.0 features spherical ROI objects as well as the ability to rotate primitives. MicroView's ROI tool can be used to select a 2D or 3D region of interest in the image for further analysis. It compliments the manual ROI selection technique, using the 7 and 8 keys. Use this tool when a ROI of a specific size or position is needed. Activate the ROI tool by selecting Standard ROI from the Tools and Applications sidebar on the left hand side of the main window, or by selecting Tools \u2192 Standard ROI... from the main menu. Choose Parallelepiped, Elliptical Cylinder or Spherical ROI shapes for the selected analysis region (Box, Cylinder and Sphere options, respectively). Choose a unit of measurement -- either millimeters or pixels. Adjust the size and position of the selected analysis region: Either manually enter coordinate values into the appropriate text boxes (hit enter key to accept changes), or adjust the sliders to the right of each entry box to choose the bounds of the region of interest. Alternatively, you can resize and reposition a rectangular ROI by interacting with the faces of the yellow box in the main 3D viewport. Position the mouse over any surface, then click and drag the middle mousebutton to resize the ROI along the axis parallel with the ROI face you clicked upon. Holding the shift key down, while performing the same operation will translate the ROI along the same axis. Press the Link X/Y button to enable or disable linking size changes in X and Y axis. Check the Link Image Plane radio button to enable rotation of ROI primitives. Rotate image planes in order to take advantage of this feature. Cortical Bone ROI Tool When applied to a CT image of a bone, this tool can be used to select a ROI corresponding to either the cortical shell or the trabecular space of the bone. The tool uses a series of morphological operators to semi-automatically select cortical bone components. The trabecular space is found within the cortical bone region. Once the cortical bone components have been selected, they can be converted to a ROI for use in the Advanced Bone Application and the image planes can be rotated so that the axes of the planes are aligned with the principal axes of the cortical bone. Before running this tool, the user needs to either select a ROI to be used for segmentation, or the tool will automatically select the entire image and perform segmentation on the resulting ROI. Activate the ROI tool by selecting Cortical ROI from the Tools and Applications sidebar on the left hand side of the main window, or by selecting Tools \u2192 Cortical ROI... from the main menu. The gray-level threshold may be either entered manually or determined automatically by using the Auto Threshold button. The result of automatic thresholding is determined using the \"Otsu\" method The \"Hole and Channel Size\" specifies the largest size, in pixels, of any holes and channels through the bone that you would like the algorithm to fill. The default value is 7 pixels. The \"Trabecular thickness\" specifies the largest size, in pixels, or trabeculae that you would like the algorithm to remove from the ROI. For bones where the cortical thickness is similar to the trabecular thickness, the segmentation algorithm may also eliminate the cortical bone making it less suitable for use in these circumstances. The default value is 7 pixels. Use the Run button to segment the cortical bone contained in the ROI. Use the Segmentation \u2192 Cortical ROI button to convert the segmentation results (highlighted in green) to a ROI (highlighted in yellow) that can be used for analysis operations in the Advanced Bone Application. Select the Segmentation \u2192 Trabecular ROI button to invert the ROI selection -- i.e. select the trabecular bone region as a ROI. Use the Align to Principal Axes button to rotate the axis planes to be aligned with the principal axes of the segmented cortical bone Isosurface Tool MicroView's isosurface tool can be used to extract a surface from a 3D image that corresponds to a user-defined gray-level value. Activate the tool by selecting Visualize \u2192 Isosurface... from the main menu. To use the tool: Select an image threshold value in the Image Threshold text box. Select a quality factor using the Surface Quality Factor slider. This factor is used to downsample the image prior, to extracting an isosurface. Use a small value (e.g. 0.25) initially to extract a course surface, then refine the surface by increasing the factor to 1.0. The memory consumed by this plugin increases quickly for large surface quality settings, as does the size of the final surface mesh. Use large values sparingly. Select a decimation factor by adjusting the appropriate slider. MicroView will attempt to reduce the surface complexity of the final isosurface by this user-defined amount. Setting a value of \"0.1\" means that MicroView will attempt to reduce the surface polygon count by 10%, while minimizing the impacting on surface topology, surface area and volume contained within the isosurface. A value of \"0\" indicates that no decimation shall be attempted, while values approaching \"1\" will significantly impact the quality of the final surface. Optionally enable image smoothing and image clipping by checking the appropriate checkboxes. If smoothing is enabled, MicroView will perform a Gaussian blur on the image prior to generating an isosurface. This is used commonly to reduce image noise, and hence remove spurious surface elements from the final surface. This will have an impact on the accuracy of the Area and Volume measurements displayed in the plugin GUI. Press the Update button to display/update the isosurface. Press the Clear to hide the surface. Image Resample Tool MicroView can perform image downsampling on a loaded image in order to decrease the disk space and memory needed to store an image. Activate the downsampling plugin by selecting Process \u2192 Resample Image... from the main menu. Then: Enter a downsampling factor in the edit field. Press the Resample and Save... button to resample the image and save it to disk. Image Transfer Tool MicroView can transfer a loaded image to a compatible DICOM viewing station. It can also browse and download into memory images from a number of remote viewing platforms. Certain stations can be automatically detected, while others must be manually configured. To activate the tool, select Tools \u2192 Dicom Transfer... from the main menu. Enter the hostname and port number of the destination server in the appropriate text entry boxes. Optionally select a DICOM application name, for servers that require communication from a specific application name. For servers that do not require a specific application name, leave this field blank. Check with your DICOM vendor, or user's manual to determine what the AE title should be. Enter values for Patient Name, Patient ID, Study ID and Study Description, if needed. In some cases MicroView may be able to provide default values based on the image loaded. Finally, hit the Send Image button to transfer the image. Manage Geometries Note MicroView 2.5.0 features an overhauled interface for handling point, surface and vector data. General purpose unstructured grids and vector fields can now be displayed in MicroView. Greater control over viewing options have also been added. This tool is used to display and manipulate 3D surface geometry objects. Surface geometries can be read from a variety of common 3D file formats , such as STL, PLOT3D and PLY formats. Loaded geometries may be superimposed on top of the current 3D image data. Surface characteristics, such as color, opacity, and whether the object is displayed as a closed surface or a wire mesh can be adjusted for each loaded surface. Finally, each surface may be selected and assigned as the default ROI for MicroView. This permits advanced ROI selections to be saved and restored, as well as allowing third-party tools to be used to generate ROI objects. Activate the \"Manage Geometries...\" plugin by selecting Visualize \u2192 Manage Geometries... from the main menu. Click the Load button to select a geometry file to load in. Multiple files can be loaded sequentially. Each surface object filename will be displayed in the list box above the Load button. Click the Show or Hide button to show or hide a selected geometry. Click the Delete button to remove a selected geometry from memory. Click the Geometry \u2192 ROI button to assign the currently selected surface as the default ROI for MicroView. Customize the color of a selected surface by clicking on the surface's color button, and adjust surface characteristics of the selected surface by checking or unchecking the Display Wireframe button. Customize the opacity of the selected surface by adjusting the opacity slider. A value of zero means the surface is completely transparent (e.g. invisible), while a value of 1.0 indicates the surface is completely opaque. Image Information Note MicroView 2.5.0 has fundamentally changed how image data is represented internally. These changes facilitate converting data between different image formats, while maintaining meta-info in DICOM-compatible format. See the \"DCM\" page for DICOM-related information. Overview This plugin displays properties about the currently loaded image and general display settings of MicroView, such as background colour, active units etc. The tool can be activated by selecting Tools \u2192 Image Information... from MicroView's main menu. Image and system properties can be viewed in one of two basic property display modes: a general mode presents as much information as possible in loosely defined categories; a DICOM-specific mode presents DICOM tags (or equivalents) for the image. Property Display Modes To view general image properties and viewing options, select the column-like icon at the top of the plugin. To view instead DICOM tags associated with this image, select the DCM icon. The third icon (a silhouette with minus sign) can be used to anonymize DICOM tags associated with the image. Property Filters Image properties can be filtered by adding filter terms in the search box at the bottom of the plugin. Filter words are case insensitive and apply to both property name and property value in both general and DICOM property display modes. You can filter on more than one search string by separating them by spaces. General Information Some fields are specific to vff format images, especially those generated by the Locus reconstruction software package: Air and water parameters, for instance, correspond to calibration values entered using the CT calibration tool in MicroView's CT Toolbox plugin. Similarly, the bone parameter value (measured in Hounsfield Units), is also a calibration value, determined as part of the Locus image reconstruction process. Some image information values (title, subject, air, water and bone values) may be edited by clicking on the value field in the image information box. Press the Enter key to accept the new value, or press the Esc key to cancel your edit session. Editing values in this way does not modify the contents of the original image file on disk -- you must explicitly save the image in order to preserve your changes. Advanced Region Grow Tool The Advanced Region Grow tool allows the user to define a ROI in a 2D or 3D image based on the connectedness of voxels with similar intensity values. Once defined, the region grown ROI may be used as MicroView's default ROI for further analysis. The tool extends the capabilities of the Region Grow tool, allowing the early termination of the growth based on a given number of iterations. It also provides the user with a mean of determining the smoothness of the final selected region. The starting point for using the Advanced Region Grow tool is typically the selection of a simple ROI, to constrain the region growing process. Selecting a small rectangular ROI around the object to be segmented will reduce the memory and time required to perform the region grow operation. Advanced Region Grow can be used without selecting a constraining ROI, but the time and memory required will be greater. Once a constraining ROI has been selected, the following operations must be performed to use the region grow tool: Activate the tool by choosing Tools \u2192 Advanced Region Grow... from the main menu. Move one of the 3D viewplanes so that it intersects the constraining ROI. Select a plane that clearly shows a slice of the object you wish to segment. Temporarily set the Window value for the main window to 1. Adjust the Level value so that the loaded image is displayed in black and white. Choose a setting such that the feature to be segmented is displayed in white. Select a threshold option from the available list. If segmenting a bright object from a darker background, select \"upper\". If segmenting a dark object from a brighter background, select \"lower\". Choose \"window\" to segment connected pixels in a range of gray-level values surrounding the current level scrollbar value. Choose the number of times Region Grow should occur by providing the \"Number of Iterations\" parameter in the plug-in. A higher number would result in the final selected region to be larger. This parameter should be changed based on the result obtained. Adjusting this value would allow the user to stop the tool from selecting undesired regions. Pick a starting point (e.g. a pick point) for the region grow operation by positioning the mouse cursor over the object of interest within the constraining ROI. Hit the Space key to select the 3D point. Once a pick point has been selected, the Advanced Region Grow tool will determine a set of connected voxels. The tool will highlight this collection of voxels in green in both the 3D and 2D viewports. In the results section of the region grow tool, the volume and centroid of the group of voxels will be displayed. Press the View Centroid button to move the 3D cut-planes so that they intersect at the centroid of the selected ROI. Press the Geometry \u2192 ROI to assign the results of this tool to the default ROI for further analysis. Once assigned, the green highlighted voxels will turn yellow, indicating the new choice of system-wide ROI. Slab Project The Slab Project tool accumulates images from a collection of image slices surrounding the currently image planes and displays them using one of a variety of different functions: minimum, maximum, mean and sum. The tool can operate on either on a finite slab of images or the entire collection of data. It can produce oblique, so-called 'Live View' images, or produce a new static image as it's output. Note This tool serves as a replacement for the 'MIP Image' tool found in older versions of MicroView. Using Slab Project Activate the Slab Project plugin by selecting Visualize \u2192 Slab Project... from the main menu. To enable slab projection, choose 'Oblique Live View', 'X-', 'Y-' or 'Z-' axis projections. The first option will produce output in currently selected 3D viewport, while the remaining three options will generate a new output window. Select an accumulation function: 'Min', 'Max', 'Mean' or 'Sum'. Click the Apply button to generate the slab projection. For 'Live View' mode, interacting with the 3D viewport slice position will change the appearance of the slab. Select File \u2192 Save Snapshot... to save a snapshot of the slab image. Snapshot images are always 8-bit images, and take advantage of the current window/level settings in the slab project window. CT Toolbox The CT Toolbox plugin consists of a collection of tools, useful for day-to-day analysis of CT image data. The plugin can be used to: perform Hounsfield image calibration of GE preclinical scanner data perform image unwarp and bright/dark field corrections remove rings interactively from a 3D CT dataset Note This plugin is designed to supersede the original CT Calibration Tool plugin, found in earlier releases of MicroView. This plugin allows the user to measure three different ROI's within an image, and save/restore these values. The purpose of saving three sets of ROIs is so that the reconstruction software can automatically determine air, water and bone calibration constants. Activate the CT Toolbox plugin by selecting Tools \u2192 CT Toolbox... from the main menu. Define a ROI with only air by using either the 7 / 8 keys,or by selecting a ROI using the ROI plugin ( Plugins \u2192 ROI Selection Tool... on the MicroView menu) and click the corresponding Save button. Similarly do the same for water and bone. Once the ROI's for air, water, and bone have been selected and the settings have been saved, click one of the Load buttons and the corresponding ROI will appear. Make Movie Note The Movie Maker plugin now uses OpenCV to generate movies in a variety of different output formats. The specific codec list available is platform dependent. This plugin allows the user to make a movie of a sequence of screen snapshots, while the loaded image is either rotated 360 degrees about an axis, or sliced along a cutplane. Sequences can be accumulated together to build more complex movies. Individual orientations can also be controlled by using stationary snapshots. Select Visualize \u2192 Make Movie... to load the movie maker. Next: Select the type of animation desired in the Animation Type drop-down menu. The X/Y/Z Rotation entries correspond to animations of the image scene while rotating the image about the selected axis. The X/Y/Z Slicing entries generate an animation of the image scene while slicing through the entire image along the selected image axis. Select from one of a number of movie file types. Enter the number of snapshot images to take while generating a movie sequence. For rotation-type movies, this number will determine how many degrees to rotate the image scene between each image and the next. Press the Add sequence button to start the movie making process. For the first sequence only, you will be prompted to select an output filename. Additional sequences can be added to the movie by repeating the above steps until the entire movie is produced. Finally, close and finish generating the movie by clicking the Finish button. Point Picker MicroView's point picker tool is used to make a set of landmark measurements on an image, and to save these measurements to disk. Start the tool by selecting Plugins \u2192 Point Picker... from the main menu. Once loaded: Position the mouse cursor over a point of interest in either 3D or 2D viewports Press the Space key to place a marker at the current mouse position Press the Accept button, or Enter key, to permanently accept the marker position, or reposition the mouse and hit the Space key again to move the marker For each marker, the 3D coordinate will be recorded in the table contained in the measurement tool. Additional column space reserved for adding comments to each line Press the Save... button to save the current marker positions to disk Captions for each landmark can be optionally displayed floating beside each landmark Additional support for the display of a rectangular-shaped ROI about each landmark is available Interactive Shell From MicroView's interactive shell, images can be interrogated and manipulated easily. The toplevel python variable images is a list of images, indexed by each loaded images tab number, which is displayed on each image's Viewer tab.","title":"Tools and Plugins"},{"location":"tools-and-plugins/#tools-and-plugins","text":"This section describes the various extension plugins which are available for MicroView.","title":"Tools and Plugins"},{"location":"tools-and-plugins/#roi-manager","text":"This tool facilitates the use of multiple regions of interest ( ROI ) within MicroView. ROI are unmanaged until added to the ROI Manager. Once added to the ROI Manager, the originating plugin that created the ROI can move on to generate a new ROI, or in fact, can be closed without losing a reference to the ROI object. The ROI Manager can remember, display, activate, and apply Boolean operations to regions of interest.","title":" ROI Manager"},{"location":"tools-and-plugins/#adding-roi","text":"To have the ROI Manager remember the active ROI, click Add Current ROI and provide a name. The name you provided now appears in the ROI Objects list. The active ROI is now managed. To save a ROI to disk, select a ROI from the ROI Objects list and click Save. The ROI Manager uses the VTK Image or vti format to store ROI on disk. The ROI Manager supports loading of VTK Image files that are created using the save functionality above, as well as the file formats previously supported with the Geometry Manager tool, such as VTK . To load a ROI from disk, click Load and locate the appropriate file. To delete a managed ROI, select the ROI from the ROI Objects list and click Delete. Click Delete All to remove all ROI from the list.","title":"Adding ROI"},{"location":"tools-and-plugins/#displaying-roi","text":"Displaying a ROI does not make a ROI active. That is, displayed ROI do not affect any of MicroView's plugins or the calculations that they perform. To activate a ROI, see the next section \"Activating ROI\". To display a managed ROI, select a ROI in the ROI Objects list. Now click Show. You can display multiple ROI simultaneously. To remove the ROI from the display, click Hide. You have several options to control the visual presentation of the ROI. To view all displayed ROI as binary masks, choose the Mask option. To view the displayed ROI as 3D objects, choose the \"Geometry\" option. The Display Characteristics tab contains options that control the presentation of individual ROI. If you are using the \"Geometry\" display option, then select \"Display Wireframe\" to view a wireframe mesh of the ROI or de-select to view the ROI as a solid object. The \"Surface color\" and \"Surface Opacity\" fields control the colour and translucency of the ROI respectively. When viewing ROI using the \"Geometry\" option, the colour and opacity of each ROI can be controlled independently. When viewing ROI using the \"Mask\" option, the colour of each ROI may be controlled independently, but the opacity affects all of the ROI currently viewed simultaneously.","title":"Displaying ROI"},{"location":"tools-and-plugins/#activating-roi","text":"The active ROI affects MicroView's plugins. To activate a ROI, select its name in the ROI Objects list and click Activate. Only one ROI can be active. The \"Active ROI\" field at the top of the ROI manager displays the name of the active ROI. Creating a new ROI supplants the active ROI.","title":"Activating ROI"},{"location":"tools-and-plugins/#applying-boolean-operations-to-roi","text":"You can apply Boolean operations to existing ROI to create new ROI. The figure illustrates the effects of the different Boolean operations: NOT inverts the ROI; OR combines two ROI; AND intersects two ROI; and XOR gives the ROIs' respective unique points. To apply a Boolean operation, open the Combine ROIs tab. Select the ROI and the operation you desire to perform. Note that NOT operates on a single ROI. Click Do Operation to execute the operation. The resulting ROI is added to the ROI Objects list.","title":"Applying Boolean Operations to ROI"},{"location":"tools-and-plugins/#visualizing-3d-data","text":"The ROI Manager's 3D display capabilities can be used to create impressive graphical presentations of data. As an alternative to MicroView's Volume Rendering plugin, you can display several ROI simultaneously using the Geometry option. This is particularly advantageous when using the Movie Maker plugin: rendering the ROI is faster than the volume rendering.","title":"Visualizing 3D Data"},{"location":"tools-and-plugins/#simple-analysis-tools","text":"","title":"Simple Analysis Tools"},{"location":"tools-and-plugins/#point-1d","text":"At any time while the mouse cursor is over the volume, the coordinates and gray-scale value will appear in the bottom left-hand corner of the 3D viewport. You can change between displaying coordinates in mm or pixels, in MicroView's application settings dialog ( Edit \u2192 Application Settings... ).","title":"Point (1D)"},{"location":"tools-and-plugins/#line-2d","text":"A line segment can be selected for analysis by performing the following steps: Position the mouse cursor over an image in any of the viewports. Press the 1 key to mark the beginning of the line. Press the 2 key to mark the end of the line. or - Select Edit \u2192 Show Line to display a line in the center of the image immediately Green and blue markers will be drawn in the 3D viewport, indicating the beginning and ending of the line, respectively. The marks can be dragged interactively about each viewport by selecting the marker using the middle button. Re-select the endpoints at any time by pressing either of the 1 and 2 keys. Clear the line by pressing the y key. Once a line segmented has been selected, use any of the following hotkeys to perform a 2D analysis: 2D Keyboard Hotkeys HotKey Result a Saves the end-points of the line tool, and gray-scale values measured along the selected line to a text file. p Plots the gray-scale values along the selected line. y Removes the line from the viewport.","title":"Line (2D)"},{"location":"tools-and-plugins/#volume-3d","text":"Select a 2D or 3D region of interest (ROI) using any of MicroView's ROI tools . Once a ROI is selected, use any of the following hotkeys to perform 2D/3D analysis: 3D Keyboard Hotkeys Hot Key Result c Removes the active ROI from the screen. g Plots the histogram of the gray-scale values within the ROI. m Calculates the mean and standard deviation of the gray-scale values within the ROI. s Saves the boundary coordinates of the standard ROI to a file. v Saves the ROI to an image file. d Saves the gray-scale values to a text file. Selection region must be two dimensional. u Saves the area to an image file (2D ROI selection only). Del Sets voxel values, within the currently defined ROI to a user-defined value (defaults to zero). Use this key to mask out regions of an image. Shift + Del Sets voxel values, outside the currently defined ROI to a user-defined value (defaults to zero). Use this key combination to mask out everything outside a ROI.","title":"Volume (3D)"},{"location":"tools-and-plugins/#line-profile-window","text":"","title":"Line Profile Window"},{"location":"tools-and-plugins/#overview","text":"MicroView can plot a profile of pixel data along a user-defined line . First, select the start and end points of the line, then press the p key to plot the data profile.","title":"Overview"},{"location":"tools-and-plugins/#interacting-with-the-plot-window","text":"Use the left mouse button to interactively click and drag a region of interest in order to zoom in on the plotted data. Multiple levels of zooming can be achieved by repeating the click-and-drag method. Zoom out by clicking with the right mouse button. Reset the plot window by clicking the Reset button at the bottom of the plot window, selecting View \u2192 Reset , or by pressing the r key. Optionally display symbols over each data point, by selecting View \u2192 Symbols . Measurements along the 2D pixel profile may be made by positioning the mouse cursor over a feature within the plot window and pressing the 1 key, then selecting a second feature and pressing the 2 key. A horizontal red line will be drawn between the two features. Once drawn, the endpoints can be moved, either by using the 1 / 2 key combination, or by adjusting the endpoint values in the editable text fields below the plot area. Mouse cursor position and selected line length are displayed in the bottom center of the plot window. This feature is particularly useful for measuring full-width half-max (FWHM) distances on peaks in a unbiased, systematic fashion.","title":"Interacting with the Plot Window"},{"location":"tools-and-plugins/#saving-data","text":"The plot window data can be exported to disk in one of two ways: Select File \u2192 Save Data... to save the line profile to disk in a simple text format Select File \u2192 Save Snapshot... to save a screen capture of the plot window to one of a number of common image file formats","title":"Saving data"},{"location":"tools-and-plugins/#histogram-window","text":"MicroView can plot a histogram of pixel values within a 2D or 3D ROI. To plot a histogram of data, first select a ROI , then press the g key to activate the histogram window. The control of the histogram window is similar to the control of the 2D profile plot window . The histogram window has the following additional features: The Auto Threshold button can be used to automatically determine an optimal threshold value for use in the isosurface tool or Advanced Bone Analysis application . The value will be selected using the method of Otsu. A red arrow will be displayed on the x-axis of the plot after hitting this button, indicating the threshold value. In addition, the window/level settings in MicroView will be adjusted to reflect this threshold value, as a convenience. The user can selectively interrogate a range of data within the histogram. For this selected range of values, the total number of voxels in the selected range and corresponding volume fraction are reported. To select a range of voxel values, place the cursor on the graph in the plot window and press the middle mouse button. Drag the mouse and release the button once the desired range of voxel values have been highlighted, in red. Check the Highlight selected region checkbox to adjust the image display in the 3D and all 2D viewports of the main window, so that voxels corresponding to the selected value range will be highlighted. Selected ranges can be converted to an active ROI by first highlighting a region, as described above, then clicking the Highlight \u2192 ROI button . The highlighted red region will become yellow, indicating that the selected values are now the active ROI. The user can select different bin sizes for the histogram. Select from one of the menu entries under Options \u2192 Bin Size to adjust the bin size.","title":" Histogram Window"},{"location":"tools-and-plugins/#advanced-bone-analysis-application","text":"","title":"Advanced Bone Analysis Application"},{"location":"tools-and-plugins/#overview_1","text":"MicroView's Advanced Bone Analysis Application performs a variety of analysis and visualization tasks upon a selected region of interest within an image. The application is designed specifically for analysis of CT images of bone. The choice of which functions to perform on a given ROI , what type of visualization output to use, and how the current project or study should be structured can be selected prior to any calculation. It is possible to export the results to any or all of the following formats: plain text, CSV, Excel, or PDF. The Advanced Bone Analysis Application contains the following analysis tools: BMD , which reports the bone mineral density (BMD), bone volume fraction (BVF), bone mineral content, and various other statistics; SMI , which reports the structure model index (SMI). SMI gives information about the curvature of the surface, and estimates how \"plate-like\" or \"rod-like\" a trabecular structure is; Anisotropy , which determines the degree of symmetry and orientation of a trabecular structure; Stereology , which reports Euler index, bone volume fraction, bone surface to bone volume ratio, trabecular plate thickness, trabecular plate number, trabecular plate separation and various other measures. The Euler index is a measure of the connectivity of a trabecular structure; Topology , which categorizes each voxel in a trabecular structure as being a member of either a surface, curve, or junction and provides a visual representation of this classification; Direct Measures , which determines the local trabecular thickness of a bone, and provides a visual representation of this local thickness, and; Cortical Bone Analysis , which determines slice-by-slice thickness, area, moment of inertia, and BMD values for cortical bone. It is to be used in conjunction with the Cortical ROI tool to perform analysis on the cortical shell of a bone.","title":"Overview"},{"location":"tools-and-plugins/#using-the-advanced-bone-analysis-application","text":"Activate the Advanced Bone Analysis Application by selecting Analyze \u2192 Bone Analysis... from MicroView's menu, or by clicking on the Bone Analysis button in the Applications group of MicroView's toolbar . If an ROI has not already been selected, first activate an ROI plugin and select a ROI. As a convenience, the list of available ROI plugins is displayed in the choice-box in the upper left of the plugin: Choose an ROI tool in the available drop-down list, then hit the Activate ROI button to launch the tool. Once a ROI has been selected, enter a gray-level threshold value, that will be used to discriminate bone from non-bone voxels in the image. Either type in a threshold value in the entry field in the Threshold section or click the Auto Threshold button, to determine a best-guess threshold value automatically. If you would like to verify that the automatically selected value is appropriate, generate a histogram of the image contained within the ROI, then hit the Auto Threshold button on the histogram plot window. In the Bone Parameters section select the type of analysis desired. Click the Advanced Options... button to modify the default settings. The Advanced options will be discussed in more detail later in this section. In the Output Options section select the name of the file where the results will be stored. The results are written to an XML database file. These results are presented for review in a custom spreadsheet view. This spreadsheet view allows the results to be exported to one of the supported file formats (text, CSV, Excel, PDF). If no project file name is provided, the analysis cannot be performed. It is also possible to select an existing database file using the Load Project button. The new results can then be added to this database. More information regarding the project database can be found here . In the Visualization Options select RAW, Topology, Anisotropy, or Direct Measures. The options Topology, Anisotropy and Direct Measures will only be available for selection if they have been selected in the Cancellous Bone Parameters section. If one of these three options is selected, MicroView will shift focus from the Advanced Analysis dialog to the appropriate dialog for visualization when the Run button is clicked. Click the Run button.","title":"Using the Advanced Bone Analysis Application"},{"location":"tools-and-plugins/#advanced-options","text":"The Advanced Options allows the user to modify the default settings. To display the Advanced Options dialog click the Advanced Options button. In the Advanced Options dialog there are several tabs: The BMD tab has several variables that can be edited manually. By default the values for Bone ADU (arbitrary density unit) and Water ADU are set to the calibration constants found in the header of image file. The Lower Exclusion ADU is a gray scale value below which voxels are not included in the bone equivalent mass calculation. Similarly the Upper Exclusion ADU is a Gray scale value above which voxels are not included in the bone equivalent mass calculation. The upper and lower exclusion ADU should be set to exclude air and metal, respectively, in the bone mass calculation. The SMI tab has options to smooth the image prior to the generation of an isosurface and to smooth the isosurface prior to the calculation of SMI. In the Anisotropy tab, the Grid Spacing determines how finely the ROI is to be resampled prior to any calculations, the Number of Tests determines the number of lines to use when calculating mean intercept length (MIL), and Random Testing Angles determines whether the direction of the lines used when calculating MIL are randomly chosen. In the Direct Measures tab, the user has an option of what measures to compute \u0096 direct trabecular thickness, direct trabecular spacing, or both. The Minimum Feature Size in pixels can also be specified. Structures less than this size will not be used in calculating direct trabecular thickness and direct trabecular spacing. The Stereology tab, has an option to enable verbose output to display additional measures, and an option to enable the purify algorithm. To obtain meaningful results from Stereology, the image should be passed through this purification filter first. The purify algorithm removes spurious unconnected region. After all the modifications to the Advanced Options have been made, click the OK button to close the dialog.","title":"Advanced Options"},{"location":"tools-and-plugins/#specific-tool-information","text":"","title":"Specific Tool Information"},{"location":"tools-and-plugins/#bone-composition-measurement-tool","text":"This tool performs a virtual biopsy and \"ashing\" to determine bone mineral content non-destructively. Image data derived from the Locus family of CT scanners may be calibrated to standard CT number, measured in Hounsfield Units (HU), and furthermore calibrated to permit determination of equivalent mass of hydroxyappetite. Results are reported as bone mineral fraction (BVF) or bone mineral density (BMD) in units of mg (HyAp)/cm 3 . To use this tool, launch the Advanced Bone Analysis application, define a 3D ROI, then select a threshold that discriminates bone from soft tissue. Prior to hitting the Run button, if required, click the Advanced Options... button to modify the BMD tool settings: Enter a value for Bone ADU Enter a value for Water ADU Enter a value for Lower Exclusion ADU Enter a value for Upper Exclusion ADU","title":"Bone Composition Measurement Tool"},{"location":"tools-and-plugins/#smi-tool","text":"Structure model index (SMI) is a parameter used to measure how \"rod-like\" or \"plate-like\" trabecular architecture is. With aging and disease, cancellous bone architecture in some sites deteriorates from plate-like to rod-like. SMI for ideal plates and rods is 0 and 3, respectively. SMI calculated for specimens with high bone volume fraction (BV/TV) can be negative.","title":"SMI Tool"},{"location":"tools-and-plugins/#outputs","text":"SMI (unitless) - the SMI parameter Volume - the volume within the isosurface S.A. - the surface area of the isosurface Delta_R - distance along the normal direction each vertex is translated to estimate SA_Prime SA_Prime - surface area derivative","title":"Outputs"},{"location":"tools-and-plugins/#algorithm","text":"The SMI parameter is discussed in detail in Hillebrand97a. SMI is calculated as \\frac{6(S'V)}{S^2} \\frac{6(S'V)}{S^2} where S' S' is the surface area derivative, V V is the trabecular bone volume, and S S is the surface area. The factor of 6 is used to obtain integer values for ideal plate, cylinder, and sphere models (plate = 0, cylinder = 3, sphere = 4). The first step in calculating SMI is to create an isosurface of the trabecular bone within the ROI. The surface area and volume are directly calculated from this isosurface. The surface area derivative is estimated by calculating the change in surface area of the isosurface when the vertices are translated a small amount along their normal directions and normalizing by the magnitude of the displacement. Note SMI was initially used to describe structures with very few intersections between the structure elements (i.e., rods and plates) while the BV/TV is low. SMI parameter is always positive for these structures. However, if SMI analysis is applied on a dense structure with lots of intersections between the structure elements, it may give negative SMI values. This results from the surface area decreasing when dilating the surface vertices along the normals and consequently a negative S' in the equation for SMI. For example, take a plate with a hole in the center. The hole becomes smaller after the vertices are translated in the normal direction and the corresponding change in surface area is negative. Note For a ROI with more than 27 000 000 (300x300x300) voxels, the ROI image is resampled by shrinking factors 2 by 2 by 2 to reduce memory consumption and speed up the calculation.","title":"Algorithm"},{"location":"tools-and-plugins/#advanced-options_1","text":"Smooth Isosurface (default value: ON) - uses a windowed sinc function as interpolation kernel to 'relax' the mesh, making the cells better shaped and the vertices more evenly distributed. The windowed sinc function is a low-pass filter that eliminates the high frequency noise and keeps the low frequency features of bone surfaces. Smooth Raw Image (default value: OFF) - passes data through a Gaussian filter prior to creating isosurface. The default kernel size is 3x3x3 and default standard deviation is 1. The user can set these parameters in the advanced options.","title":"Advanced Options"},{"location":"tools-and-plugins/#anisotropy-tool","text":"Anisotropy measures the orientation of the trabecular architecture. This orientation affects the mechanical behavior of trabecular tissue and is affected by age and disease. MicroView uses the mean intercept length (MIL) method to calculate the structural anisotropy. This method measures the intersections of a test grid with the trabecular structure and calculates the fabric ellipsoid (3D ellipse). Trabecular structures with no preferred orientation have a spherical ellipsoid, while structures with more alignment in one direction have the major axis of the ellipse aligned in that direction.","title":"Anisotropy Tool"},{"location":"tools-and-plugins/#output","text":"Ellipsoid Coefficient Eigenvector, value and principle MILs Ratios: a1/a3, a1/a2, a2/a3","title":"Output"},{"location":"tools-and-plugins/#algorithm_1","text":"A grid of parallel test lines is passed though the ROI and the number of intersections of the test lines with the bone/marrow interface is calculated. This procedure is performed for the number of test rotations listed in the advanced options. Each rotation of the test grid is described by two angles (theta, phi) in spherical coordinates. For each rotation, MIL is calculated as 2* BV/TV / (number of intersections / test line length). The MIL data are then fit to the equation of an ellipse using least squares. The least squares analysis provides the 6 coefficients for the best fit ellipse. An eigen analysis of the second rank tensor formed by these coefficients provides the length of the axes of the ellipsoid and their corresponding directions. The degree of anisotropy is then defined as the ratio of the lengths of the maximum and minimum axes.","title":"Algorithm"},{"location":"tools-and-plugins/#advanced-options_2","text":"Random Test Angles (default: ON) - when checked, the test grid is rotated through pseudo-random angles; otherwise the test grid is rotated step by step in theta and phi with a constant stride. Number of Rotations (default: 200) - number of rotations of the test grid Grid Spacing (default: 3) - spacing (in voxels) between test lines","title":"Advanced Options"},{"location":"tools-and-plugins/#stereology-tool","text":"MicroView can perform a simple stereology analysis of a 3D bone image. The stereology tool measures trabecular structure using similar techniques to those implemented in classical histomorphometry . 2D techniques determine estimates of trabecular thickness, spacing and density. At the same time, trabecular connectivity is quantified by calculating the Euler number for the trabecular structure. Finally, the bone surface area to volume ratio is also calculated. To perform a stereology analysis on a CT image of a bone, launch the Advanced Bone Analysis application, define a 3D ROI, then select a threshold that discriminates bone from soft tissue. Prior to hitting the Run, if required, click the Advanced button to modify the Stereology tool settings:","title":"Stereology Tool"},{"location":"tools-and-plugins/#advanced-options_3","text":"Turning on Enable verbose output will generate additional output measures. Turn on the Enable purify algorithm for Euler No. calculation option to pass the selected image through a purification algorithm, first, before computing the Euler number. The purify algorithm removes isolated bony spicules and fills encapsulated marrow spaces. !!! Note When the purify algorithm is enabled, select a ROI where at least one of the voxels at the boundary of the ROI is equal to or above the threshold (ie. the trabecular bone must intersect the boundaries of the ROI). Passing a clipped image, through the purify filter, which has no boundary voxels equal to or above the threshold will produce a blank image from the filter. Turn on the Enable purify algorithm for all other calculations option to pass the selected image through a purification algorithm, first, before performing the other calculations. Topology Plugin","title":"Advanced Options"},{"location":"tools-and-plugins/#topology","text":"Warning This plugin may not be available in all versions of MicroView. This plugin can be used to determine a 3D topology of each voxel in a trabecular bone structure. Define a 3D ROI by using either the 7 / 8 keys,or by selecting a ROI using the ROI plugin ( Plugins \u2192 ROI Selection Tool... on the MicroView menu). Once a ROI has been defined, activate the Topology plugin by selecting Topology... from the Plugins menu. Enter the desired file name in the Output File text window. Click the Calculate button to generate a topological image within the selected ROI and create a report (see Output File ). Click the Show Overlay or Hide Overlay button to show or hide the topological image. Once the topological image is overlaid on the original image, the transparency of topological image can be adjusted by the checkboxes and sliders. The voxels of the topological image are classified as follows: DENS - topological skeleton CE - curve edge SE - surface edge C - curve interior S - surface interior CC - curve-curve junction SC - surface-curve SS - surface-surface PE - profile-edge PI - profile interior","title":"Topology"},{"location":"tools-and-plugins/#direct-measures-tool","text":"Direct Measures Direct Measures calculates the trabecular thickness ( Tb.Th Tb.Th ) and separation ( Tb.Sp Tb.Sp ) by fitting maximal spheres to the trabecular structure. The diameters of the spheres within the bone and marrow regions provide estimates of Tb.Th Tb.Th and Tb.Sp Tb.Sp , respectively.","title":"Direct Measures Tool"},{"location":"tools-and-plugins/#output_1","text":"Tb.Th Tb.Th - mean trabecular thickness Tb.Sp Tb.Sp - mean trabecular separation Histogram of voxels within spheres of incremental sizes determined in the Advanced Options","title":"Output"},{"location":"tools-and-plugins/#algorithm_2","text":"The algorithm is discussed in detail in. The first step is to binarize the data based on the selected threshold. For trabecular thickness, the Euclidean Distance Transform of the bone region is calculated. This results in each bone voxel being assigned a value corresponding to the distance to the nearest non-bone voxel. Next, for each bone voxel the largest sphere that fits within the bone structure is determined. Tb.Th Tb.Th and Tb.Sp Tb.Sp are then calculated as the mean value assigned to all bone and marrow voxels, respectively.","title":"Algorithm"},{"location":"tools-and-plugins/#advanced-options_4","text":"Min Feature Size - determines the minimum diameter sphere used when calculating the mean value for Tb.Th Tb.Th and Tb.Sp Tb.Sp . Histogram Bin Size - sets the bin width for the Tb.Th Tb.Th and Tb.Sp Tb.Sp histograms What to measure? - sets which parameters are measured Direct Trabecular Thickness Direct Trabecular Separation Direct Tb.Th Tb.Th and Tb.Sp Tb.Sp Note There is a limitation for ROI dimensions, which is 650x650x650. The accuracy of the Tb.Th Tb.Th and Tb.Sp Tb.Sp calculation is 0.01 voxel.","title":"Advanced Options"},{"location":"tools-and-plugins/#cortical-analysis-tool","text":"Cortical Analysis Cortical analysis is designed to be applied to the cortical shell of a bone such as a femur or humerus. The algorithm measures a wide number of different parameters of utility. Note The cortical analysis tool assumes that the bone is aligned with the long axis parallel to the z-axis defined in MicroView. If your sample is not oriented in this way, it must be reoriented for the results to be meaningful.","title":"Cortical Analysis Tool"},{"location":"tools-and-plugins/#output_2","text":"By default, the output values are reported for the entire ROI. Using an advanced option, it is possible to have the values reported on a slice-by-slice basis. Angle X - the angle between the x-axis of the ROI and the original x-axis (not available in slice-by-slice data) Angle Y - the angle between the y-axis of the ROI and the original y-axis (not available in slice-by-slice data) Angle Z - the angle between the z-axis of the ROI and the original z-axis (not available in slice-by-slice data) Number of Slices - number of slices in the ROI (not available in slice-by-slice data) Mean Thickness - the average thickness of the cortical bone Std Dev Thickness - the standard deviation of the thickness of the cortical bone Ixx - the moment about the x-axis of the cortical bone Iyy - the moment about the y-axis of the cortical bone Izz - the moment about the z-axis of the cortical bone Ixy - the bending xy moment of the cortical bone Inner Perimeter - the inner perimeter of the cortical bone Outer Perimeter - the outer perimeter of the cortical bone Marrow Area - the area contained inside the cortical bone Cortical Area - the area of the cortical bone only Total Area - the total cross-sectional area of the bone BMD - Bone mineral density BMC - Bone mineral content Centroid - the position of the centroid of the volume","title":"Output"},{"location":"tools-and-plugins/#algorithm_3","text":"The first parameters computed are the moments and the centroid location. Once the centroid location has been determined, rays are projected from this location towards the edge of the ROI. When the ray first intersects the edge of the cortical bone, this point is noted as an interior point. When the ray intersects the second edge of the cortical bone, this is noted as an exterior point. The lists of interior and exterior points are then used for thickness, perimeter and area computations.","title":"Algorithm"},{"location":"tools-and-plugins/#advanced-options_5","text":"Report individual slice data - turns on reporting of all output measures listed above but on a slice-by-slice basis rather than for the entire volume Report radial thickness data - turns on reporting of cortical thickness measurements at ten degree intervals around the circumference of each slice Perform mass normalization of moments - normalizes all of the moment measures by the total mass of cortical bone","title":"Advanced Options"},{"location":"tools-and-plugins/#basic-bone-analysis-application","text":"","title":" Basic Bone Analysis Application"},{"location":"tools-and-plugins/#overview_2","text":"MicroView's Basic Bone Analysis Application performs a variety of analysis upon a selected region of interest within an image. The application is designed specifically for analysis of CT images of bone. The choice of which functions to perform on a given ROI , can be selected prior to any calculation. The results could be stored or appended in user specified plain text files. The Basic Bone Analysis Application contains the following analysis tools: BMD , which reports the bone mineral density (BMD), bone volume fraction (BVF), bone mineral content, and various other statistics; Stereology , which reports Euler index, bone volume fraction, bone surface to bone volume ratio, trabecular plate thickness, trabecular plate number, trabecular plate separation and various other measures. The Euler index is a measure of the connectivity of a trabecular structure. Tip The commercial package Advanced Bone Analysis Application contains analysis tools for SMI, Anisotropy, and Stereology. It also offers project and study management tools and support PDF and Excel outputs.","title":"Overview"},{"location":"tools-and-plugins/#using-the-basic-bone-analysis-application","text":"Activate the Basic Bone Analysis Application by selecting Analyze \u2192 Bone Analysis... from MicroView's menu, or by clicking on the Bone Analysis button in the Applications group of MicroView's toolbar . If an ROI has not already been selected, first activate an ROI plugin and select a ROI. As a convenience, the list of available ROI plugins is displayed in the choice-box in the upper left of the plugin: Choose an ROI tool in the available drop-down list, then hit the Activate button to launch the tool. Once a ROI has been selected, enter a gray-level threshold value, that will be used to discriminate bone from none-bone voxels in the image. Either type in a threshold value in the entry field in the Threshold section or click the Auto Threshold button, to determine a best-guess threshold value automatically. If you would like to verify that the automatically selected value is appropriate, generate a histogram of the image contained within the ROI, then hit the Auto Threshold button on the histogram plot window. In the Bone Parameters section select the type of analysis desired. Click the Advanced Options... button to modify the default settings. The Advanced options will be discussed in more detail later in this section. In the Output File section select the name of the file where the results will be stored. The results are written to a plain text file. These results are presented for review after each successful execution. It is also possible to append the results to an existing text file by checking the Append checkbox button. Click the Run button to perform the analysis.","title":"Using the Basic Bone Analysis Application"},{"location":"tools-and-plugins/#advanced-options_6","text":"The Advanced Options allows the user to modify the default settings. To display the Advanced Options dialog click the Advanced Options... button. In the Advanced Options dialog there are several tabs: The BMD tab has several variables that can be edited manually. By default the values for Bone ADU (arbitrary density unit) and Water ADU are set to the calibration constants found in the header of the currently loaded image file (not all file types support this). The Lower Exclusion ADU is a gray scale value below which voxels are not included in the bone equivalent mass calculation. Similarly the Upper Exclusion ADU is a Gray scale value above which voxels are not included in the bone equivalent mass calculation. The upper and lower exclusion ADU should be set to exclude air and metal, respectively, in the bone mass calculation. The Stereology tab, has an option to enable verbose output to display additional measures, and an option to enable the purify algorithm. To obtain meaningful results from Stereology, the image should be passed through this purification filter first. The purify algorithm removes spurious unconnected region. After all the modifications to the Advanced Options have been made, click the OK button to close the dialog.","title":"Advanced Options"},{"location":"tools-and-plugins/#specific-tool-information_1","text":"","title":"Specific Tool Information"},{"location":"tools-and-plugins/#bone-composition-measurement-tool_1","text":"Bone Composition This tool performs a virtual biopsy and \"ashing\" to determine bone mineral content non-destructively. Image data derived from the Locus family of CT scanners may be calibrated to standard CT number, measured in Hounsfield Units (HU), and furthermore calibrated to permit determination of equivalent mass of hydroxyappetite. Results are reported as bone mineral fraction (BVF) or bone mineral density (BMD) in units of mg (HyAp)/cm 3 . To use this tool, launch the Advanced Bone Analysis application, define a 3D ROI, then select a threshold that discriminates bone from soft tissue. Prior to hitting the Run button, if required, click the Advanced Options... button to modify the BMD tool settings: Enter a value for Bone ADU Enter a value for Water ADU Enter a value for Lower Exclusion ADU Enter a value for Upper Exclusion ADU","title":"Bone Composition Measurement Tool"},{"location":"tools-and-plugins/#stereology-tool_1","text":"Stereology MicroView can perform a simple stereology analysis of a 3D bone image. The stereology tool measures trabecular structure using similar techniques to those implemented in classical histomorphometry . 2D techniques determine estimates of trabecular thickness, spacing and density. At the same time, trabecular connectivity is quantified by calculating the Euler number for the trabecular structure. Finally, the bone surface area to volume ratio is also calculated. To perform a stereology analysis on a CT image of a bone, launch the Advanced Bone Analysis application, define a 3D ROI, then select a threshold that discriminates bone from soft tissue. Prior to hitting the Run, if required, click the Advanced button to modify the Stereology tool settings: Optionally click on the Enable Purify option to pass the selected image through a purification algorithm, first, before performing the stereology analysis. The purify algorithm removes isolated bony spicules and fills encapsulated marrow spaces. Note: When the purify algorithm is enabled, select a ROI where at least one of the voxels at the boundary of the ROI is equal to or above the threshold (ie. the trabecular bone must intersect the boundaries of the ROI). Passing a clipped image, through the purify filter, which has no boundary voxels equal to or above the threshold will produce a blank image by the filter. Optionally uncheck the Enable verbose output to disable the verbose output.","title":"Stereology Tool"},{"location":"tools-and-plugins/#image-registration-and-fusion-application","text":"Image Registration","title":"Image Registration and Fusion Application"},{"location":"tools-and-plugins/#overview_3","text":"Image registration is the process of finding a spatial transform that co-aligns two images, such that homologous features in both images (i.e. identical landmarks in the two distinct images) are given the same spatial coordinate. This is commonly performed so that the two images may be displayed superimposed together (i.e. fused) in a fashion that makes corresponding features easily viewed and identified. MicroView's register tool is designed for manual landmark registration. Manual landmark registration involves picking two sets of homologous landmarks from so-called \"fixed\" and \"moving\" images. A simple sum of least squares fitting algorithm is then used to determine the transformation to map the moving image to the coordinate system of the fixed image based on the landmarks selected. There is an option in this registration tool that allows the user to select the type of transform to be performed. The options are rigid body, similarity, and full affine transformations. Once images are registered they can be visualized through synchronization and/or fusion. For example, an image gathered from a positron emission tomography (PET) scanner provides functional information whereas an image obtained from a computed tomography (CT) scanner provides information regarding the structure and anatomy of the specimen. Synchronization and fusion will correlate the structural and functional information.","title":"Overview"},{"location":"tools-and-plugins/#using-the-register-tool","text":"Activate the Register Tool by selecting Plugins \u2192 Register... from MicroView's menu or by clicking on the Register button in the Applications group of MicroView's toolbar. The registration process is divided into the following 3 main steps: Loading Images and Layout Setup Landmark Registration Visualization Notice that a toggle button appears beside the window/level slides when the Register Tool is activated. Click on the button to toggle the control of the window/level slides to the left and right images.","title":"Using the Register Tool"},{"location":"tools-and-plugins/#loading-images-and-layout-setup","text":"Click the Images and Layout tab to activate this page. Click the Fixed Image (Left) button and select the fixed image when the Open dialog appears. The fixed image is also called the target image. It is displayed on the left side. Click the Moving Image (Right) button and select the moving image when the Open dialog appears. The moving image is also called the source image. It is displayed on the right side. Select the views desired in the Layouts section and click the Set button. The view settings can be changed at any time during the registration process.","title":"Loading Images and Layout Setup"},{"location":"tools-and-plugins/#landmark-registration","text":"Landmarks Click on the Register tab to activate this page. Following are the typical steps to do landmark registrations: To select landmarks on images, position the cursor over a landmark in either image and then press the Space on the keyboard. Do the same to the other image to find the corresponding landmark. The selected pair of landmarks are shown as orange marks. At the same time, the coordinates of the landmarks are displayed in a row in the table on the left panel, which is highlighted in orange color and begins with a ? mark. These two landmarks can be moved around by moving the mouse to new positions and then pressing the Space . Zoom in on the images if required to fine-tune the locations of the landmarks. Sometimes, it may be easier to locate the corresponding landmarks in a oblique view. Use the 3D view to manipulate the image and get oblique views. To record the pair of landmarks that are selected in previous step, click the Accept button, or press the Enter key. This pair of landmarks will be displayed as red marks to indicate that they are accepted and recorded. The recorded landmarks may not be moved around. However, they can be deleted and replaced by a new pair. Repeat the above two steps to find more pairs of landmarks. There is no upper limit for the number of landmarks that may be selected. However, a minimum of 3 pairs of landmarks must be selected for 2D images and at least 4 pairs of landmarks must be selected for 3D images. Once enough landmarks have been selected a transformation matrix is automatically calculated to register the moving image on left to the fixed image on the right. The initially disabled Transformed View check box becomes enabled. Check the Transformed View check box to switch the moving image to the transformed view. At this stage, it may be sufficient to skip to the visualization section and examine the registration result. If the result is not satisfactory, continue on to the following steps. Select more landmarks to improve the registration. The additional landmarks on the moving image could be picked either in its original view or the transformed view. Switch back and forth between original and transformed views by checking and unchecking the Transformed View check box. Notice the contents of the second (landmark coordinates on the right) and third (distance) columns also change when the view is changed. Examining the distance column in the transformed view could help one to find the pair of landmarks that contribute the largest RMS error for the registration. The RMS value is the root mean square of the distances between each landmark pairs. This value is displayed under the Landmarks table. Landmarks can be reviewed and/or deleted by selecting the corresponding row in the Landmarks table. Click the left mouse button on a row to highlight it. Click the Delete button to delete the highlighted row and the corresponding landmarks on the images. All of the landmarks can be deleted at once by clicking the Delete All button. By default, the rigid-body transform is used for the registration. If the rigid-body transform is not sufficient for the registration, switch to another type of transform by changing the drop-down selection from the Transformation Matrix section: Rigid Body (6 Parameters) is a type of transformation with 6 degrees of freedom (ie. 3 for rotation and 3 for translation). Similarity (7 Parameters) is a type of transformation with 7 degrees of freedom (ie. 3 for rotation, 3 for translation, and 1 for uniform scale). Full Affine (12 Parameters) is a transformation with 12 degrees of freedom (ie. 3 for rotation, 3 for translation, 3 for scale, and 3 for shear). Note that the more parameters the transformation matrix uses, the more landmarks are needed to get a good result. Landmarks may be added or removed after switching the transformation type. Once done, go to the Visualization page to review the registration result. When satisfied, the results can be saved in one, two or all of the following three ways: Landmark tags: save the landmark coordinates by clicking the Save... button in the Landmarks section of the dialog. The landmarks can be loaded at a later time by clicking the Load... button in the Landmarks section. Resampled image: save the transformed (i.e., registered) moving image on the right pane to a file by clicking the Save... button in the Transformed View section. Tri-cubic interpolation is used to resample the transformed image. Transformation matrix: save the transformation matrix by clicking the Save... button in the Transformation Matrix section. This saved transformation can be applied at a later time to the moving image by clicking the Load... button in the Transformation Matrix section.","title":"Landmark Registration"},{"location":"tools-and-plugins/#visualization","text":"Click on the Visual tab to activate this page. The visualization tools in this application serve two purposes. One is to visually evaluate the registration result and the other is to help user to correlate the information from the two images, e.g., the structural and functional information.","title":"Visualization"},{"location":"tools-and-plugins/#synchronized-view","text":"Checking the Synchronized View check box synchronizes the two displayed images. The synchronized interactions on the images include: Gray scale values for both images are displayed when moving the cursor. Synchronized viewing angle. Synchronized zooming and panning. Synchronized slicing through the images (including Page-Up and Page-Down). Synchronized landmarks. Moving the cursor over a point of interest in either the fixed or moving images and then pressing the Space on the keyboard will activate the pair of orange colored landmarks. This feature can be used to do point-by-point comparison for the two registered images. Tip Remember to uncheck the Synchronized View check box before going back to the landmark page and selecting additional landmarks.","title":"Synchronized View"},{"location":"tools-and-plugins/#fusion","text":"Fusion The moving image can be fused on to the fixed image by checking the Fusion View check box. Once the Fusion View check box is checked, additional controls will appear in the dialog. The Min Level and Max Level sliders determine the range of gray scale values that get mapped to colors. The moving image will be transparent outside this range. If the Ramp Opacity option is checked then the opacity of the moving image is ramped exponentially. Otherwise the opacity is constant and is determined by the Opacity slider. There are several different color tables to select from. A color table is a mapping of gray scale values to RGB color values. Tip Synchronized view and fused views are designed to be used for two registered images, or at least two spatially overlapped images in the world-coordinates (the patient space). Trying to synchronize or fuse two spatially unrelated images will result in unexpected behaviors.","title":"Fusion"},{"location":"tools-and-plugins/#volume-rendering-tool","text":"Volume Rendering","title":" Volume Rendering Tool"},{"location":"tools-and-plugins/#overview_4","text":"Note MicroView 2.5.0 features GPU-acceleration and improved level of detail rendering for most volume rendering functions. MicroView's volume rendering tool can be used to produce stunning photo-realistic 2D semi-transparent representations of 3D image data by one of three raycast techniques. Raycast volume rendering is especially common in the medical imaging community where three dimensional volume data is easily available. To understand raycasting, think of voxels within a 3D image as possessing a density which corresponds to the graylevel value of the voxel. Imagine that for each pixel in the rendered image scene, a ray is drawn from the observer's eye, through the image pixel, then through the entire 3D image data set. Each ray will intersect a number of voxels before leaving the 3D image data. For each image pixel in the rendered scene, a color is determined by accumulating information derived from the intersecting voxels along the corresponding raycast ray. In particular, for each voxel in the 3D image data, the \"density\" or graylevel value of the voxel will be transformed into a corresponding voxel color and transparency. This color and transparency information will be combined, according to a raycast function to determine the final pixel color in the image scene. MicroView currently supports three styles of raycast volume rendering: Isosurface Rendering - a raycast method where surfaces of similar density objects are rendered, and the remaining materials are hidden. For this rendering mode, a density threshold value must be selected that defines the surface, and the color of the surface selected. Maximum Intensity Rendering - a method where the color of the densest object along each raycast path is used to determine the final color of each pixel. This method is particularly useful to extract, e.g. contrast-enhanced vessels, or bone from images. Composite Rendering - a general raycast method, which gives the greatest level of control over the raycast scene.","title":"Overview"},{"location":"tools-and-plugins/#microviews-rendering-interface","text":"MicroView's volume rendering interface allows the user to control the type of rendering to generate and the parameters that will be used to generate the rendering. The interface consists of the following elements. A graphical view that presents the image histogram, the opacity and color ramp and a representation of the LUT. The view can be controlled in the same fashion as the histogram or 2D profile plot windows. Additionally, this view contains a number of control points connected by a line. These control points are represented by either a blue (inactive) or red (active) dot and can be manipulated as outlined below. Control Point Settings group. These controls allow the user to fine tune the specific values that are used for each control point in the opacity and color ramp. A drop down box that contains a number of rendering presets. These presets have been designed to produce a good quality rendering in specific circumstances. There are two presents currently. Bone - sets the threshold at the Bone HU value specified in the volume. Soft tissue/Bone - uses the composite rendering method to generate an image that will accurately represent both soft tissues and bones. The preset values have been chosen using the calibrated HU values for bone and soft tissues. A pair of drop down boxes that are used to select the rendering mode to use, and the quality of the rendering to generate. The low quality rendering can be used to rapidly evaluate whether the chosen parameters will generate the desired image or not as the rendering is produced much more rapidly. Once the parameters have been roughly determined, the high quality rendering can be used to fine tune the results. A group of buttons that provide the following functionality: Save - saves all of the parameter settings to file for use at a later time or on another system. Load - loads the parameter settings from a file generated using the Save function above. Reset - Resets the histogram view and all of the associated parameters to the default values for the selected rendering function. Isosurface - the threshold value is set in the middle of the grayscale range of the volume. Maximum Intensity Projection - three regions equally spaced in the grayscale range of the volume. The first region covers the smallest values and has an opacity of 0. The second region covers the middle third of the values and is a ramp from an opacity of 0 to an opacity of 1. The final region covers the highest values and has an opacity of 1. Composite - a ramp starting from the smallest grayscale value in the volume and an opacity of 0 to the largest grayscale value in the volume and an opacity of 1. There is a third control point at the middle grayscale value. The interface is reset whenever a new image is loaded into MicroView. Update: generate the volume rendering using the current settings. Manipulating the volume (rotation, slicing, magnification) has the same effect.","title":"MicroView's Rendering Interface"},{"location":"tools-and-plugins/#using-the-volume-renderer-tool","text":"Select Visualize \u2192 Render Volume... from the MicroView menu to open the volume rendering tool window. Select the style of volume rendering desired. Composite rendering offers the greatest control over the display, but is the slowest form of rendering. MIP rendering displays a maximum intensity projection of the currently loaded image data. Isosurface rendering displays only the surface of objects, and is most useful for rendering bone images. Change the location of the controls points if desired, to achieve the appropriate rendering result. The control points are chosen using the left mouse button and will change from blue to red to indicate that they are active. Isosurface - there are two control points that are vertically connected. These control points represent a threshold. All of the values above the threshold will be rendered. The two control points are always at the same graylevel. Maximum Intensity Projection - there are four control points, of which two can be manipulated by changing the graylevel value where they are located. The opacity values are fixed for all of the control points. The two end points are fixed. The first end point is at the lowest graylevel value in the volume and has an opacity of 0. The second end point is at the highest graylevel value in the volume and has an opacity of 1. The two control points in the middle of the histogram can be moved back and forth to change their graylevel position, and thus the location and slope of the ramp function. Composite - the composite rendering function is the most complicated and begins with three control points (two end points and the mid-point) and a ramp function from an opacity of 0 to an opacity of 1 as outlined above. The end points are fixed at the appropriate graylevel positions, but can have their opacity changed. There are a number of different manipulations that can be performed on the control points. Adding a control point - move the mouse pointer over the line that does not have an existing control point and click the left mouse button. A new point will appear at that location and will be active as indicated by the red coloration. Deleting a control point - select any existing control point by clicking on it with the left mouse button. The point will be marked active using the red coloration. Delete the point by pressing the \"Del\" key on your keyboard. Changing the opacity - select any existing control point by clicking on it with the left mouse button. By holding the left mouse button, it is possible to drag the control point up and down in the graphical view to change its opacity value. It is also possible to change the opacity of the currently selected control point by typing a value into the Opacity text entry box. Changing the graylevel position - select any existing control point by clicking on it with the left mouse button. By holding the left mouse button, it is possible to drag the control point left and right in the graphical view to changes is graylevel position. It is also possible to change the graylevel position of the currently selected control point by typing a value into the Position text entry box. Change the color that each surface will appear by using the color editor. Begin by selecting any control point by clicking on it with the left mouse button and noting that its color changes from blue to red. The color can then be edited using either the sliders on the color bars or by entering a value in the appropriate text entry box. How the color change is applied depends on the type of rendering that is being generated. Isosurface - all pixels above the specified threshold will be colored using the selected color. Maximum Intensity Projection - the pixels above the active control point will be colored using the selected color and the ramp function that joins the active control point to the next larger graylevel control point. Composite - same color treatment as the Maximum Intensity Project noted above. Select quality of rendering. Choose \"low\" quality to render rapid, lower quality images. These low quality renderings can be used to quickly evaluate the results of any changes that are made to the parameters before generating the more time consuming high quality renderings. Choose \"high\" quality once opacity, and color tables have been correctly set, in order to render at the highest quality. Click the Update button to update the output display whenever the rendering parameters have been adjusted. Manipulating the image by rotation, slicing or magnification will cause the output display to be updated. Click the Reset button to restore the opacity and color transfer functions to their original default values. Use the Save and Load buttons to save and load the parameter settings. Use the \"Enable volume picking\" checkbox to enable or disable volume picking: When enabled, the middle mouse button can be used to interactively adjust cropping dimensions that will be applied to the rendered image. When disabled, picking is disabled and MicroView will not allow the rendered volume to intercept mouse clicks and drags.","title":"Using the Volume Renderer Tool"},{"location":"tools-and-plugins/#additional-microview-tools","text":"MicroView has a number of additional features bundled into application plugins. Some of the core plugins are described below.","title":"Additional MicroView Tools"},{"location":"tools-and-plugins/#reorient-image","text":"As discussed in earlier sections of this help guide, MicroView can perform arbitrary axis multiplanar reformatting of 3-D image data. Reorienting the displayed image planes is performed on-the-fly without actually adjusting the underlying image. To actually save the image reformatted along new axes, a specific image reorient tool in MicroView is used. To save a reoriented image, first center and orient the cut planes in the 3-D view pane to represent the axes of the desired output image. Once satisfied with the displayed axes, select File \u2192 Save Reoriented Image... to save the reoriented image to a file.","title":"Reorient Image"},{"location":"tools-and-plugins/#standard-roi-tool","text":"Note MicroView 2.5.0 features spherical ROI objects as well as the ability to rotate primitives. MicroView's ROI tool can be used to select a 2D or 3D region of interest in the image for further analysis. It compliments the manual ROI selection technique, using the 7 and 8 keys. Use this tool when a ROI of a specific size or position is needed. Activate the ROI tool by selecting Standard ROI from the Tools and Applications sidebar on the left hand side of the main window, or by selecting Tools \u2192 Standard ROI... from the main menu. Choose Parallelepiped, Elliptical Cylinder or Spherical ROI shapes for the selected analysis region (Box, Cylinder and Sphere options, respectively). Choose a unit of measurement -- either millimeters or pixels. Adjust the size and position of the selected analysis region: Either manually enter coordinate values into the appropriate text boxes (hit enter key to accept changes), or adjust the sliders to the right of each entry box to choose the bounds of the region of interest. Alternatively, you can resize and reposition a rectangular ROI by interacting with the faces of the yellow box in the main 3D viewport. Position the mouse over any surface, then click and drag the middle mousebutton to resize the ROI along the axis parallel with the ROI face you clicked upon. Holding the shift key down, while performing the same operation will translate the ROI along the same axis. Press the Link X/Y button to enable or disable linking size changes in X and Y axis. Check the Link Image Plane radio button to enable rotation of ROI primitives. Rotate image planes in order to take advantage of this feature.","title":" Standard ROI Tool"},{"location":"tools-and-plugins/#cortical-bone-roi-tool","text":"When applied to a CT image of a bone, this tool can be used to select a ROI corresponding to either the cortical shell or the trabecular space of the bone. The tool uses a series of morphological operators to semi-automatically select cortical bone components. The trabecular space is found within the cortical bone region. Once the cortical bone components have been selected, they can be converted to a ROI for use in the Advanced Bone Application and the image planes can be rotated so that the axes of the planes are aligned with the principal axes of the cortical bone. Before running this tool, the user needs to either select a ROI to be used for segmentation, or the tool will automatically select the entire image and perform segmentation on the resulting ROI. Activate the ROI tool by selecting Cortical ROI from the Tools and Applications sidebar on the left hand side of the main window, or by selecting Tools \u2192 Cortical ROI... from the main menu. The gray-level threshold may be either entered manually or determined automatically by using the Auto Threshold button. The result of automatic thresholding is determined using the \"Otsu\" method The \"Hole and Channel Size\" specifies the largest size, in pixels, of any holes and channels through the bone that you would like the algorithm to fill. The default value is 7 pixels. The \"Trabecular thickness\" specifies the largest size, in pixels, or trabeculae that you would like the algorithm to remove from the ROI. For bones where the cortical thickness is similar to the trabecular thickness, the segmentation algorithm may also eliminate the cortical bone making it less suitable for use in these circumstances. The default value is 7 pixels. Use the Run button to segment the cortical bone contained in the ROI. Use the Segmentation \u2192 Cortical ROI button to convert the segmentation results (highlighted in green) to a ROI (highlighted in yellow) that can be used for analysis operations in the Advanced Bone Application. Select the Segmentation \u2192 Trabecular ROI button to invert the ROI selection -- i.e. select the trabecular bone region as a ROI. Use the Align to Principal Axes button to rotate the axis planes to be aligned with the principal axes of the segmented cortical bone","title":"Cortical Bone ROI Tool"},{"location":"tools-and-plugins/#isosurface-tool","text":"MicroView's isosurface tool can be used to extract a surface from a 3D image that corresponds to a user-defined gray-level value. Activate the tool by selecting Visualize \u2192 Isosurface... from the main menu. To use the tool: Select an image threshold value in the Image Threshold text box. Select a quality factor using the Surface Quality Factor slider. This factor is used to downsample the image prior, to extracting an isosurface. Use a small value (e.g. 0.25) initially to extract a course surface, then refine the surface by increasing the factor to 1.0. The memory consumed by this plugin increases quickly for large surface quality settings, as does the size of the final surface mesh. Use large values sparingly. Select a decimation factor by adjusting the appropriate slider. MicroView will attempt to reduce the surface complexity of the final isosurface by this user-defined amount. Setting a value of \"0.1\" means that MicroView will attempt to reduce the surface polygon count by 10%, while minimizing the impacting on surface topology, surface area and volume contained within the isosurface. A value of \"0\" indicates that no decimation shall be attempted, while values approaching \"1\" will significantly impact the quality of the final surface. Optionally enable image smoothing and image clipping by checking the appropriate checkboxes. If smoothing is enabled, MicroView will perform a Gaussian blur on the image prior to generating an isosurface. This is used commonly to reduce image noise, and hence remove spurious surface elements from the final surface. This will have an impact on the accuracy of the Area and Volume measurements displayed in the plugin GUI. Press the Update button to display/update the isosurface. Press the Clear to hide the surface.","title":" Isosurface Tool"},{"location":"tools-and-plugins/#image-resample-tool","text":"MicroView can perform image downsampling on a loaded image in order to decrease the disk space and memory needed to store an image. Activate the downsampling plugin by selecting Process \u2192 Resample Image... from the main menu. Then: Enter a downsampling factor in the edit field. Press the Resample and Save... button to resample the image and save it to disk.","title":"Image Resample Tool"},{"location":"tools-and-plugins/#image-transfer-tool","text":"MicroView can transfer a loaded image to a compatible DICOM viewing station. It can also browse and download into memory images from a number of remote viewing platforms. Certain stations can be automatically detected, while others must be manually configured. To activate the tool, select Tools \u2192 Dicom Transfer... from the main menu. Enter the hostname and port number of the destination server in the appropriate text entry boxes. Optionally select a DICOM application name, for servers that require communication from a specific application name. For servers that do not require a specific application name, leave this field blank. Check with your DICOM vendor, or user's manual to determine what the AE title should be. Enter values for Patient Name, Patient ID, Study ID and Study Description, if needed. In some cases MicroView may be able to provide default values based on the image loaded. Finally, hit the Send Image button to transfer the image.","title":" Image Transfer Tool"},{"location":"tools-and-plugins/#manage-geometries","text":"Note MicroView 2.5.0 features an overhauled interface for handling point, surface and vector data. General purpose unstructured grids and vector fields can now be displayed in MicroView. Greater control over viewing options have also been added. This tool is used to display and manipulate 3D surface geometry objects. Surface geometries can be read from a variety of common 3D file formats , such as STL, PLOT3D and PLY formats. Loaded geometries may be superimposed on top of the current 3D image data. Surface characteristics, such as color, opacity, and whether the object is displayed as a closed surface or a wire mesh can be adjusted for each loaded surface. Finally, each surface may be selected and assigned as the default ROI for MicroView. This permits advanced ROI selections to be saved and restored, as well as allowing third-party tools to be used to generate ROI objects. Activate the \"Manage Geometries...\" plugin by selecting Visualize \u2192 Manage Geometries... from the main menu. Click the Load button to select a geometry file to load in. Multiple files can be loaded sequentially. Each surface object filename will be displayed in the list box above the Load button. Click the Show or Hide button to show or hide a selected geometry. Click the Delete button to remove a selected geometry from memory. Click the Geometry \u2192 ROI button to assign the currently selected surface as the default ROI for MicroView. Customize the color of a selected surface by clicking on the surface's color button, and adjust surface characteristics of the selected surface by checking or unchecking the Display Wireframe button. Customize the opacity of the selected surface by adjusting the opacity slider. A value of zero means the surface is completely transparent (e.g. invisible), while a value of 1.0 indicates the surface is completely opaque.","title":" Manage Geometries"},{"location":"tools-and-plugins/#image-information","text":"Note MicroView 2.5.0 has fundamentally changed how image data is represented internally. These changes facilitate converting data between different image formats, while maintaining meta-info in DICOM-compatible format. See the \"DCM\" page for DICOM-related information.","title":" Image Information"},{"location":"tools-and-plugins/#overview_5","text":"This plugin displays properties about the currently loaded image and general display settings of MicroView, such as background colour, active units etc. The tool can be activated by selecting Tools \u2192 Image Information... from MicroView's main menu. Image and system properties can be viewed in one of two basic property display modes: a general mode presents as much information as possible in loosely defined categories; a DICOM-specific mode presents DICOM tags (or equivalents) for the image.","title":"Overview"},{"location":"tools-and-plugins/#property-display-modes","text":"To view general image properties and viewing options, select the column-like icon at the top of the plugin. To view instead DICOM tags associated with this image, select the DCM icon. The third icon (a silhouette with minus sign) can be used to anonymize DICOM tags associated with the image.","title":"Property Display Modes"},{"location":"tools-and-plugins/#property-filters","text":"Image properties can be filtered by adding filter terms in the search box at the bottom of the plugin. Filter words are case insensitive and apply to both property name and property value in both general and DICOM property display modes. You can filter on more than one search string by separating them by spaces.","title":"Property Filters"},{"location":"tools-and-plugins/#general-information","text":"Some fields are specific to vff format images, especially those generated by the Locus reconstruction software package: Air and water parameters, for instance, correspond to calibration values entered using the CT calibration tool in MicroView's CT Toolbox plugin. Similarly, the bone parameter value (measured in Hounsfield Units), is also a calibration value, determined as part of the Locus image reconstruction process. Some image information values (title, subject, air, water and bone values) may be edited by clicking on the value field in the image information box. Press the Enter key to accept the new value, or press the Esc key to cancel your edit session. Editing values in this way does not modify the contents of the original image file on disk -- you must explicitly save the image in order to preserve your changes.","title":"General Information"},{"location":"tools-and-plugins/#advanced-region-grow-tool","text":"The Advanced Region Grow tool allows the user to define a ROI in a 2D or 3D image based on the connectedness of voxels with similar intensity values. Once defined, the region grown ROI may be used as MicroView's default ROI for further analysis. The tool extends the capabilities of the Region Grow tool, allowing the early termination of the growth based on a given number of iterations. It also provides the user with a mean of determining the smoothness of the final selected region. The starting point for using the Advanced Region Grow tool is typically the selection of a simple ROI, to constrain the region growing process. Selecting a small rectangular ROI around the object to be segmented will reduce the memory and time required to perform the region grow operation. Advanced Region Grow can be used without selecting a constraining ROI, but the time and memory required will be greater. Once a constraining ROI has been selected, the following operations must be performed to use the region grow tool: Activate the tool by choosing Tools \u2192 Advanced Region Grow... from the main menu. Move one of the 3D viewplanes so that it intersects the constraining ROI. Select a plane that clearly shows a slice of the object you wish to segment. Temporarily set the Window value for the main window to 1. Adjust the Level value so that the loaded image is displayed in black and white. Choose a setting such that the feature to be segmented is displayed in white. Select a threshold option from the available list. If segmenting a bright object from a darker background, select \"upper\". If segmenting a dark object from a brighter background, select \"lower\". Choose \"window\" to segment connected pixels in a range of gray-level values surrounding the current level scrollbar value. Choose the number of times Region Grow should occur by providing the \"Number of Iterations\" parameter in the plug-in. A higher number would result in the final selected region to be larger. This parameter should be changed based on the result obtained. Adjusting this value would allow the user to stop the tool from selecting undesired regions. Pick a starting point (e.g. a pick point) for the region grow operation by positioning the mouse cursor over the object of interest within the constraining ROI. Hit the Space key to select the 3D point. Once a pick point has been selected, the Advanced Region Grow tool will determine a set of connected voxels. The tool will highlight this collection of voxels in green in both the 3D and 2D viewports. In the results section of the region grow tool, the volume and centroid of the group of voxels will be displayed. Press the View Centroid button to move the 3D cut-planes so that they intersect at the centroid of the selected ROI. Press the Geometry \u2192 ROI to assign the results of this tool to the default ROI for further analysis. Once assigned, the green highlighted voxels will turn yellow, indicating the new choice of system-wide ROI.","title":"Advanced Region Grow Tool"},{"location":"tools-and-plugins/#slab-project","text":"The Slab Project tool accumulates images from a collection of image slices surrounding the currently image planes and displays them using one of a variety of different functions: minimum, maximum, mean and sum. The tool can operate on either on a finite slab of images or the entire collection of data. It can produce oblique, so-called 'Live View' images, or produce a new static image as it's output. Note This tool serves as a replacement for the 'MIP Image' tool found in older versions of MicroView.","title":"Slab Project"},{"location":"tools-and-plugins/#using-slab-project","text":"Activate the Slab Project plugin by selecting Visualize \u2192 Slab Project... from the main menu. To enable slab projection, choose 'Oblique Live View', 'X-', 'Y-' or 'Z-' axis projections. The first option will produce output in currently selected 3D viewport, while the remaining three options will generate a new output window. Select an accumulation function: 'Min', 'Max', 'Mean' or 'Sum'. Click the Apply button to generate the slab projection. For 'Live View' mode, interacting with the 3D viewport slice position will change the appearance of the slab. Select File \u2192 Save Snapshot... to save a snapshot of the slab image. Snapshot images are always 8-bit images, and take advantage of the current window/level settings in the slab project window.","title":"Using Slab Project"},{"location":"tools-and-plugins/#ct-toolbox","text":"The CT Toolbox plugin consists of a collection of tools, useful for day-to-day analysis of CT image data. The plugin can be used to: perform Hounsfield image calibration of GE preclinical scanner data perform image unwarp and bright/dark field corrections remove rings interactively from a 3D CT dataset Note This plugin is designed to supersede the original CT Calibration Tool plugin, found in earlier releases of MicroView. This plugin allows the user to measure three different ROI's within an image, and save/restore these values. The purpose of saving three sets of ROIs is so that the reconstruction software can automatically determine air, water and bone calibration constants. Activate the CT Toolbox plugin by selecting Tools \u2192 CT Toolbox... from the main menu. Define a ROI with only air by using either the 7 / 8 keys,or by selecting a ROI using the ROI plugin ( Plugins \u2192 ROI Selection Tool... on the MicroView menu) and click the corresponding Save button. Similarly do the same for water and bone. Once the ROI's for air, water, and bone have been selected and the settings have been saved, click one of the Load buttons and the corresponding ROI will appear.","title":" CT Toolbox"},{"location":"tools-and-plugins/#make-movie","text":"Note The Movie Maker plugin now uses OpenCV to generate movies in a variety of different output formats. The specific codec list available is platform dependent. This plugin allows the user to make a movie of a sequence of screen snapshots, while the loaded image is either rotated 360 degrees about an axis, or sliced along a cutplane. Sequences can be accumulated together to build more complex movies. Individual orientations can also be controlled by using stationary snapshots. Select Visualize \u2192 Make Movie... to load the movie maker. Next: Select the type of animation desired in the Animation Type drop-down menu. The X/Y/Z Rotation entries correspond to animations of the image scene while rotating the image about the selected axis. The X/Y/Z Slicing entries generate an animation of the image scene while slicing through the entire image along the selected image axis. Select from one of a number of movie file types. Enter the number of snapshot images to take while generating a movie sequence. For rotation-type movies, this number will determine how many degrees to rotate the image scene between each image and the next. Press the Add sequence button to start the movie making process. For the first sequence only, you will be prompted to select an output filename. Additional sequences can be added to the movie by repeating the above steps until the entire movie is produced. Finally, close and finish generating the movie by clicking the Finish button.","title":" Make Movie"},{"location":"tools-and-plugins/#point-picker","text":"MicroView's point picker tool is used to make a set of landmark measurements on an image, and to save these measurements to disk. Start the tool by selecting Plugins \u2192 Point Picker... from the main menu. Once loaded: Position the mouse cursor over a point of interest in either 3D or 2D viewports Press the Space key to place a marker at the current mouse position Press the Accept button, or Enter key, to permanently accept the marker position, or reposition the mouse and hit the Space key again to move the marker For each marker, the 3D coordinate will be recorded in the table contained in the measurement tool. Additional column space reserved for adding comments to each line Press the Save... button to save the current marker positions to disk Captions for each landmark can be optionally displayed floating beside each landmark Additional support for the display of a rectangular-shaped ROI about each landmark is available","title":" Point Picker"},{"location":"tools-and-plugins/#interactive-shell","text":"From MicroView's interactive shell, images can be interrogated and manipulated easily. The toplevel python variable images is a list of images, indexed by each loaded images tab number, which is displayed on each image's Viewer tab.","title":"Interactive Shell"},{"location":"a/adora/","text":"Adora Analysis (2017-06-28) The goal here is to import all data from our 2017-06-28 scanning session, and format it in a pandas dataframe. We collected DICOM image data, rpos angle data and motion capture information. Three identical scans were performed of a 9-BB phantom with a larger, central BB close to the center of rotation for tracking purposes. Motion capture data was recorded, as was gantry angle data. Data Import Start with the usual python variable definitions and import statements # set `s3_access` to True to pull data from s3 storage on Amazon -- note that the s3 bucket I'm currently using migrates stuff to glacier so # amazon access won't work at the moment. s3_access = False # additional global variables base_directory = 'D: \\\\ Data \\\\ UWO X-ray project \\\\ Adora \\\\ ' date = '20170628' debug = True import os import sys import zipfile import pandas as pd from pylab import * import matplotlib.pyplot as plt from IPython.display import Image from ipywidgets import IntProgress , widgets , HTML , VBox try : import adora_bb_finder except : pass # ignore _transformations warning # globally change plot size matplotlib . rcParams [ 'figure.figsize' ] = [ 10 , 4.8 ] c : \\ users \\ jgill \\ documents \\ src \\ mv \\ lib \\ site - packages \\ PI \\ math \\ transformations . py : 1888 : UserWarning : failed to import module _transformations warnings . warn ( \"failed to import module %s \" % name ) Create/open an HDF5 data store and set it up to be accesible via pandas . store = pd . HDFStore ( r 'D:\\Data\\UWO X-ray project\\Adora\\{date}\\data_store.hd5' . format ( date = date )) Read RPos angle data We performed three scans with angle measurements and motion capture info. Iterate over each dataset. We'll read from individual CSV-format files and pack them into our HDF5 store. RPos data was recorded by Rudy on his cell phone over bluetooth to the Arduino system we've set up. A master device senses x-ray exposure and requests angle data whenever this occurs. A slave device mounted in the Adora gantry digitally samples rpos angle values and reports last-recorded value when asked. if s3_access : template = \"https://s3.amazonaws.com/parallax-adora/Adora/{date}/ArduinoAngleData/scan+{scan_number}.csv\" else : template = r \"D:\\Data\\UWO X-ray project\\Adora\\{date}\\Arduino Angle data\\scan {scan_number}.csv\" for i in range ( 3 ): label = '/adora/date_{date}/scan{scan_number}/angles' . format ( date = date , scan_number = i + 1 ) if label not in store : store [ label ] = \\ pd . read_csv ( template . format ( date = date , scan_number = i + 1 ), names = [ 'view' , 'angle' ]) store . flush () if debug : for i in range ( 3 ): label = '/adora/date_{date}/scan{scan_number}/angles' . format ( date = date , scan_number = i + 1 ) plot ( store [ label ] . view . values , store [ label ] . angle . values ); show () Read Motion-capture data Okay, next let's pull in motion capture data. The files are somewhat free-form but essentially contain tab-delimited CSV data. We ignore the first few rows of data, process the remainder as csv, then edit column headers. One important thing to know about the motion capture data: The vertical axis in the capture *.ts files is labelled as the 'Y1' axis. At the moment we'll assume a right handed coordinate system, which means we want to convert (Z1,X1,Y1) to (X1,Y1,Z1). Part of the column manipulation, fixes this. if s3_access : template = \"https://s3.amazonaws.com/parallax-adora/Adora/{date}/MotionCapture/adora_rotation_cube{scan_number}.ts\" else : template = r \"D:\\Data\\UWO X-ray project\\Adora\\{date}\\Motion Capture\\adora_rotation_cube{scan_number}.ts\" for i in range ( 3 ): label = '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = i + 1 ) if label not in store : data = pd . read_csv ( template . format ( date = date , scan_number = i + 1 ), \\ sep = ' \\t ' , skiprows = ( 0 , 1 , 2 , 3 )) # tweak column headers columns = list ( data . columns ) columns [ 0 ] = 'Frame#' ; columns [ 1 ] = 'Time' for j in range ( 10 ): idx = 2 + 11 * j columns [ idx ] = 'Y{}' . format ( j + 1 ); columns [ idx + 1 ] = 'Z{}' . format ( j + 1 ); columns [ idx + 2 ] = 'X{}' . format ( j + 1 ) data . columns = columns store [ label ] = data store . flush () What does our (relabeled) data look like? store [ '/adora/date_{date}/scan1/motion_capture' . format ( date = date )] . iloc [:, 0 : 8 ] . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Frame# Time Y1 Z1 X1 vX1 vY1 vZ1 0 1 0.00 -242.95070 1046.91772 -378.62418 NaN NaN NaN 1 2 0.01 -242.96999 1046.91431 -378.59717 -0.61340 2.09961 2.81982 2 3 0.02 -242.96297 1046.95972 -378.56778 0.61493 0.12817 0.29755 3 4 0.03 -242.95769 1046.91687 -378.59122 0.14420 -2.51465 -0.55237 4 5 0.04 -242.96008 1046.90942 -378.57883 3.40881 0.01221 -2.25677 Read data from XMALab Next, let's process data we generated using XMALab (generated on August 11). Rudy has found a semi-automated way to do BB tracking which simplifies things significantly. Previously, I'd been spending significant effort to optimize a fully-automated way to track BBs, but XMALab is fast enough and good enough that this is no longer a worth-while effort. def convert_xma_to_dataframe ( xma_filename ): \"\"\" Converts fiducial tracking information from an XMALabs *.xma file to a pandas DataFrame \"\"\" # open xma file (it's a zip file) z = zipfile . ZipFile ( xma_filename , mode = 'r' ) namelist = z . namelist () # iterate over all fiducials, extract CSV file. Convert to a pandas dataframe vals = [] for num in range ( 10 ): label = 'Trial 1/data/Marker{:03d}points2d.csv' . format ( num ) if label in namelist : _file = z . open ( label ) df = pd . read_csv ( _file , names = [ 'm{}_x' . format ( num ), 'm{}_y' . format ( num )]) vals . append ( df ) z . close () # concat results df = pd . concat ( vals , axis = 1 ) return df def get_xma_model_coordinates ( xma_filename ): \"\"\" Reads an XMALabs file and returns model coordinates \"\"\" # open xma file (it's a zip file) z = zipfile . ZipFile ( xma_filename , mode = 'r' ) _file = z . open ( 'CalibrationObject/3DCube_framespec_9point.csv' ) df = pd . read_csv ( _file , names = [ 'X' , 'Y' , 'Z' ], header = 0 ) * 10.0 # convert from cm -> mm return df store = pd . HDFStore ( r 'D:\\Data\\UWO X-ray project\\Adora\\{date}\\data_store.hd5' . format ( date = date )) # convert first scan (9-bb scan) for scan_name in ( 'scan1' , 'scan2' ): xma_filename = os . path . join ( base_directory , date , '{date}-{scan_name}.xma' . format ( date = date , scan_name = scan_name )) label = '/adora/date_{date}/{scan_name}/XMALab/measured_points' . format ( date = date , scan_name = scan_name ) df = convert_xma_to_dataframe ( xma_filename ) store [ label ] = df # get model coordinates (for scan 1) coords = get_xma_model_coordinates ( xma_filename ) store [ '/adora/date_{date}/{scan_name}/XMALab/model_points' . format ( date = date , scan_name = scan_name )] = coords store . flush () Data Analysis Next, we will visualize the data that we have collected into store . Investigation of Motion Tracking Data Let's plot various (x,y,z) sets to see what our motion tracking data looks like. Select the scan to process in the drop-down box below: #####%matplotlib wx % matplotlib notebook from mpl_toolkits.mplot3d import Axes3D fig = plt . figure () plt . figure ( figsize = ( 8 , 8 )) ax1 = fig . add_subplot ( 221 , projection = '3d' ) ax1 . set_xlabel ( 'x (mm)' ) ax1 . set_ylabel ( 'y (mm)' ) ax1 . set_zlabel ( 'z (mm)' ) ax1 . set_title ( '{date}: Reproducibility of 3 scans' . format ( date = date )) data = store [ '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = 1 )] ax1 . plot ( data [ 'X1' ], data [ 'Y1' ], data [ 'Z1' ]) data = store [ '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = 2 )] ax1 . plot ( data [ 'X1' ], data [ 'Y1' ], data [ 'Z1' ]) data = store [ '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = 3 )] ax1 . plot ( data [ 'X1' ], data [ 'Y1' ], data [ 'Z1' ]) ############### ax2 = fig . add_subplot ( 222 , projection = '3d' ) ax2 . set_xlabel ( 'x (mm)' ) ax2 . set_ylabel ( 'y (mm)' ) ax2 . set_zlabel ( 'z (mm)' ) ax2 . set_title ( 'A few points on detector?' ) data = store [ '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = 1 )] ax2 . plot ( data [ 'X2' ], data [ 'Y2' ], data [ 'Z2' ]) ax2 . plot ( data [ 'X3' ], data [ 'Y3' ], data [ 'Z3' ]) ax3 = fig . add_subplot ( 223 , projection = '3d' ) ax3 . set_xlabel ( 'x (mm)' ) ax3 . set_ylabel ( 'y (mm)' ) ax3 . set_zlabel ( 'z (mm)' ) ax3 . set_title ( 'A few points on tube?' ) data = store [ '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = 1 )] ax3 . plot ( data [ 'X9' ], data [ 'Y9' ], data [ 'Z9' ]) ax3 . plot ( data [ 'X10' ], data [ 'Y10' ], data [ 'Z10' ]) ax4 = fig . add_subplot ( 224 , projection = '3d' ) ax4 . set_xlabel ( 'x (mm)' ) ax4 . set_ylabel ( 'y (mm)' ) ax4 . set_zlabel ( 'z (mm)' ) ax4 . set_title ( 'Merged results' ) ax4 . plot ( data [ 'X2' ], data [ 'Y2' ], data [ 'Z2' ]) ax4 . plot ( data [ 'X3' ], data [ 'Y3' ], data [ 'Z3' ]) ax4 . plot ( data [ 'X9' ], data [ 'Y9' ], data [ 'Z9' ]) ax4 . plot ( data [ 'X10' ], data [ 'Y10' ], data [ 'Z10' ]) show () &lt;IPython.core.display.Javascript object&gt; &lt;IPython.core.display.Javascript object&gt; Okay, this is awesome - we can see a z-axis deviation here clearly in the data. This may be due to a miscalibration of the motion-capture equipment at WOBL . It might otherwise be real, in which case the Adora is sagging as it rotates about its axis. Calibrate scanner using Li method Get first image points - 10 objects are tracked per frame in two dimensions. The 10 th BB is our center BB which isn't involved in the fit. Recorded image points are measured in mm, while the model that Rudy provided me is measured in cm. scan_number = 1 image_points = store [ '/adora/date_{date}/scan{scan_number}/XMALab/measured_points' . format ( date = date , scan_number = scan_number )] . values shape = image_points . shape image_points . shape = ( shape [ 0 ], shape [ 1 ] // 2 , 2 ) # drop 10th BB for now image_points = image_points [:, 0 : 9 , :] . copy () model_points = store [ '/adora/date_{date}/scan{scan_number}/XMALab/model_points' . format ( date = date , scan_number = scan_number )] . values * 10.0 # convert cm -> mm # original model points that appear to work. TODO: figure out why Rudy's point orientation is wrong? model_points_2 = np . array ([ [ - 65.0 , - 65.0 , 100.0 ], # unique [ 65.0 , 65.0 , 130.0 ], # u-12 [ 65.0 , - 65.0 , 130.0 ], # u-3 [ - 65.0 , - 65.0 , 130.0 ], # u-6 [ - 65.0 , 65.0 , 130.0 ], # u-9 [ 65.0 , 65.0 , 0.0 ], # b-12 [ 65.0 , - 65.0 , 0.0 ], # b-3 [ - 65.0 , - 65.0 , 0.0 ], # b-6 [ - 65.0 , 65.0 , 0.0 ], # b-9 ], dtype = 'float32' ) # mapping from XMALabs data to my coordinate space coordinate_mapping_2 = [ 2 , 6 , 1 , 0 , 5 , 8 , 4 , 3 , 7 ] # map image data from XMALabs description to my model (version 2) above. image_points = image_points [:, coordinate_mapping_2 , :] . astype ( 'float32' ) . copy () # determine CT calibration values using Li method on first frame obj = adora_bb_finder . BBFinder () Angle , Source , t , c = obj . li_method ( model_points_2 , image_points [ 0 , :, :]) # convert Source distance from pixels -> mm Source *= 0.32 Angle , Source , t , c (array([ 178.15710548, 75.67482708, 91.06748747]), array([ 234.76490214, 152.46888132, 1213.52259637]), array([ -33.03920917, 90.49597267, 941.87998138]), matrix([[ 921.18466286], [ 202.19132397], [ 83.40560627]])) The value of 1211.8 represents our estimate of SDD distance, which matches the expected value of 1200 mm pretty closely. Next, let's examine reported angle for all views angles = np . zeros ([ image_points . shape [ 0 ]]) sdd = np . zeros ([ image_points . shape [ 0 ]]) for i in range ( image_points . shape [ 0 ]): Angle , Source , t , c = obj . li_method ( model_points_2 , image_points [ i , :, :]) angles [ i ] = Angle [ 1 ] sdd [ i ] = Source [ 2 ] * 0.32 fig = plt . figure () ax = fig . add_subplot ( 121 ) ax . plot ( np . arange ( image_points . shape [ 0 ]), angles ) ax . set_title ( 'Gantry angle (calculated)' ) ax . set_xlabel ( 'View #' ) ax . set_ylabel ( 'Angle (deg)' ) ax2 = fig . add_subplot ( 122 ) ax2 . plot ( np . arange ( image_points . shape [ 0 ]), store [ '/adora/date_{date}/scan{scan_number}/angles' . format ( date = date , scan_number = scan_number )] . angle . values ) ax2 . set_title ( 'Gantry angle (measured)' ) ax2 . set_xlabel ( 'View #' ) ax2 . set_ylabel ( 'Angle (deg)' ) show () &lt;IPython.core.display.Javascript object&gt; Note that the angle values aren't the same for two reasons: The coordinate systems are different (gantry coord system vs model phantom coord system) There appears to be a 90 degree issue in the fitting code. Next, let's examine source to detector distance... fig = plt . figure () ax = fig . add_subplot ( 111 ) ax . plot ( np . arange ( image_points . shape [ 0 ]), sdd ) ax . set_title ( 'Source to detector distance' ) ax . set_xlabel ( 'view #' ) ax . set_ylabel ( 'mm' ) show () &lt;IPython.core.display.Javascript object&gt; U,V offset calculation Next, let's determine how far the 10 th BB deviates from an ideal sine-wave. import numpy as np from scipy.optimize import leastsq import scipy scan_number = 1 image_points = store [ '/adora/date_{date}/scan{scan_number}/XMALab/measured_points' . format ( date = date , scan_number = scan_number )] . values shape = image_points . shape image_points . shape = ( shape [ 0 ], shape [ 1 ] // 2 , 2 ) image_points = image_points [:, 9 , :] # angle data as determined by rpos angles = store [ '/adora/date_{date}/scan{scan_number}/angles' . format ( date = date , scan_number = scan_number )] . angle . values # guess at U0,V0 by averaging data U0 = image_points [:, 0 ] . mean () V0 = image_points [:, 1 ] . mean () # guess at sin function amplitude guess_U_std = image_points [:, 0 ] . max () - image_points [:, 0 ] . min () guess_V_std = image_points [:, 1 ] . max () - image_points [:, 1 ] . min () # phase is zero guess_phase = 0.0 optimize_func1 = lambda t , * x : ( x [ 0 ] * np . sin (( t + x [ 1 ]) / 180. * np . pi ) + x [ 2 ]) p_fit1 , ret1 = scipy . optimize . curve_fit ( optimize_func1 , angles , image_points [:, 0 ], [ guess_U_std , guess_phase , U0 ]) p_fit2 , ret2 = scipy . optimize . curve_fit ( optimize_func1 , angles , image_points [:, 1 ], [ guess_V_std , guess_phase , V0 ]) fig = plt . figure () ax = fig . add_subplot ( 211 ) ax . plot ( image_points [:, 0 ]) data_fit = optimize_func1 ( angles , * p_fit1 ) ax . plot ( data_fit ) ax . set_title ( 'Large BB x-axis position' ) ax . set_xlabel ( 'view #' ) ax . set_ylabel ( 'pixels' ) U_deviation = data_fit - image_points [:, 0 ] ax = fig . add_subplot ( 212 ) ax . plot ( image_points [:, 1 ]) data_fit = optimize_func1 ( angles , * p_fit2 ) ax . plot ( data_fit ) ax . set_title ( 'Large BB y-axis position' ) ax . set_xlabel ( 'view #' ) ax . set_ylabel ( 'pixels' ) V_deviation = data_fit - image_points [:, 1 ] uv_deviations = pd . DataFrame ( np . array ([ U_deviation , V_deviation ]) . T , columns = [ '\u0394U' , '\u0394V' ]) store [ '/adora/date_{date}/scan{scan_number}/uv_deviations' . format ( date = date , scan_number = scan_number )] = uv_deviations store . flush () show () #print(\"Average U0: {:.2f} pixels\".format(store['/adora/date_20170628/bright'].shape[1] - p_fit1[2])) print ( \"Average U0: {:.2f} pixels\" . format ( p_fit1 [ 2 ])) &lt;IPython.core.display.Javascript object&gt; Average U0: 652.18 pixels Okay, this result is a bit worrying: The top plot shows that the U0 shift as a function of time clearly deviates from a sin function. The bottom plot looks okay though. The bottom chart seems to validate the code though - I think the fit is working fine. The recon engine can take this offset values directly, but to satisfy David, let's show pre/post corrected sinograms. In the image, below, raw data is on the left. Corrected data is on the right. Notice that the oscillations at top and bottom have been largely fixed. Also notice the change in particularly the right side of the image. Image ( 'https://s3.amazonaws.com/parallax-adora/Adora/20170628/pre_vs_post_corrected_image.png' ) Experiment with reconstruction of view through large BB These images are from reconstructions done on my other laptop. In the first image, if you look carefully, you can see 8 intersections with the phantom body itself plus the large BB near the center. This actually isn't so bad an image. # U0=654.9, V0=575.41 -- The U0 comes directly from Yang2006, the V0 value is flipped about y-axis Image ( 'https://s3.amazonaws.com/parallax-adora/Adora/20170628/Reconstructions/recon_1_u0%3D654.9%2Cv0%3D575.41.png' , width = 500 ) Next, let's show a reconstruction on the corrected image data - I won't apply U,V shifting in recon code but instead use the shifted image data. # U0=654.9, V0=575.41 -- The U0 comes directly from Yang2006, the V0 value is flipped about y-axis # SDD=1212.978 (Yang), SOD=935.313 (Yang) # # This is an intermediate result... # Image ( 'https://s3.amazonaws.com/parallax-adora/Adora/20170628/Reconstructions/recon_2_u0%3D654.9%2Cv0%3D575.41.png' , width = 500 ) # # and this is the final result -- Note that there's still an obvious center of rotation problem if you zoom in # Image ( 'https://s3.amazonaws.com/parallax-adora/Adora/20170628/Reconstructions/recon_3_u0%3D654.9%2Cv0%3D575.41.png' , width = 500 ) Huh. This works. David's going to rub my nose in this... I should mention that a major breakthrough occurred when I realized that angle data appears to be reversed when compared with the order of DICOM slices. Also, I had to avoid 16-bit overflow issues by throwing in an arbitrary divisor (akin to the ~10k value used in Locus/eXplore data). Test BB tracking code Okay, now let's run a BB detection on first set of DICOM data recorded on 2017-06-28. We no longer really need this code since XMALabs works so well. # create a widget to control which scan to investigate options = [ 'Scan {}' . format ( i + 1 ) for i in range ( 3 )] scan_number = widgets . Dropdown ( options = options , value = 'Scan 1' , description = 'Scan Number:' , disabled = False , ) display ( scan_number ) # create an object finder obj = adora_bb_finder . BBFinder () folder = 'D: \\\\ Data \\\\ UWO X-ray project \\\\ Adora \\\\ 20170628' filenames = os . listdir ( folder )[ - 3 :] filename = filenames [ 0 ] obj . set_dicom_filename ( os . path . join ( folder , filename )) # this line will take a bit of time to execute as it imports ~1GB of data ... image , ds = obj . read_dicom_image ( os . path . join ( folder , filename )) A Jupyter Widget # okay, track all slices progress = IntProgress ( min = 0 , max = obj . _image . shape [ 0 ] - 1 , value = 0 ) progress . bar_style = 'info' progress . bar_style = 'success' label = HTML () label . value = \"Detecting large BB on all slices...\" box = VBox ( children = [ label , progress ]) display ( box ) label2 = '/adora/date_{}/scan1/large_BB_points' . format ( ds . SeriesDate , int ( ds . InstanceNumber ) - 2 ) if label2 not in store : obj . setup_large_bb_detector () points = obj . track_fiducials ( progress = progress ) points = points [ 0 , :, :] else : points = store [ label2 ] . values progress . value = obj . _image . shape [ 0 ] - 1 label . value = \"Done!\" # save points back to hdf5 file if label2 not in store : store [ label2 ] = points store . flush () A Jupyter Widget --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-18-0777e2685a1f&gt; in &lt;module&gt;() 17 points = points[0, :, :] 18 else: ---&gt; 19 points = store[label2].values 20 21 progress.value = obj._image.shape[0]-1 c:\\users\\jgill\\documents\\src\\mv\\lib\\site-packages\\pandas\\io\\pytables.py in __getitem__(self, key) 477 478 def __getitem__(self, key): --&gt; 479 return self.get(key) 480 481 def __setitem__(self, key, value): c:\\users\\jgill\\documents\\src\\mv\\lib\\site-packages\\pandas\\io\\pytables.py in get(self, key) 694 if group is None: 695 raise KeyError('No object named %s in the file' % key) --&gt; 696 return self._read_group(group) 697 698 def select(self, key, where=None, start=None, stop=None, columns=None, c:\\users\\jgill\\documents\\src\\mv\\lib\\site-packages\\pandas\\io\\pytables.py in _read_group(self, group, **kwargs) 1337 1338 def _read_group(self, group, **kwargs): -&gt; 1339 s = self._create_storer(group) 1340 s.infer_axes() 1341 return s.read(**kwargs) c:\\users\\jgill\\documents\\src\\mv\\lib\\site-packages\\pandas\\io\\pytables.py in _create_storer(self, group, format, value, append, **kwargs) 1220 else: 1221 raise TypeError( -&gt; 1222 \"cannot create a storer if the object is not existing \" 1223 \"nor a value are passed\") 1224 else: TypeError: cannot create a storer if the object is not existing nor a value are passed # display results from ipywidgets import widgets from IPython.display import display , clear_output % matplotlib notebook # display first slice #plt.figure(figsize=(8, 8)) fig = plt . figure ( figsize = ( 9 , 6 )) axe = fig . add_subplot ( 211 ) img = axe . imshow ( obj . _image [ 0 , :, :], cmap = 'gray' ) line1 = axe . plot ( points [:, 0 ], points [:, 1 ]) line2 = axe . plot ( points [ 0 , 0 ], points [ 0 , 1 ], 'ro' ) axe2 = fig . add_subplot ( 212 ) line3 = axe2 . plot ( points [:, 0 ]) line4 = axe2 . plot ([ 0 , points [:, 0 ] . min ()], [ 1 , points [:, 0 ] . max ()], 'ro' ) axe2 . set_xlabel ( 'view #' ) axe2 . set_ylabel ( 'BB position (x-axis, pixels)' ) def update_results ( i ): #fig.clf() img . set_data ( obj . _image [ i , :, :]) img . autoscale () ret = axe . set_title ( 'slice {}' . format ( i )) line1 [ 0 ] . set_data ( points [:, 0 ], points [:, 1 ]) line2 [ 0 ] . set_data ( points [ i , 0 ], points [ i , 1 ]) line4 [ 0 ] . set_data ( i , points [ i , 0 ]) axe2 . set_ylim ([ 640 , 740 ]) # why is this needed? # ret = display(fig) ret = widgets . interact ( update_results , i = ( 0 , obj . _image . shape [ 0 ] - 1 )) Clearly, the plot above shows a non-sinusoidal trend. Actually, this could be a magnification effect. I also see that the centroid could be improved upon, but this is a secondary concern. 9-point BB-tracking and Calibration Next, we'll track 9 medium-sized BB's in order to calibrate scanner params. % matplotlib notebook # the `medium` setup is for the 9-BB phantom obj . setup_medium_bb_detector () # find 9 BBs, then display results _slice , keypoints = obj . process_slice ( 0 ) obj . show_slice ( 0 , keypoints ) points = np . array ([ k . pt for k in keypoints ]) means = points [:, 1 ] . mean () unique_bb_index = np . abs ( points [:, 1 ] - means ) . argmin () unique_bb_index top_bb_indices = np . where ( points [:, 1 ] < points [ unique_bb_index , 1 ])[ 0 ] bottom_bb_indices = np . where ( points [:, 1 ] > points [ unique_bb_index , 1 ])[ 0 ] ss = np . linalg . norm ( points - points [ unique_bb_index , :], axis = 1 ) . argsort () upper_point_closest_to_unique = ss [ 1 ] lower_point_closest_to_unique = bottom_bb_indices [ np . linalg . norm ( points [ bottom_bb_indices ] - points [ unique_bb_index , :], axis = 1 ) . argsort ()[ 0 ]] print ( unique_bb_index , upper_point_closest_to_unique , lower_point_closest_to_unique ) # okay, track all slices from ipywidgets import IntProgress , widgets , HTML , VBox progress = IntProgress ( min = 0 , max = obj . _image . shape [ 0 ] - 1 , value = 0 ) progress . bar_style = 'info' progress . bar_style = 'success' label = HTML () label . value = \"Detecting medium BB on all slices...\" box = VBox ( children = [ label , progress ]) display ( box ) points = obj . track_fiducials ( progress = progress , debug = True ) label . value = \"Done!\"","title":"Adora"},{"location":"a/adora/#adora-analysis-2017-06-28","text":"The goal here is to import all data from our 2017-06-28 scanning session, and format it in a pandas dataframe. We collected DICOM image data, rpos angle data and motion capture information. Three identical scans were performed of a 9-BB phantom with a larger, central BB close to the center of rotation for tracking purposes. Motion capture data was recorded, as was gantry angle data.","title":"Adora Analysis (2017-06-28)"},{"location":"a/adora/#data-import","text":"Start with the usual python variable definitions and import statements # set `s3_access` to True to pull data from s3 storage on Amazon -- note that the s3 bucket I'm currently using migrates stuff to glacier so # amazon access won't work at the moment. s3_access = False # additional global variables base_directory = 'D: \\\\ Data \\\\ UWO X-ray project \\\\ Adora \\\\ ' date = '20170628' debug = True import os import sys import zipfile import pandas as pd from pylab import * import matplotlib.pyplot as plt from IPython.display import Image from ipywidgets import IntProgress , widgets , HTML , VBox try : import adora_bb_finder except : pass # ignore _transformations warning # globally change plot size matplotlib . rcParams [ 'figure.figsize' ] = [ 10 , 4.8 ] c : \\ users \\ jgill \\ documents \\ src \\ mv \\ lib \\ site - packages \\ PI \\ math \\ transformations . py : 1888 : UserWarning : failed to import module _transformations warnings . warn ( \"failed to import module %s \" % name ) Create/open an HDF5 data store and set it up to be accesible via pandas . store = pd . HDFStore ( r 'D:\\Data\\UWO X-ray project\\Adora\\{date}\\data_store.hd5' . format ( date = date ))","title":"Data Import"},{"location":"a/adora/#read-rpos-angle-data","text":"We performed three scans with angle measurements and motion capture info. Iterate over each dataset. We'll read from individual CSV-format files and pack them into our HDF5 store. RPos data was recorded by Rudy on his cell phone over bluetooth to the Arduino system we've set up. A master device senses x-ray exposure and requests angle data whenever this occurs. A slave device mounted in the Adora gantry digitally samples rpos angle values and reports last-recorded value when asked. if s3_access : template = \"https://s3.amazonaws.com/parallax-adora/Adora/{date}/ArduinoAngleData/scan+{scan_number}.csv\" else : template = r \"D:\\Data\\UWO X-ray project\\Adora\\{date}\\Arduino Angle data\\scan {scan_number}.csv\" for i in range ( 3 ): label = '/adora/date_{date}/scan{scan_number}/angles' . format ( date = date , scan_number = i + 1 ) if label not in store : store [ label ] = \\ pd . read_csv ( template . format ( date = date , scan_number = i + 1 ), names = [ 'view' , 'angle' ]) store . flush () if debug : for i in range ( 3 ): label = '/adora/date_{date}/scan{scan_number}/angles' . format ( date = date , scan_number = i + 1 ) plot ( store [ label ] . view . values , store [ label ] . angle . values ); show ()","title":"Read RPos angle data"},{"location":"a/adora/#read-motion-capture-data","text":"Okay, next let's pull in motion capture data. The files are somewhat free-form but essentially contain tab-delimited CSV data. We ignore the first few rows of data, process the remainder as csv, then edit column headers. One important thing to know about the motion capture data: The vertical axis in the capture *.ts files is labelled as the 'Y1' axis. At the moment we'll assume a right handed coordinate system, which means we want to convert (Z1,X1,Y1) to (X1,Y1,Z1). Part of the column manipulation, fixes this. if s3_access : template = \"https://s3.amazonaws.com/parallax-adora/Adora/{date}/MotionCapture/adora_rotation_cube{scan_number}.ts\" else : template = r \"D:\\Data\\UWO X-ray project\\Adora\\{date}\\Motion Capture\\adora_rotation_cube{scan_number}.ts\" for i in range ( 3 ): label = '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = i + 1 ) if label not in store : data = pd . read_csv ( template . format ( date = date , scan_number = i + 1 ), \\ sep = ' \\t ' , skiprows = ( 0 , 1 , 2 , 3 )) # tweak column headers columns = list ( data . columns ) columns [ 0 ] = 'Frame#' ; columns [ 1 ] = 'Time' for j in range ( 10 ): idx = 2 + 11 * j columns [ idx ] = 'Y{}' . format ( j + 1 ); columns [ idx + 1 ] = 'Z{}' . format ( j + 1 ); columns [ idx + 2 ] = 'X{}' . format ( j + 1 ) data . columns = columns store [ label ] = data store . flush () What does our (relabeled) data look like? store [ '/adora/date_{date}/scan1/motion_capture' . format ( date = date )] . iloc [:, 0 : 8 ] . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Frame# Time Y1 Z1 X1 vX1 vY1 vZ1 0 1 0.00 -242.95070 1046.91772 -378.62418 NaN NaN NaN 1 2 0.01 -242.96999 1046.91431 -378.59717 -0.61340 2.09961 2.81982 2 3 0.02 -242.96297 1046.95972 -378.56778 0.61493 0.12817 0.29755 3 4 0.03 -242.95769 1046.91687 -378.59122 0.14420 -2.51465 -0.55237 4 5 0.04 -242.96008 1046.90942 -378.57883 3.40881 0.01221 -2.25677","title":"Read Motion-capture data"},{"location":"a/adora/#read-data-from-xmalab","text":"Next, let's process data we generated using XMALab (generated on August 11). Rudy has found a semi-automated way to do BB tracking which simplifies things significantly. Previously, I'd been spending significant effort to optimize a fully-automated way to track BBs, but XMALab is fast enough and good enough that this is no longer a worth-while effort. def convert_xma_to_dataframe ( xma_filename ): \"\"\" Converts fiducial tracking information from an XMALabs *.xma file to a pandas DataFrame \"\"\" # open xma file (it's a zip file) z = zipfile . ZipFile ( xma_filename , mode = 'r' ) namelist = z . namelist () # iterate over all fiducials, extract CSV file. Convert to a pandas dataframe vals = [] for num in range ( 10 ): label = 'Trial 1/data/Marker{:03d}points2d.csv' . format ( num ) if label in namelist : _file = z . open ( label ) df = pd . read_csv ( _file , names = [ 'm{}_x' . format ( num ), 'm{}_y' . format ( num )]) vals . append ( df ) z . close () # concat results df = pd . concat ( vals , axis = 1 ) return df def get_xma_model_coordinates ( xma_filename ): \"\"\" Reads an XMALabs file and returns model coordinates \"\"\" # open xma file (it's a zip file) z = zipfile . ZipFile ( xma_filename , mode = 'r' ) _file = z . open ( 'CalibrationObject/3DCube_framespec_9point.csv' ) df = pd . read_csv ( _file , names = [ 'X' , 'Y' , 'Z' ], header = 0 ) * 10.0 # convert from cm -> mm return df store = pd . HDFStore ( r 'D:\\Data\\UWO X-ray project\\Adora\\{date}\\data_store.hd5' . format ( date = date )) # convert first scan (9-bb scan) for scan_name in ( 'scan1' , 'scan2' ): xma_filename = os . path . join ( base_directory , date , '{date}-{scan_name}.xma' . format ( date = date , scan_name = scan_name )) label = '/adora/date_{date}/{scan_name}/XMALab/measured_points' . format ( date = date , scan_name = scan_name ) df = convert_xma_to_dataframe ( xma_filename ) store [ label ] = df # get model coordinates (for scan 1) coords = get_xma_model_coordinates ( xma_filename ) store [ '/adora/date_{date}/{scan_name}/XMALab/model_points' . format ( date = date , scan_name = scan_name )] = coords store . flush ()","title":"Read data from XMALab"},{"location":"a/adora/#data-analysis","text":"Next, we will visualize the data that we have collected into store .","title":"Data Analysis"},{"location":"a/adora/#investigation-of-motion-tracking-data","text":"Let's plot various (x,y,z) sets to see what our motion tracking data looks like. Select the scan to process in the drop-down box below: #####%matplotlib wx % matplotlib notebook from mpl_toolkits.mplot3d import Axes3D fig = plt . figure () plt . figure ( figsize = ( 8 , 8 )) ax1 = fig . add_subplot ( 221 , projection = '3d' ) ax1 . set_xlabel ( 'x (mm)' ) ax1 . set_ylabel ( 'y (mm)' ) ax1 . set_zlabel ( 'z (mm)' ) ax1 . set_title ( '{date}: Reproducibility of 3 scans' . format ( date = date )) data = store [ '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = 1 )] ax1 . plot ( data [ 'X1' ], data [ 'Y1' ], data [ 'Z1' ]) data = store [ '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = 2 )] ax1 . plot ( data [ 'X1' ], data [ 'Y1' ], data [ 'Z1' ]) data = store [ '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = 3 )] ax1 . plot ( data [ 'X1' ], data [ 'Y1' ], data [ 'Z1' ]) ############### ax2 = fig . add_subplot ( 222 , projection = '3d' ) ax2 . set_xlabel ( 'x (mm)' ) ax2 . set_ylabel ( 'y (mm)' ) ax2 . set_zlabel ( 'z (mm)' ) ax2 . set_title ( 'A few points on detector?' ) data = store [ '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = 1 )] ax2 . plot ( data [ 'X2' ], data [ 'Y2' ], data [ 'Z2' ]) ax2 . plot ( data [ 'X3' ], data [ 'Y3' ], data [ 'Z3' ]) ax3 = fig . add_subplot ( 223 , projection = '3d' ) ax3 . set_xlabel ( 'x (mm)' ) ax3 . set_ylabel ( 'y (mm)' ) ax3 . set_zlabel ( 'z (mm)' ) ax3 . set_title ( 'A few points on tube?' ) data = store [ '/adora/date_{date}/scan{scan_number}/motion_capture' . format ( date = date , scan_number = 1 )] ax3 . plot ( data [ 'X9' ], data [ 'Y9' ], data [ 'Z9' ]) ax3 . plot ( data [ 'X10' ], data [ 'Y10' ], data [ 'Z10' ]) ax4 = fig . add_subplot ( 224 , projection = '3d' ) ax4 . set_xlabel ( 'x (mm)' ) ax4 . set_ylabel ( 'y (mm)' ) ax4 . set_zlabel ( 'z (mm)' ) ax4 . set_title ( 'Merged results' ) ax4 . plot ( data [ 'X2' ], data [ 'Y2' ], data [ 'Z2' ]) ax4 . plot ( data [ 'X3' ], data [ 'Y3' ], data [ 'Z3' ]) ax4 . plot ( data [ 'X9' ], data [ 'Y9' ], data [ 'Z9' ]) ax4 . plot ( data [ 'X10' ], data [ 'Y10' ], data [ 'Z10' ]) show () &lt;IPython.core.display.Javascript object&gt; &lt;IPython.core.display.Javascript object&gt; Okay, this is awesome - we can see a z-axis deviation here clearly in the data. This may be due to a miscalibration of the motion-capture equipment at WOBL . It might otherwise be real, in which case the Adora is sagging as it rotates about its axis.","title":"Investigation of Motion Tracking Data"},{"location":"a/adora/#calibrate-scanner-using-li-method","text":"Get first image points - 10 objects are tracked per frame in two dimensions. The 10 th BB is our center BB which isn't involved in the fit. Recorded image points are measured in mm, while the model that Rudy provided me is measured in cm. scan_number = 1 image_points = store [ '/adora/date_{date}/scan{scan_number}/XMALab/measured_points' . format ( date = date , scan_number = scan_number )] . values shape = image_points . shape image_points . shape = ( shape [ 0 ], shape [ 1 ] // 2 , 2 ) # drop 10th BB for now image_points = image_points [:, 0 : 9 , :] . copy () model_points = store [ '/adora/date_{date}/scan{scan_number}/XMALab/model_points' . format ( date = date , scan_number = scan_number )] . values * 10.0 # convert cm -> mm # original model points that appear to work. TODO: figure out why Rudy's point orientation is wrong? model_points_2 = np . array ([ [ - 65.0 , - 65.0 , 100.0 ], # unique [ 65.0 , 65.0 , 130.0 ], # u-12 [ 65.0 , - 65.0 , 130.0 ], # u-3 [ - 65.0 , - 65.0 , 130.0 ], # u-6 [ - 65.0 , 65.0 , 130.0 ], # u-9 [ 65.0 , 65.0 , 0.0 ], # b-12 [ 65.0 , - 65.0 , 0.0 ], # b-3 [ - 65.0 , - 65.0 , 0.0 ], # b-6 [ - 65.0 , 65.0 , 0.0 ], # b-9 ], dtype = 'float32' ) # mapping from XMALabs data to my coordinate space coordinate_mapping_2 = [ 2 , 6 , 1 , 0 , 5 , 8 , 4 , 3 , 7 ] # map image data from XMALabs description to my model (version 2) above. image_points = image_points [:, coordinate_mapping_2 , :] . astype ( 'float32' ) . copy () # determine CT calibration values using Li method on first frame obj = adora_bb_finder . BBFinder () Angle , Source , t , c = obj . li_method ( model_points_2 , image_points [ 0 , :, :]) # convert Source distance from pixels -> mm Source *= 0.32 Angle , Source , t , c (array([ 178.15710548, 75.67482708, 91.06748747]), array([ 234.76490214, 152.46888132, 1213.52259637]), array([ -33.03920917, 90.49597267, 941.87998138]), matrix([[ 921.18466286], [ 202.19132397], [ 83.40560627]])) The value of 1211.8 represents our estimate of SDD distance, which matches the expected value of 1200 mm pretty closely. Next, let's examine reported angle for all views angles = np . zeros ([ image_points . shape [ 0 ]]) sdd = np . zeros ([ image_points . shape [ 0 ]]) for i in range ( image_points . shape [ 0 ]): Angle , Source , t , c = obj . li_method ( model_points_2 , image_points [ i , :, :]) angles [ i ] = Angle [ 1 ] sdd [ i ] = Source [ 2 ] * 0.32 fig = plt . figure () ax = fig . add_subplot ( 121 ) ax . plot ( np . arange ( image_points . shape [ 0 ]), angles ) ax . set_title ( 'Gantry angle (calculated)' ) ax . set_xlabel ( 'View #' ) ax . set_ylabel ( 'Angle (deg)' ) ax2 = fig . add_subplot ( 122 ) ax2 . plot ( np . arange ( image_points . shape [ 0 ]), store [ '/adora/date_{date}/scan{scan_number}/angles' . format ( date = date , scan_number = scan_number )] . angle . values ) ax2 . set_title ( 'Gantry angle (measured)' ) ax2 . set_xlabel ( 'View #' ) ax2 . set_ylabel ( 'Angle (deg)' ) show () &lt;IPython.core.display.Javascript object&gt; Note that the angle values aren't the same for two reasons: The coordinate systems are different (gantry coord system vs model phantom coord system) There appears to be a 90 degree issue in the fitting code. Next, let's examine source to detector distance... fig = plt . figure () ax = fig . add_subplot ( 111 ) ax . plot ( np . arange ( image_points . shape [ 0 ]), sdd ) ax . set_title ( 'Source to detector distance' ) ax . set_xlabel ( 'view #' ) ax . set_ylabel ( 'mm' ) show () &lt;IPython.core.display.Javascript object&gt;","title":"Calibrate scanner using Li method"},{"location":"a/adora/#uv-offset-calculation","text":"Next, let's determine how far the 10 th BB deviates from an ideal sine-wave. import numpy as np from scipy.optimize import leastsq import scipy scan_number = 1 image_points = store [ '/adora/date_{date}/scan{scan_number}/XMALab/measured_points' . format ( date = date , scan_number = scan_number )] . values shape = image_points . shape image_points . shape = ( shape [ 0 ], shape [ 1 ] // 2 , 2 ) image_points = image_points [:, 9 , :] # angle data as determined by rpos angles = store [ '/adora/date_{date}/scan{scan_number}/angles' . format ( date = date , scan_number = scan_number )] . angle . values # guess at U0,V0 by averaging data U0 = image_points [:, 0 ] . mean () V0 = image_points [:, 1 ] . mean () # guess at sin function amplitude guess_U_std = image_points [:, 0 ] . max () - image_points [:, 0 ] . min () guess_V_std = image_points [:, 1 ] . max () - image_points [:, 1 ] . min () # phase is zero guess_phase = 0.0 optimize_func1 = lambda t , * x : ( x [ 0 ] * np . sin (( t + x [ 1 ]) / 180. * np . pi ) + x [ 2 ]) p_fit1 , ret1 = scipy . optimize . curve_fit ( optimize_func1 , angles , image_points [:, 0 ], [ guess_U_std , guess_phase , U0 ]) p_fit2 , ret2 = scipy . optimize . curve_fit ( optimize_func1 , angles , image_points [:, 1 ], [ guess_V_std , guess_phase , V0 ]) fig = plt . figure () ax = fig . add_subplot ( 211 ) ax . plot ( image_points [:, 0 ]) data_fit = optimize_func1 ( angles , * p_fit1 ) ax . plot ( data_fit ) ax . set_title ( 'Large BB x-axis position' ) ax . set_xlabel ( 'view #' ) ax . set_ylabel ( 'pixels' ) U_deviation = data_fit - image_points [:, 0 ] ax = fig . add_subplot ( 212 ) ax . plot ( image_points [:, 1 ]) data_fit = optimize_func1 ( angles , * p_fit2 ) ax . plot ( data_fit ) ax . set_title ( 'Large BB y-axis position' ) ax . set_xlabel ( 'view #' ) ax . set_ylabel ( 'pixels' ) V_deviation = data_fit - image_points [:, 1 ] uv_deviations = pd . DataFrame ( np . array ([ U_deviation , V_deviation ]) . T , columns = [ '\u0394U' , '\u0394V' ]) store [ '/adora/date_{date}/scan{scan_number}/uv_deviations' . format ( date = date , scan_number = scan_number )] = uv_deviations store . flush () show () #print(\"Average U0: {:.2f} pixels\".format(store['/adora/date_20170628/bright'].shape[1] - p_fit1[2])) print ( \"Average U0: {:.2f} pixels\" . format ( p_fit1 [ 2 ])) &lt;IPython.core.display.Javascript object&gt; Average U0: 652.18 pixels Okay, this result is a bit worrying: The top plot shows that the U0 shift as a function of time clearly deviates from a sin function. The bottom plot looks okay though. The bottom chart seems to validate the code though - I think the fit is working fine. The recon engine can take this offset values directly, but to satisfy David, let's show pre/post corrected sinograms. In the image, below, raw data is on the left. Corrected data is on the right. Notice that the oscillations at top and bottom have been largely fixed. Also notice the change in particularly the right side of the image. Image ( 'https://s3.amazonaws.com/parallax-adora/Adora/20170628/pre_vs_post_corrected_image.png' )","title":"U,V offset calculation"},{"location":"a/adora/#experiment-with-reconstruction-of-view-through-large-bb","text":"These images are from reconstructions done on my other laptop. In the first image, if you look carefully, you can see 8 intersections with the phantom body itself plus the large BB near the center. This actually isn't so bad an image. # U0=654.9, V0=575.41 -- The U0 comes directly from Yang2006, the V0 value is flipped about y-axis Image ( 'https://s3.amazonaws.com/parallax-adora/Adora/20170628/Reconstructions/recon_1_u0%3D654.9%2Cv0%3D575.41.png' , width = 500 ) Next, let's show a reconstruction on the corrected image data - I won't apply U,V shifting in recon code but instead use the shifted image data. # U0=654.9, V0=575.41 -- The U0 comes directly from Yang2006, the V0 value is flipped about y-axis # SDD=1212.978 (Yang), SOD=935.313 (Yang) # # This is an intermediate result... # Image ( 'https://s3.amazonaws.com/parallax-adora/Adora/20170628/Reconstructions/recon_2_u0%3D654.9%2Cv0%3D575.41.png' , width = 500 ) # # and this is the final result -- Note that there's still an obvious center of rotation problem if you zoom in # Image ( 'https://s3.amazonaws.com/parallax-adora/Adora/20170628/Reconstructions/recon_3_u0%3D654.9%2Cv0%3D575.41.png' , width = 500 ) Huh. This works. David's going to rub my nose in this... I should mention that a major breakthrough occurred when I realized that angle data appears to be reversed when compared with the order of DICOM slices. Also, I had to avoid 16-bit overflow issues by throwing in an arbitrary divisor (akin to the ~10k value used in Locus/eXplore data).","title":"Experiment with reconstruction of view through large BB"},{"location":"a/adora/#test-bb-tracking-code","text":"Okay, now let's run a BB detection on first set of DICOM data recorded on 2017-06-28. We no longer really need this code since XMALabs works so well. # create a widget to control which scan to investigate options = [ 'Scan {}' . format ( i + 1 ) for i in range ( 3 )] scan_number = widgets . Dropdown ( options = options , value = 'Scan 1' , description = 'Scan Number:' , disabled = False , ) display ( scan_number ) # create an object finder obj = adora_bb_finder . BBFinder () folder = 'D: \\\\ Data \\\\ UWO X-ray project \\\\ Adora \\\\ 20170628' filenames = os . listdir ( folder )[ - 3 :] filename = filenames [ 0 ] obj . set_dicom_filename ( os . path . join ( folder , filename )) # this line will take a bit of time to execute as it imports ~1GB of data ... image , ds = obj . read_dicom_image ( os . path . join ( folder , filename )) A Jupyter Widget # okay, track all slices progress = IntProgress ( min = 0 , max = obj . _image . shape [ 0 ] - 1 , value = 0 ) progress . bar_style = 'info' progress . bar_style = 'success' label = HTML () label . value = \"Detecting large BB on all slices...\" box = VBox ( children = [ label , progress ]) display ( box ) label2 = '/adora/date_{}/scan1/large_BB_points' . format ( ds . SeriesDate , int ( ds . InstanceNumber ) - 2 ) if label2 not in store : obj . setup_large_bb_detector () points = obj . track_fiducials ( progress = progress ) points = points [ 0 , :, :] else : points = store [ label2 ] . values progress . value = obj . _image . shape [ 0 ] - 1 label . value = \"Done!\" # save points back to hdf5 file if label2 not in store : store [ label2 ] = points store . flush () A Jupyter Widget --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-18-0777e2685a1f&gt; in &lt;module&gt;() 17 points = points[0, :, :] 18 else: ---&gt; 19 points = store[label2].values 20 21 progress.value = obj._image.shape[0]-1 c:\\users\\jgill\\documents\\src\\mv\\lib\\site-packages\\pandas\\io\\pytables.py in __getitem__(self, key) 477 478 def __getitem__(self, key): --&gt; 479 return self.get(key) 480 481 def __setitem__(self, key, value): c:\\users\\jgill\\documents\\src\\mv\\lib\\site-packages\\pandas\\io\\pytables.py in get(self, key) 694 if group is None: 695 raise KeyError('No object named %s in the file' % key) --&gt; 696 return self._read_group(group) 697 698 def select(self, key, where=None, start=None, stop=None, columns=None, c:\\users\\jgill\\documents\\src\\mv\\lib\\site-packages\\pandas\\io\\pytables.py in _read_group(self, group, **kwargs) 1337 1338 def _read_group(self, group, **kwargs): -&gt; 1339 s = self._create_storer(group) 1340 s.infer_axes() 1341 return s.read(**kwargs) c:\\users\\jgill\\documents\\src\\mv\\lib\\site-packages\\pandas\\io\\pytables.py in _create_storer(self, group, format, value, append, **kwargs) 1220 else: 1221 raise TypeError( -&gt; 1222 \"cannot create a storer if the object is not existing \" 1223 \"nor a value are passed\") 1224 else: TypeError: cannot create a storer if the object is not existing nor a value are passed # display results from ipywidgets import widgets from IPython.display import display , clear_output % matplotlib notebook # display first slice #plt.figure(figsize=(8, 8)) fig = plt . figure ( figsize = ( 9 , 6 )) axe = fig . add_subplot ( 211 ) img = axe . imshow ( obj . _image [ 0 , :, :], cmap = 'gray' ) line1 = axe . plot ( points [:, 0 ], points [:, 1 ]) line2 = axe . plot ( points [ 0 , 0 ], points [ 0 , 1 ], 'ro' ) axe2 = fig . add_subplot ( 212 ) line3 = axe2 . plot ( points [:, 0 ]) line4 = axe2 . plot ([ 0 , points [:, 0 ] . min ()], [ 1 , points [:, 0 ] . max ()], 'ro' ) axe2 . set_xlabel ( 'view #' ) axe2 . set_ylabel ( 'BB position (x-axis, pixels)' ) def update_results ( i ): #fig.clf() img . set_data ( obj . _image [ i , :, :]) img . autoscale () ret = axe . set_title ( 'slice {}' . format ( i )) line1 [ 0 ] . set_data ( points [:, 0 ], points [:, 1 ]) line2 [ 0 ] . set_data ( points [ i , 0 ], points [ i , 1 ]) line4 [ 0 ] . set_data ( i , points [ i , 0 ]) axe2 . set_ylim ([ 640 , 740 ]) # why is this needed? # ret = display(fig) ret = widgets . interact ( update_results , i = ( 0 , obj . _image . shape [ 0 ] - 1 )) Clearly, the plot above shows a non-sinusoidal trend. Actually, this could be a magnification effect. I also see that the centroid could be improved upon, but this is a secondary concern.","title":"Test BB tracking code"},{"location":"a/adora/#9-point-bb-tracking-and-calibration","text":"Next, we'll track 9 medium-sized BB's in order to calibrate scanner params. % matplotlib notebook # the `medium` setup is for the 9-BB phantom obj . setup_medium_bb_detector () # find 9 BBs, then display results _slice , keypoints = obj . process_slice ( 0 ) obj . show_slice ( 0 , keypoints ) points = np . array ([ k . pt for k in keypoints ]) means = points [:, 1 ] . mean () unique_bb_index = np . abs ( points [:, 1 ] - means ) . argmin () unique_bb_index top_bb_indices = np . where ( points [:, 1 ] < points [ unique_bb_index , 1 ])[ 0 ] bottom_bb_indices = np . where ( points [:, 1 ] > points [ unique_bb_index , 1 ])[ 0 ] ss = np . linalg . norm ( points - points [ unique_bb_index , :], axis = 1 ) . argsort () upper_point_closest_to_unique = ss [ 1 ] lower_point_closest_to_unique = bottom_bb_indices [ np . linalg . norm ( points [ bottom_bb_indices ] - points [ unique_bb_index , :], axis = 1 ) . argsort ()[ 0 ]] print ( unique_bb_index , upper_point_closest_to_unique , lower_point_closest_to_unique ) # okay, track all slices from ipywidgets import IntProgress , widgets , HTML , VBox progress = IntProgress ( min = 0 , max = obj . _image . shape [ 0 ] - 1 , value = 0 ) progress . bar_style = 'info' progress . bar_style = 'success' label = HTML () label . value = \"Detecting medium BB on all slices...\" box = VBox ( children = [ label , progress ]) display ( box ) points = obj . track_fiducials ( progress = progress , debug = True ) label . value = \"Done!\"","title":"9-point BB-tracking and Calibration"},{"location":"appendices/file-formats/","text":"Appendix A - Supported File Formats Supported Image File Formats This is a partial list of image formats that MicroView can read and/or write: vff - SUN TAAC file format dcm - DICOM version 3.0, part 10 image format DICOMDIR - DICOM directory file (container for multiple DICOM images) vtk - The Visualization Tool Kit image format ppm,pbm,pgm - Portable pixmap/bitmap/graymap image format jpg - jpeg image format png - Portable network graphics format bmp - Windows bitmap file format tiff - Tagged image file format (uncompressed, 8-bit, 16-bit and 32-bit single and multi-channel images) hdr - Analyze image format mnc - MINC image format nfo - A simple raw image format interfile - A Nuclear medicine file format mha,mhd - UNC meta image data vgi,vgl - VG Studio Max image export format vox - RTViz Voxel file format webp - WebP image format pic - BioRad image format isq - Scanco microCT image format Supported Geometry File Formats vtk - Native VTK format obj - Alias Wavefront file format stl - Stereo Lithography File format bin - PLOT3D file format ply - PLY file format vtp - VTK XML file format oogl - Geomview OFF format file gts - GNU Triangulated Library file format tec - Tecplot file format","title":"File Formats"},{"location":"appendices/file-formats/#appendix-a-supported-file-formats","text":"","title":"Appendix A - Supported File Formats"},{"location":"appendices/file-formats/#supported-image-file-formats","text":"This is a partial list of image formats that MicroView can read and/or write: vff - SUN TAAC file format dcm - DICOM version 3.0, part 10 image format DICOMDIR - DICOM directory file (container for multiple DICOM images) vtk - The Visualization Tool Kit image format ppm,pbm,pgm - Portable pixmap/bitmap/graymap image format jpg - jpeg image format png - Portable network graphics format bmp - Windows bitmap file format tiff - Tagged image file format (uncompressed, 8-bit, 16-bit and 32-bit single and multi-channel images) hdr - Analyze image format mnc - MINC image format nfo - A simple raw image format interfile - A Nuclear medicine file format mha,mhd - UNC meta image data vgi,vgl - VG Studio Max image export format vox - RTViz Voxel file format webp - WebP image format pic - BioRad image format isq - Scanco microCT image format","title":"Supported Image File Formats"},{"location":"appendices/file-formats/#supported-geometry-file-formats","text":"vtk - Native VTK format obj - Alias Wavefront file format stl - Stereo Lithography File format bin - PLOT3D file format ply - PLY file format vtp - VTK XML file format oogl - Geomview OFF format file gts - GNU Triangulated Library file format tec - Tecplot file format","title":"Supported Geometry File Formats"},{"location":"appendices/memory-performance/","text":"Appendix B - Memory performance of MicroView under 32-bit Windows MicroView memory performance can be improved by running under certain version of Windows operating systems, where the large memory aware boot option is available. Windows XP Professional and Windows 2003 versions both support this boot option. The method for increasing available memory for MicroView involves modification of the file C:\\boot.ini to add \"/3GB /PAE\" to the boot line: Log on as a user with Administrative privileges Select Start \u2192 Settings \u2192 Control Panel \u2192 System \u2192 Advanced \u2192 (Startup and Recovery) Settings , then click the Edit button. Duplicate the first line under [operating systems] Change the name of the new entry (the text between quotes), then add a \"/3GB /PAE\" switch at the end of the line. Save and Exit. The file should look something like the following: \\ [ boot loader ] timeout = 5 default = multi ( 0 ) disk ( 0 ) rdisk ( 0 ) partition ( 1 ) \\\\ WINNT \\ [ operating systems ] multi ( 0 ) disk ( 0 ) rdisk ( 0 ) partition ( 1 ) \\\\ WINNT = \"Microsoft Windows XP Professional\" / fastdetect multi ( 0 ) disk ( 0 ) rdisk ( 0 ) partition ( 1 ) \\\\ WINNT = \"Microsoft Windows XP Professional\" / fastdetect / 3 GB / PAE Reboot your computer. As your computer boots, a screen will be displayed giving you the choice of selecting between different boot options. Select the new boot option corresponding to the name you entered in C:\\boot.ini . Once the computer finishes booting, you will be able to take advantage of up to 3GB of virtual memory in each instance of MicroView, rather than the default of 2GB.","title":"Memory Performance"},{"location":"appendices/memory-performance/#appendix-b-memory-performance-of-microview-under-32-bit-windows","text":"MicroView memory performance can be improved by running under certain version of Windows operating systems, where the large memory aware boot option is available. Windows XP Professional and Windows 2003 versions both support this boot option. The method for increasing available memory for MicroView involves modification of the file C:\\boot.ini to add \"/3GB /PAE\" to the boot line: Log on as a user with Administrative privileges Select Start \u2192 Settings \u2192 Control Panel \u2192 System \u2192 Advanced \u2192 (Startup and Recovery) Settings , then click the Edit button. Duplicate the first line under [operating systems] Change the name of the new entry (the text between quotes), then add a \"/3GB /PAE\" switch at the end of the line. Save and Exit. The file should look something like the following: \\ [ boot loader ] timeout = 5 default = multi ( 0 ) disk ( 0 ) rdisk ( 0 ) partition ( 1 ) \\\\ WINNT \\ [ operating systems ] multi ( 0 ) disk ( 0 ) rdisk ( 0 ) partition ( 1 ) \\\\ WINNT = \"Microsoft Windows XP Professional\" / fastdetect multi ( 0 ) disk ( 0 ) rdisk ( 0 ) partition ( 1 ) \\\\ WINNT = \"Microsoft Windows XP Professional\" / fastdetect / 3 GB / PAE Reboot your computer. As your computer boots, a screen will be displayed giving you the choice of selecting between different boot options. Select the new boot option corresponding to the name you entered in C:\\boot.ini . Once the computer finishes booting, you will be able to take advantage of up to 3GB of virtual memory in each instance of MicroView, rather than the default of 2GB.","title":"Appendix B - Memory performance of MicroView under 32-bit Windows"},{"location":"appendices/raw-import-notes/","text":"Appendix C - MicroView's support for Raw image data MicroView reads and writes a variety of 2D and 3D image formats, summarized in the appendix above. In particular, the \".nfo\" image format is a simple format that can be easily used to import and export raw images with MicroView. It is a two-file format that consists of a raw image, contained in a file named something like rawfile.img , and a text-based header file with the same base name, but with a \".nfo\" extension (i.e. rawfile.nfo ). Header files are simple ascii text files, that contain a set of name-value pairs, separated by a colon, one pair per line of the file. An example header file is listed below: width : 336 height : 283 numFrames : 160 shear_angle ( rad ): 0.000000 xVoxelSize : 0.1 yVoxelSize : 0.1 zVoxelSize : 0.2 dataType : 4 This header file describes a 336x283x160 raw image with voxels that are 0.1mm x 0.1mm x 0.2mm in dimension. The shear_angle(rad) entry should be present in the header, but is ignored by MicroView -- it can safely be set to zero. The dataType entry defines the numeric type of the data contained within the raw image file, rawimage.img . The value should be selected from the table below: Image Datatype codes Function Description 2 Signed 8-bit char 3 Unsigned 8-bit char 4 Signed 16-bit short integer 5 Unsigned 16-bit short integer 8 Signed long integer 9 Unsigned long integer 10 Floating-point data Given a raw image for import, first rename the file to have an extension of \".img\". Determine the image dimensions, voxel size and image format. Using the text editor of your choice, create a corresponding header file with the same base name, but an \".nfo\" extension. Copy and edit the entries listed Example 1 into this file, customize to match your image and save. Load MicroView and select the \".nfo\" for reading.","title":"Raw Image Data Support"},{"location":"appendices/raw-import-notes/#appendix-c-microviews-support-for-raw-image-data","text":"MicroView reads and writes a variety of 2D and 3D image formats, summarized in the appendix above. In particular, the \".nfo\" image format is a simple format that can be easily used to import and export raw images with MicroView. It is a two-file format that consists of a raw image, contained in a file named something like rawfile.img , and a text-based header file with the same base name, but with a \".nfo\" extension (i.e. rawfile.nfo ). Header files are simple ascii text files, that contain a set of name-value pairs, separated by a colon, one pair per line of the file. An example header file is listed below: width : 336 height : 283 numFrames : 160 shear_angle ( rad ): 0.000000 xVoxelSize : 0.1 yVoxelSize : 0.1 zVoxelSize : 0.2 dataType : 4 This header file describes a 336x283x160 raw image with voxels that are 0.1mm x 0.1mm x 0.2mm in dimension. The shear_angle(rad) entry should be present in the header, but is ignored by MicroView -- it can safely be set to zero. The dataType entry defines the numeric type of the data contained within the raw image file, rawimage.img . The value should be selected from the table below: Image Datatype codes Function Description 2 Signed 8-bit char 3 Unsigned 8-bit char 4 Signed 16-bit short integer 5 Unsigned 16-bit short integer 8 Signed long integer 9 Unsigned long integer 10 Floating-point data Given a raw image for import, first rename the file to have an extension of \".img\". Determine the image dimensions, voxel size and image format. Using the text editor of your choice, create a corresponding header file with the same base name, but an \".nfo\" extension. Copy and edit the entries listed Example 1 into this file, customize to match your image and save. Load MicroView and select the \".nfo\" for reading.","title":"Appendix C - MicroView's support for Raw image data"},{"location":"dev/plugin-architecture/","text":"Plugin Architecture Introduction MicroView supports two extension mechanisms for running third-party code: plugins and scripts . MicroView's plugins are the principle way for integrating features into the application - they can contain platform dependent and platform independent code including user interface components. They can call out to other plugins in MicroView. They can require addition software that MicroView will download and install on the user's behalf. Under the hood, MicroView plugins rely on python's egg file format and capabilities.","title":"Plugin Architecture"},{"location":"dev/plugin-architecture/#plugin-architecture","text":"","title":"Plugin Architecture"},{"location":"dev/plugin-architecture/#introduction","text":"MicroView supports two extension mechanisms for running third-party code: plugins and scripts . MicroView's plugins are the principle way for integrating features into the application - they can contain platform dependent and platform independent code including user interface components. They can call out to other plugins in MicroView. They can require addition software that MicroView will download and install on the user's behalf. Under the hood, MicroView plugins rely on python's egg file format and capabilities.","title":"Introduction"},{"location":"dev/scripting/","text":"Scripting Introduction MicroView supports two extension mechanisms for running third-party code: plugins and scripts . While MicroView's plugin architecture is more powerful, and gives fine-grain control over the application, it has a steeper learning curve. For simple tasks, MicroView's scripting interface is sufficient. Directories and Files On application startup, MicroView looks for scripts by searching for python *.py files under the Scripts folder in it's application settings folder. The application settings folder can be found by selecting Help \u2192 Open User directory from MicroView's menu. The actual folder location will vary depending on your platform. In the figure, below, the script folder is show for a Windows 10 computer. test1.py will be examined on application startup to see if it is a valid script. Anatomy of a MicroView Script File The contents of test1.py are shown below: import logging logger = logging . getLogger ( __name__ ) def zero_image ( image , origin , spacing , dicom_info ): \"\"\" replace image values with zero \"\"\" image [:] = 0 def flip_image ( image , origin , spacing , dicom_info ): \"\"\" flip image in x-axis \"\"\" image [:] = image [:, :: - 1 ] logger . info ( \"flipped image in x axis\" ) def print_dicom_header ( image , origin , spacing , dicom_info ): \"\"\" print image dicom header \"\"\" logger . info ( \"DICOM info: {}\" . format ( str ( dicom_info ))) zero_image . __menu__ = 'Fill image with zeros' flip_image . __menu__ = 'Flip image in x-axis' print_dicom_header . __menu__ = 'Show image DICOM header' print_dicom_header . __requires__ = [ 'BeautifulSoup' ] This script file contains three entry-point functions: zero_img() , flip_image() and print_dicom_header() all with the same argument list ( image , origin , spacing , dicom_info ). In order for MicroView to call a script function, it must have this calling syntax. Arguments image : contains the currently-selected image as a numpy array. origin : the (x,y,z) origin of the image, measured in mm spacing : the image voxel spacing (x,y,z), measured in mm dicom_info: a pydicom compatible dictionary representing the image meta-info in DICOM format. If the original image data was DICOM this will be a verbatim copy, otherwise a DICOM header is interpolated for the image Note: The image array is a shared copy of the current image in MicroView: modifications to the image array modify the image in MicroView directly. Meta-info At the bottom of test1.py are four static lines that may seem a little odd. The first three attach a static attribute named __menu__ to each function. MicroView searches for this attribute before deciding if a function should be displayed from the Scripts menu. The final line provides a python list of required packages in order for the given function to be run. For instance, in test1.py above, print_dicom_header() is a simple script that prints DICOM header values to MicroView's central logging window - but it claims to require additional python software (BeautifulSoup in this case) before the plugin can be run. This last attribute provides a rudimentary way for MicroView to bootstrap additional software dependencies using python's pip installer.","title":"Scripting"},{"location":"dev/scripting/#scripting","text":"","title":"Scripting"},{"location":"dev/scripting/#introduction","text":"MicroView supports two extension mechanisms for running third-party code: plugins and scripts . While MicroView's plugin architecture is more powerful, and gives fine-grain control over the application, it has a steeper learning curve. For simple tasks, MicroView's scripting interface is sufficient.","title":"Introduction"},{"location":"dev/scripting/#directories-and-files","text":"On application startup, MicroView looks for scripts by searching for python *.py files under the Scripts folder in it's application settings folder. The application settings folder can be found by selecting Help \u2192 Open User directory from MicroView's menu. The actual folder location will vary depending on your platform. In the figure, below, the script folder is show for a Windows 10 computer. test1.py will be examined on application startup to see if it is a valid script.","title":"Directories and Files"},{"location":"dev/scripting/#anatomy-of-a-microview-script-file","text":"The contents of test1.py are shown below: import logging logger = logging . getLogger ( __name__ ) def zero_image ( image , origin , spacing , dicom_info ): \"\"\" replace image values with zero \"\"\" image [:] = 0 def flip_image ( image , origin , spacing , dicom_info ): \"\"\" flip image in x-axis \"\"\" image [:] = image [:, :: - 1 ] logger . info ( \"flipped image in x axis\" ) def print_dicom_header ( image , origin , spacing , dicom_info ): \"\"\" print image dicom header \"\"\" logger . info ( \"DICOM info: {}\" . format ( str ( dicom_info ))) zero_image . __menu__ = 'Fill image with zeros' flip_image . __menu__ = 'Flip image in x-axis' print_dicom_header . __menu__ = 'Show image DICOM header' print_dicom_header . __requires__ = [ 'BeautifulSoup' ] This script file contains three entry-point functions: zero_img() , flip_image() and print_dicom_header() all with the same argument list ( image , origin , spacing , dicom_info ). In order for MicroView to call a script function, it must have this calling syntax.","title":"Anatomy of a MicroView Script File"},{"location":"dev/scripting/#arguments","text":"image : contains the currently-selected image as a numpy array. origin : the (x,y,z) origin of the image, measured in mm spacing : the image voxel spacing (x,y,z), measured in mm dicom_info: a pydicom compatible dictionary representing the image meta-info in DICOM format. If the original image data was DICOM this will be a verbatim copy, otherwise a DICOM header is interpolated for the image Note: The image array is a shared copy of the current image in MicroView: modifications to the image array modify the image in MicroView directly.","title":"Arguments"},{"location":"dev/scripting/#meta-info","text":"At the bottom of test1.py are four static lines that may seem a little odd. The first three attach a static attribute named __menu__ to each function. MicroView searches for this attribute before deciding if a function should be displayed from the Scripts menu. The final line provides a python list of required packages in order for the given function to be run. For instance, in test1.py above, print_dicom_header() is a simple script that prints DICOM header values to MicroView's central logging window - but it claims to require additional python software (BeautifulSoup in this case) before the plugin can be run. This last attribute provides a rudimentary way for MicroView to bootstrap additional software dependencies using python's pip installer.","title":"Meta-info"}]}